<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch08"></a>Chapter 8. Sorry My App Ate the Cluster</h2></div></div></div><p>Using Kubernetes to run our applications allows us to achieve much higher utilization of resources on the machines in our clusters. The Kubernetes scheduler is very effective at packing different applications onto your cluster in a way that will maximize the use of the resources on each machine. You can schedule a mix of lower-priority jobs that can be restarted if needed, for example, batch jobs, and high-priority jobs, such as web servers or databases. Kubernetes will help you make use of the idle CPU cycles that occur when your web server is waiting for requests.</p><p>This is great news if you want to reduce the amount that you are paying AWS, for your EC2 instances to run your applications. It is important to learn how to configure your pods, so Kubernetes can account for the resource use of your applications. If you don't configure your pods correctly, then the reliability and performance of your application could be impacted as Kubernetes may need to evict your pods from a node because it is running out of resources.</p><p>In this chapter, you are going to start by learning how to account for the memory and CPU that your pods will use. We will learn how to configure pods with a different quality of service so important workloads are guaranteed the resources they need, but less important workloads can make use of idle resources when they are available without needing dedicated resources. You will also learn how to make use of Kubernetes autoscaling facilities to add additional pods to your applications when they are under increased load, and to add additional nodes to your cluster when resources run low.</p><p>In this chapter, you will learn how to do the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Configure container resource requests and limits</li><li style="list-style-type: disc">Configure your <span>pods</span><a id="id325750932" class="indexterm"></a> for a desired <span class="strong"><strong>Quality of Service</strong></span> (<span class="strong"><strong>QoS</strong></span>) class</li><li style="list-style-type: disc">Set quotas on the use of resources per namespace</li><li style="list-style-type: disc">Use the horizontal pod autoscaler to automatically scale your applications to match the demand for them</li><li style="list-style-type: disc">Use the cluster autoscaler to automatically provision and terminate EC2 instances as the use of your cluster changes over time</li></ul></div></div>