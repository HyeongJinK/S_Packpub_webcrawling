<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec58"></a>Horizontal Pod Autoscaling</h2></div></div><hr /></div><p>Some applications can be <span>scaled</span><a id="id325268185" class="indexterm"></a> up to handle an increased load by adding additional replicas. Stateless web applications are a great example of this, as adding additional replicas provides the additional capacity required to handle increased requests to your application. Some other applications are also designed to operate in such a way that adding additional pods can handle increased loads; many systems that are architected around processing messages from a central queue can also handle an increased load in this way.</p><p>When we use Kubernetes deployments to deploy our pod workloads, it is simple to scale the number of replicas used by our applications up and down using the <code class="literal">kubectl scale</code> command. However, if we want our applications to automatically respond to changes in their workloads and scale to meet demand, then Kubernetes provides us with Horizontal Pod Autoscaling.</p><p>Horizontal Pod Autoscaling allows us to define rules that will scale the numbers of replicas up or down in our deployments based on CPU utilization and optionally other custom metrics. Before we are able to use Horizontal Pod Autoscaling in our cluster, we need to deploy the Kubernetes metrics server; this server provides endpoints that are used to discover CPU utilization and other metrics generated by our applications.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec83"></a>Deploying the metrics server</h3></div></div></div><p>Before we can make use of Horizontal Pod Autoscaling, we need to deploy the Kubernetes metrics server to our cluster. This is because the Horizontal Pod Autoscaling controller <span>makes</span><a id="id325268208" class="indexterm"></a> use of the metrics provided by the <code class="literal">metrics.k8s.io</code> API, which is provided by the metrics server.</p><p>While some installations of Kubernetes may install this add-on by default, in our EKS cluster we will need to deploy it ourselves.</p><p>There are a number of ways to deploy add-on components to your cluster:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">If you have followed the advice in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>, and are provisioning your cluster with Terraform, you could provision the required manifests with <code class="literal">kubectl</code> as we did in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>, when we provisioned kube2iam.</li><li style="list-style-type: disc">If you are using helm to manage applications on your cluster, you could use the stable/metrics server chart.</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">In this chapter, for simplicity we are just going to deploy the metrics server manifests using <code class="literal">kubectl.</code></li><li style="list-style-type: disc">I like to integrate deploying add-ons such as the metrics server and kube2iam with the process that provisions the cluster, as I see them as integral parts of the cluster infrastructure. But if you are going to use a tool like helm to manage deploying applications to your cluster, then you might prefer to manage everything running on your cluster with the same tool. The decision you take really depends on the processes you and your team adopt for managing your cluster and the applications that run on it.</li><li style="list-style-type: disc">The metrics server is developed in the GitHub repository found at <a class="ulink" href="https://github.com/kubernetes-incubator/metrics-server" target="_blank"><span>https://github.com/kubernetes-incubator/metrics-server</span></a> You will find the manifests required to deploy it in the deploy directory of that repository.</li></ul></div><p>Start by cloning the configuration from GitHub. The metrics server began supporting the authentication methods provided by EKS in version 0.0.3 so make sure the manifests you have use at least that version.</p><p>You will find a number of manifests in the <code class="literal">deploy/1.8+</code> directory. The <code class="literal">auth-reader.yaml</code> and <code class="literal">auth-delegator.yaml</code> files configure the integration of the metrics server with the Kubernetes authorization infrastructure. The <code class="literal">resource-reader.yaml</code> file configures a role to give the metrics server the permissions to read resources from the API server, in order to discover the nodes that pods are running on. Basically, <code class="literal">metrics-server-deployment.yaml</code> and <code class="literal">metrics-server-service.yaml</code> define the deployment used to run the service itself and a service to be able to access it. Finally, the <code class="literal">metrics-apiservice.yaml</code> file defines an <code class="literal">APIService</code> resource that registers the metrics.k8s.io API group with the Kubernetes API server aggregation layer; this means that requests to the API server for the metrics.k8s.io group will be proxied to the metrics server service.</p><p>Deploying these manifests with <code class="literal">kubectl</code> is simple, just submit all of the manifests to the cluster with <code class="literal">kubectl apply</code>:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl apply -f deploy/1.8+</strong></span></pre><p>You should see a message about each of the resources being created on the cluster.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip66"></a>Note</h3><p>If you are using a tool like Terraform to provision your cluster, you might use it to submit the manifests for the metrics server when you create your cluster.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec84"></a>Verifying the metrics server and troubleshooting</h3></div></div></div><p>Before we continue, we should <span>take</span><a id="id325751206" class="indexterm"></a> a moment to <span>check</span><a id="id325751214" class="indexterm"></a> that our cluster and the metrics server are correctly configured to work together.</p><p>After the metrics server is running on your cluster and has had a chance to collect metrics from the cluster (give it a minute or so), you should be able to use the <code class="literal">kubectl top</code> command to see the resource usage of the pods and nodes in your cluster.</p><p>Start by running <code class="literal">kubectl top nodes</code>. If you see output like this, then the metrics server is configured correctly and is collecting metrics from your nodes:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl top nodes</strong></span><span class="strong"><strong>NAME             CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%</strong></span><span class="strong"><strong>ip-10-3-29-209   20m          1%        717Mi           19%</strong></span><span class="strong"><strong>ip-10-3-61-119   24m          1%        1011Mi          28%</strong></span></pre><p>If you see an error message, then there are a number of troubleshooting steps you can follow.</p><p>You should start by describing the metrics server deployment and checking that one replica is available:</p><pre class="programlisting"><span class="strong"><strong>kubectl -n kube-system describe deployment metrics-server</strong></span></pre><p>If it is not, you should debug the created pod by running <code class="literal">kubectl -n kube-system describe pod</code>. Look at the events to see why the server is not available. Make sure that you are running at least version 0.0.3 of the metrics server, as previous versions didn't support authenticating with the EKS API server.</p><p>If the metrics server is running correctly and you still see errors when running <code class="literal">kubectl top</code>, the issue is that the APIservice registered with the aggregation layer is not configured correctly. Check the events output at the bottom of the information returned when you run <code class="literal">kubectl describe apiservice v1beta1.metrics.k8s.io</code>.</p><p>One common issue is that the EKS control plane cannot connect to the metrics server service on port <code class="literal">443</code>. If you followed the instructions in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>, you should already have a security group rule allowing this traffic from the control plane to the worker nodes, but some other documentation can suggest more restrictive rules, which might not allow traffic on port <code class="literal">443</code>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec85"></a>Autoscaling pods based on CPU usage</h3></div></div></div><p>Once the metrics server has <span>been</span><a id="id325753366" class="indexterm"></a> installed into our cluster, we will be able to use the metrics API to retrieve information about CPU and memory usage of the pods and nodes in our cluster. Using the <code class="literal">kubectl top</code> command is a simple example of this.</p><p>The Horizontal Pod Autoscaler can also use this same metrics API to gather information about the current resource usage of the pods that make up a deployment.</p><p>Let's look at an example of this; we are going to deploy a sample application that uses a lot of CPU under load, then configure a Horizontal Pod Autoscaler to scale up extra replicas of this pod to provide extra capacity when CPU utilization exceeds a target level.</p><p>The application we will be deploying as an example is a simple Ruby web application that can calculate the nth number in the Fibonacci sequence, this application uses a simple recursive algorithm, and is not very efficient (perfect for us to experiment with autoscaling). The deployment for this application is very simple. It is important to set resource limits for CPU because the target CPU utilization is based on a percentage of this limit:</p><pre class="programlisting"><span class="strong"><strong>deployment.yaml</strong></span> 
apiVersion: apps/v1 
kind: Deployment 
metadata: 
  name: fib 
  labels: 
    app: fib 
spec: 
  selector: 
    matchLabels: 
      app: fib 
  template: 
    metadata: 
      labels: 
        app: fib 
    spec: 
      containers: 
      - name: fib 
        image: errm/fib 
        ports: 
        - containerPort: 9292 
        resources: 
          limits: 
            cpu: 250m 
            memory: 32Mi </pre><p>We are not specifying a number of replicas in the deployment spec; when we first submit this deployment to the cluster, the number of replicas will therefore default to 1. This is good practice when creating a deployment where we intend the replicas to be adjusted by a Horizontal Pod Autoscaler, because it means that if we use <code class="literal">kubectl apply</code> to update the deployment later, we won't override the replica value the Horizonal Pod Autoscaler has set (inadvertently scaling the deployment down or up).</p><p>Let's deploy this application to the cluster:</p><pre class="programlisting"><span class="strong"><strong>kubectl apply -f deployment.yaml</strong></span></pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip67"></a>Note</h3><p>You could run <code class="literal">kubectl get pods -l app=fib</code> to check that the application started up correctly.</p></div><p>We will create a service, so we are able to access the pods in our deployment, requests will be proxied to each of the replicas, spreading the load:</p><pre class="programlisting"><span class="strong"><strong>service.yaml</strong></span> 
kind: Service 
apiVersion: v1 
metadata: 
  name: fib 
spec: 
  selector: 
    app: fib 
  ports: 
  - protocol: TCP 
    port: 80 
    targetPort: 9292 </pre><p>Submit the service manifest to the cluster with <code class="literal">kubectl</code>:</p><pre class="programlisting"><span class="strong"><strong>kubectl apply -f service.yaml</strong></span></pre><p>We are going to configure a Horizonal Pod Autoscaler to control the number of replicas in our deployment. The <code class="literal">spec</code> defines how we want the autoscaler to behave; we have defined here that we want the autoscaler to maintain between 1 and 10 replicas of our application and achieve a target average CPU utilization of 60, across those replicas.</p><p>When CPU utilization falls below 60%, then the autoscaler will adjust the replica count of the targeted deployment down; when it goes above 60%, replicas will be added:</p><pre class="programlisting"><span class="strong"><strong>hpa.yaml</strong></span> 
kind: HorizontalPodAutoscaler 
apiVersion: autoscaling/v2beta1 
metadata: 
  name: fib 
spec: 
  maxReplicas: 10 
  minReplicas: 1 
  scaleTargetRef: 
    apiVersion: app/v1 
    kind: Deployment 
    name: fib 
  metrics: 
  - type: Resource 
    resource: 
      name: cpu 
      targetAverageUtilization: 60 </pre><p>Create the autoscaler with <code class="literal">kubectl</code>:</p><pre class="programlisting"><span class="strong"><strong>kubectl apply -f hpa.yaml</strong></span></pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip68"></a>Note</h3><p>The <code class="literal">kubectl autoscale</code> command is a shortcut to create a <code class="literal">HorizontalPodAutoscaler</code>. Running <code class="literal">kubectl autoscale deployment fib --min=1 --max=10 --cpu-percent=60</code> would create an equivalent autoscaler.</p></div><p>Once you have created the Horizontal Pod Autoscaler, you can see a lot of interesting information about its <span>current</span><a id="id325759573" class="indexterm"></a> state with <code class="literal">kubectl describe</code>:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl describe hpa fib</strong></span>
<span class="strong"><strong>Name:              fib</strong></span><span class="strong"><strong>Namespace:         default</strong></span><span class="strong"><strong>CreationTimestamp: Sat, 15 Sep 2018 14:32:46 +0100</strong></span><span class="strong"><strong>Reference:         Deployment/fib</strong></span><span class="strong"><strong>Metrics:           ( current / target )</strong></span><span class="strong"><strong>resource cpu:    0% (1m) / 60%</strong></span><span class="strong"><strong>Min replicas:      1</strong></span><span class="strong"><strong>Max replicas:      10</strong></span><span class="strong"><strong>Deployment pods:   1 current / 1 desired</strong></span></pre><p>Now we have set up our Horizontal Pod Autoscaler, we should generate some load on the pods in our deployment to illustrate how it works. In this case, we are going to use the <code class="literal">ab</code> (Apache benchmark) tool to repeatedly ask our application to compute the thirtieth Fibonacci number:</p><pre class="programlisting"><span class="strong"><strong>load.yaml</strong></span>
apiVersion: batch/v1 
kind: Job 
metadata: 
  name: fib-load 
  labels: 
    app: fib 
    component: load 
spec: 
  template: 
    spec: 
      containers: 
      - name: fib-load 
        image: errm/ab 
        args: ["-n1000", "-c4", "fib/30"] 
      restartPolicy: OnFailure </pre><p>This job uses <code class="literal">ab</code> to make 1,000 requests to the endpoint (with a concurrency of 4). Submit the job to the cluster, then observe the state of the Horizontal Pod Autoscaler:</p><pre class="programlisting"><span class="strong"><strong>kubectl apply -f load.yaml</strong></span>
<span class="strong"><strong>watch kubectl describe hpa fib</strong></span></pre><p>Once the load job has started to make requests, the autoscaler will scale up the deployment in order to handle the load:</p><pre class="programlisting"><span class="strong"><strong>Name:                   fib</strong></span><span class="strong"><strong>Namespace:              default</strong></span><span class="strong"><strong>CreationTimestamp: Sat, 15 Sep 2018 14:32:46 +0100</strong></span><span class="strong"><strong>Reference:         Deployment/fib</strong></span><span class="strong"><strong>Metrics:           ( current / target )</strong></span><span class="strong"><strong>resource cpu:    100% (251m) / 60%</strong></span><span class="strong"><strong>Min replicas:      1</strong></span><span class="strong"><strong>Max replicas:      10</strong></span><span class="strong"><strong>Deployment pods:   2 current / 2 desired</strong></span></pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec86"></a>Autoscaling pods based on other metrics</h3></div></div></div><p>The metrics server provides APIs <span>that</span><a id="id325810320" class="indexterm"></a> the Horizontal Pod Autoscaler can use to gain information about the CPU and memory utilization of pods in the cluster.</p><p>It is possible to target a utilization percentage like we did for the CPU metric, or to target the absolute value as we have here for the memory metric:</p><pre class="programlisting"><span class="strong"><strong>hpa.yaml</strong></span> 
kind: HorizontalPodAutoscaler 
apiVersion: autoscaling/v2beta1 
metadata: 
  name: fib 
spec: 
  maxReplicas: 10 
  minReplicas: 1 
  scaleTargetRef: 
    apiVersion: app/v1 
    kind: Deployment 
    name: fib 
  metrics: 
  - type: Resource 
    resource: 
      name: memory 
      targetAverageValue: 20M </pre><p>The Horizonal Pod Autoscaler also allows us to scale on other metrics provided by more comprehensive metrics systems. Kubernetes allows for metrics APIs to be aggregated for custom and external metrics.</p><p>Custom metrics are metrics other than CPU and memory that are associated with a pod. You might for example use an adapter that allows you to use metrics that a system like Prometheus has collected from your pods.</p><p>This can be very beneficial if you have more detailed metrics available about the utilization of your application, for example, a forking web server that exposes a count of busy worker processes, or a queue processing application that exposes metrics about the number of items currently enqueued.</p><p>External metrics adapters provide information about resources that are not associated with any object within Kubernetes, for example, if you were using an external queuing system, such as the AWS SQS service.</p><p>On the whole, it is simpler if your applications can expose metrics about resources that they depend on that use an external metrics adapter, as it can be hard to limit access to particular metrics, whereas custom metrics are tied to a particular Pod, so Kubernetes can limit access to only those users and processes that need to use them.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec87"></a>Autoscaling the cluster</h3></div></div></div><p>The capabilities of Kubernetes Horizontal Pod Autoscaler allow us to add and remove pod replicas from our applications as their resource usage changes over time. However, this <span>makes</span><a id="id325810356" class="indexterm"></a> no difference to the capacity of our cluster. If our pod autoscaler is adding pods to handle an increase in load, then eventually we might run out of space in our cluster, and additional pods would fail to be scheduled. If there is a decrease in the load on our application and the pod autoscaler removes pods, then we are paying AWS for EC2 instances that will sit idle.</p><p>When we created our cluster in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>, we deployed the cluster nodes using an autoscaling group, so we should be able to use this to grow and shrink the cluster as the needs of the applications deployed to it change over time.</p><p>Autoscaling groups have built-in support for scaling the size of the cluster, based on the average CPU utilization of the instances. This, however, is not really suitable when dealing with a Kubernetes cluster because the workloads running on each node of our cluster might be quite different, so the average CPU utilization is not really a very good proxy for the free capacity of the cluster.</p><p>Thankfully, in order to schedule pods to nodes effectively, Kubernetes keeps track of the capacity of each node and the resources requested by each pod. By utilizing this information, we can automate scaling the cluster to match the size of the workload.</p><p>The Kubernetes autoscaler project provides a cluster autoscaler component for some of the main cloud providers, including AWS. The cluster autoscaler can be deployed to our cluster quite simply. As well as being able to add instances to our cluster, the cluster autoscaler is also able to drain the pods from and then terminate instances when the capacity of the cluster can be reduced.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl2sec88"></a>Deploying the cluster autoscaler</h3></div></div></div><p>Deploying the cluster autoscaler to <span>our</span><a id="id326108801" class="indexterm"></a> cluster is quite simple as it just requires a simple pod to be running. All we need for this is a simple Kubernetes deployment, just as we have used in previous chapters.</p><p>In order for the cluster autoscaler to update the desired capacity of our autoscaling group, we need to give it permissions via an IAM role. If you are using kube2iam, as we discussed in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>, we will be able to specify this role for the cluster autoscaler pod via an appropriate annotation:</p><pre class="programlisting"><span class="strong"><strong>cluster_autoscaler.tf</strong></span>
data "aws_iam_policy_document" "eks_node_assume_role_policy" { 
  statement { 
    actions = ["sts:AssumeRole"] 
    principals { 
      type = "AWS" 
      identifiers = ["${aws_iam_role.node.arn}"] 
    } 
  } 
} 
 
resource "aws_iam_role" "cluster-autoscaler" { 
  name = "EKSClusterAutoscaler" 
  assume_role_policy = "${data.aws_iam_policy_document.eks_node_assume_role_policy.json}" 
} 
 
 
data "aws_iam_policy_document" "autoscaler" { 
  statement { 
    actions = [ 
      "autoscaling:DescribeAutoScalingGroups", 
      "autoscaling:DescribeAutoScalingInstances", 
      "autoscaling:DescribeTags", 
      "autoscaling:SetDesiredCapacity", 
      "autoscaling:TerminateInstanceInAutoScalingGroup" 
    ] 
    resources = ["*"] 
  } 
} 
 
resource "aws_iam_role_policy" "cluster_autoscaler" { 
  name = "cluster-autoscaler" 
  role = "${aws_iam_role.cluster_autoscaler.id}" 
  policy = "${data.aws_iam_policy_document.autoscaler.json}" 
} </pre><p>In order to deploy the cluster autoscaler to our cluster, we will submit a deployment manifest using <code class="literal">kubectl</code>, in a similar way to how we deployed kube2iam in <a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>. We will use Terraform's templating system to produce the manifest.</p><p>We create a service account that is used by the autoscaler to connect to the Kubernetes API:</p><pre class="programlisting"><span class="strong"><strong>cluster_autoscaler.tpl</strong></span>
--- 
apiVersion: v1 
kind: ServiceAccount 
metadata: 
  labels: 
    k8s-addon: cluster-autoscaler.addons.k8s.io 
    k8s-app: cluster-autoscaler 
  name: cluster-autoscaler 
  namespace: kube-system </pre><p>The cluster autoscaler needs to read information about the current resource usage of the cluster, and needs to be able to evict pods from nodes that need to be removed from the cluster and terminated. Basically, <code class="literal">cluster-autoscalerClusterRole</code> provides the required permissions for these actions. The following is the code continuation for <code class="literal">cluster_autoscaler.tpl</code>:</p><pre class="programlisting">--- 
apiVersion: rbac.authorization.k8s.io/v1beta1 
kind: ClusterRole 
metadata: 
  name: cluster-autoscaler 
  labels: 
    k8s-addon: cluster-autoscaler.addons.k8s.io 
    k8s-app: cluster-autoscaler 
rules: 
- apiGroups: [""] 
  resources: ["events","endpoints"] 
  verbs: ["create", "patch"] 
- apiGroups: [""] 
  resources: ["pods/eviction"] 
  verbs: ["create"] 
- apiGroups: [""] 
  resources: ["pods/status"] 
  verbs: ["update"] 
- apiGroups: [""] 
  resources: ["endpoints"] 
  resourceNames: ["cluster-autoscaler"] 
  verbs: ["get","update"] 
- apiGroups: [""] 
  resources: ["nodes"] 
  verbs: ["watch","list","get","update"] 
- apiGroups: [""] 
  resources: ["pods","services","replicationcontrollers","persistentvolumeclaims","persistentvolumes"] 
  verbs: ["watch","list","get"] 
- apiGroups: ["extensions"] 
  resources: ["replicasets","daemonsets"] 
  verbs: ["watch","list","get"] 
- apiGroups: ["policy"] 
  resources: ["poddisruptionbudgets"] 
  verbs: ["watch","list"] 
- apiGroups: ["apps"] 
  resources: ["statefulsets"] 
  verbs: ["watch","list","get"] 
- apiGroups: ["storage.k8s.io"] 
  resources: ["storageclasses"] 
  verbs: ["watch","list","get"] 
--- 
apiVersion: rbac.authorization.k8s.io/v1beta1 
kind: ClusterRoleBinding 
metadata: 
  name: cluster-autoscaler 
  labels: 
    k8s-addon: cluster-autoscaler.addons.k8s.io 
    k8s-app: cluster-autoscaler 
roleRef: 
  apiGroup: rbac.authorization.k8s.io 
  kind: ClusterRole 
  name: cluster-autoscaler 
subjects: 
  - kind: ServiceAccount 
    name: cluster-autoscaler 
    namespace: kube-system </pre><p>Note that <code class="literal">cluster-autoscaler</code> stores state information in a config map, so needs permissions to be able to <span>read</span><a id="id325772281" class="indexterm"></a> and write from it. This role allows that. The following is the code continuation for <code class="literal">cluster_autoscaler.tpl</code>:</p><pre class="programlisting">--- 
apiVersion: rbac.authorization.k8s.io/v1beta1 
kind: Role 
metadata: 
  name: cluster-autoscaler 
  namespace: kube-system 
  labels: 
    k8s-addon: cluster-autoscaler.addons.k8s.io 
    k8s-app: cluster-autoscaler 
rules: 
- apiGroups: [""] 
  resources: ["configmaps"] 
  verbs: ["create"] 
- apiGroups: [""] 
  resources: ["configmaps"] 
  resourceNames: ["cluster-autoscaler-status"] 
  verbs: ["delete","get","update"] 
--- 
apiVersion: rbac.authorization.k8s.io/v1beta1 
kind: RoleBinding 
metadata: 
  name: cluster-autoscaler 
  namespace: kube-system 
  labels: 
    k8s-addon: cluster-autoscaler.addons.k8s.io 
    k8s-app: cluster-autoscaler 
roleRef: 
  apiGroup: rbac.authorization.k8s.io 
  kind: Role 
  name: cluster-autoscaler 
subjects: 
  - kind: ServiceAccount 
    name: cluster-autoscaler 
    namespace: kube-system </pre><p>Finally, let's consider the manifest for the cluster autoscaler deployment itself. The cluster autoscaler pod contains a single container running the cluster autoscaler control loop. You will notice that we are passing some configuration to the cluster autoscaler as command-line arguments. Most importantly, the <code class="literal">--node-group-auto-discovery</code> flag allows the autoscaler to operate on autoscaling groups with the <code class="literal">kubernetes.io/cluster/&lt;cluster_name&gt;</code> tag that we set on our autoscaling group when we created the cluster in <span class="emphasis"><em></em></span><a class="link" href="#" linkend="ch07">Chapter 7</a>, <span class="emphasis"><em>A Production-Ready Cluster</em></span>. This is convenient because we don't have to explicitly configure the autoscaler with our cluster autoscaling group.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip69"></a>Note</h3><p>If your Kubernetes cluster has nodes in more than one availability zone and you are running pods that rely on being scheduled to a particular zone (for example, pods that are making use of EBS volumes), it is recommended to create an autoscaling group for each availability zone that you plan to use. If you use one autoscaling group that spans several zones, then the cluster autoscaler will be unable to specify the availability zone of the instances that it launches.</p></div><p>Here is the code continuation for <code class="literal">cluster_autoscaler.tpl</code>:</p><pre class="programlisting">--- 
apiVersion: extensions/v1beta1 
kind: Deployment 
metadata: 
  name: cluster-autoscaler 
  namespace: kube-system 
  labels: 
    app: cluster-autoscaler 
spec: 
  replicas: 1 
  selector: 
    matchLabels: 
      app: cluster-autoscaler 
  template: 
    metadata: 
      annotations: 
        iam.amazonaws.com/role: ${iam_role} 
      labels: 
        app: cluster-autoscaler 
    spec: 
      serviceAccountName: cluster-autoscaler 
      containers: 
        - image: k8s.gcr.io/cluster-autoscaler:v1.3.3 
          name: cluster-autoscaler 
          resources: 
            limits: 
              cpu: 100m 
              memory: 300Mi 
            requests: 
              cpu: 100m 
              memory: 300Mi 
          command: 
            - ./cluster-autoscaler 
            - --v=4 
            - --stderrthreshold=info 
            - --cloud-provider=aws 
            - --skip-nodes-with-local-storage=false 
            - --expander=least-waste 
            - --node-group-auto-discovery=asg:tag=kubernetes.io/cluster/${cluster_name} 
          env: 
            - name: AWS_REGION 
              value: ${aws_region} 
          volumeMounts: 
            - name: ssl-certs 
              mountPath: /etc/ssl/certs/ca-certificates.crt 
              readOnly: true 
          imagePullPolicy: "Always" 
      volumes: 
        - name: ssl-certs 
          hostPath: 
            path: "/etc/ssl/certs/ca-certificates.crt" </pre><p>Finally, we render the templated <span>manifest</span><a id="id325787558" class="indexterm"></a> by passing in the variables for the AWS region, cluster name and IAM role, and submitting the file to Kubernetes using <code class="literal">kubectl</code>:</p><p>Here is the code continuation for <code class="literal">cluster_autoscaler.tpl</code>:</p><pre class="programlisting">data "aws_region" "current" {} 
 
data "template_file" " cluster_autoscaler " { 
  template = "${file("${path.module}/cluster_autoscaler.tpl")}" 
 
  vars { 
    aws_region = "${data.aws_region.current.name}" 
    cluster_name = "${aws_eks_cluster.control_plane.name}" 
    iam_role = "${aws_iam_role.cluster_autoscaler.name}" 
  } 
} 
 
resource "null_resource" "cluster_autoscaler" { 
  trigers = { 
    manifest_sha1 = "${sha1("${data.template_file.cluster_autoscaler.rendered}")}" 
  } 
 
  provisioner "local-exec" { 
    command = "kubectl  
--kubeconfig=${local_file.kubeconfig.filename} apply -f -&lt;&lt;EOF\n${data.template_file.cluster_autoscaler.rendered}\nEOF" 
  } 
} </pre></div></div>