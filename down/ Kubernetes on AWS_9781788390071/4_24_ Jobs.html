<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec29"></a>Jobs</h2></div></div><hr /></div><p>The simplest use case for a job is to <span>launch</span><a id="id325162570" class="indexterm"></a> a single pod and ensure that it successfully runs to completion.</p><p>In our next example, we are going to use the Ruby programming language to compute and print out the first 100 Fibonacci numbers:</p><pre class="programlisting"><span class="strong"><strong>fib.yaml
</strong></span>apiVersion: batch/v1
kind: Job
metadata:
  name: fib
spec:
  template:
     metadata:
       name: fib
     spec:
       containers:
       - name: fib
         image: ruby:alpine
         command: ["ruby"]
         args:
         - -e
         - |
           a,b = 0,1
           100.times { puts b = (a = a+b) - b }
       restartPolicy: Never<span class="strong"><strong>
</strong></span></pre><p>Notice that the contents of <code class="literal">spec</code> and <code class="literal">template</code> are very similar to the specification we used to launch a pod directly. When we define a pod template for use in a job, we need to choose a <code class="literal">restartPolicy</code> of <code class="literal">Never</code> or <code class="literal">OnFailure</code>.</p><p>The reason for this is that the end goal of a job is to run the pod until it exits successfully. If the underlying pod is restarted when it exits successfully, the pod would continue to be restarted and the job would never complete.</p><p>Save the definition to a file and then submit it to the cluster using <code class="literal">kubectl create</code>:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl create -f fib.yaml</strong></span>
<span class="strong"><strong>job "fib" created</strong></span></pre><p>Once you have submitted a job to Kubernetes, you can check on its status with the <code class="literal">kubectl describe</code> command. It might take a little while for the Docker image to download and Kubernetes to launch the pod. Once the pod is running, you should see first <code class="literal">1 Running</code> and then <code class="literal">1 Succeeded</code> in the <code class="literal">Pods Statues</code> field:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl describe jobs/fib</strong></span>
<span class="strong"><strong>Name: fib</strong></span>
<span class="strong"><strong>Namespace: default</strong></span>
<span class="strong"><strong>Selector: controller-uid=278fa785-9b86-11e7-b25b-080027e071f1</strong></span>
<span class="strong"><strong>Labels: controller-uid=278fa785-9b86-11e7-b25b-080027e071f1</strong></span>
<span class="strong"><strong>  job-name=fib</strong></span>
<span class="strong"><strong>Annotations: &lt;none&gt;</strong></span>
<span class="strong"><strong>Parallelism: 1</strong></span>
<span class="strong"><strong>Completions: 1</strong></span>
<span class="strong"><strong>Start Time: Sun, 17 Sep 2017 09:56:54 +0100</strong></span>
<span class="strong"><strong>Pods Statuses: 0 Running / 1 Succeeded / 0 Failed</strong></span></pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip24"></a>Note</h3><p>When waiting for Kubernetes to take some action, repeatedly running <code class="literal">kubectl</code> to find out what is happening can get tedious. I like to use the <code class="literal">watch</code> command in conjunction with <code class="literal">kubectl</code>. To watch Kubernetes launch this job, I could run:<code class="literal"><span class="strong"><strong>$ watch kubectl describe jobs/fib</strong></span></code>
Most Linux distributions will include the watch command by default, or make it simple to install with a package manager. If you are on macOS, it's very simple to install with Homebrew:<code class="literal"><span class="strong"><strong>$ brew install watch</strong></span></code></p></div><p>We can use <code class="literal">kubectl logs</code> to view the output from our job. Notice how we don't need to know the name of the underlying pod(s); we can just refer to the job by name:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl logs job/fib</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>83621143489848422977</strong></span>
<span class="strong"><strong>135301852344706746049</strong></span>
<span class="strong"><strong>218922995834555169026</strong></span></pre><p>We can also look at the underlying pod that was created by this job with <code class="literal">kubectl get</code> by using the <code class="literal">job-name</code> label that Kubernetes adds to the pods for us:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get pods -l job-name=fib --show-all</strong></span>
<span class="strong"><strong>NAME READY STATUS RESTARTS AGE</strong></span>
<span class="strong"><strong>fib-dg4zh 0/1 Completed 0 1m</strong></span></pre><p></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip25"></a>Note</h3><p>The <code class="literal">--show-all</code> flag means that all pods are shown (even those that no longer have a running status).</p></div><p>Notice how Kubernetes created a unique name for our pod based on the job name. This is important because if the first pod to have been created failed in some way, Kubernetes would need to <span>launch</span><a id="id325872945" class="indexterm"></a> another pod based on the same pod specification.</p><p>One of the key advantages jobs have over launching a pod directly is that a job is able to handle not only errors caused by the underlying infrastructure that might cause a pod to be lost before it has completed, but also errors that occur at runtime.</p><p>To illustrate how this works, this job simulates a process that (mostly) fails with a non-zero exit status, but sometimes exits with a (successful) zero exit status. This Ruby program chooses a random integer from 0 to 10 and exits with it. So, on average, Kubernetes will have to run the pod 10 times before it exits successfully:</p><pre class="programlisting"><span class="strong"><strong>luck.yaml
</strong></span>apiVersion: batch/v1
kind: Job
metadata:
  name: luck
spec:
  template:
    metadata:
      name: luck
    spec:
      containers:
      - name: luck
      image: ruby:alpine
      command: ["ruby"]
      args: ["-e", "exit rand(10)"]
restartPolicy: Never</pre><p>As before, submit the job to your cluster with <code class="literal">kubectl</code>:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl create -f luck.yaml</strong></span>
<span class="strong"><strong>job "luck" created</strong></span></pre><p>Unless you are very lucky, when you inspect the job, you should see that Kubernetes has to launch a number of pods before one exited with 0 status:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/7a3ce34b-0836-4a44-8300-c5c50f65f12b.png" /></div><p>Inspecting the pods launched by the luck job using the Kubernetes dashboard</p><p>In this example, the pod spec has a <code class="literal">restartPolicy</code> of <code class="literal">Never</code>. This means that when the pod exits with a non-zero exit status, the pod is marked as terminated and the job controller launches another pod. It is also possible to run jobs with a <code class="literal">restartPolicy</code> of <code class="literal">OnFailure</code>.</p><p>Try editing <code class="literal">luck.yaml</code> to make this change. Remove the first version of the <code class="literal">luck</code> job and submit your new version:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl delete jobs/luck</strong></span>
<span class="strong"><strong>job "luck" deleted</strong></span>
<span class="strong"><strong>$ kubectl create -f luck.yaml</strong></span>
<span class="strong"><strong>job "luck" created</strong></span></pre><p>This time, you should notice <span>that</span><a id="id325887140" class="indexterm"></a> instead of quickly launching new pods until one exits successfully, Kubernetes restarts one pod until it is successful. You will notice that this takes quite a bit longer, because when Kubernetes restarts a pod locally with an exponential back-off, this behavior is useful if a failure was caused by an underlying resource that is overloaded or unavailable. You might notice the pod in a status of <code class="literal">CrashLoopBackoff</code> while Kubernetes is waiting to restart the pod:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get pods -l job-name=luck -a</strong></span>
<span class="strong"><strong>NAME READY STATUS RESTARTS AGE</strong></span>
<span class="strong"><strong>luck-0kptd 0/1 Completed 5 3m</strong></span></pre><p>Allowing the job controller to recreate a new pod each time it terminates in error ensures that the new pod is run in a new pristine environment and causes the job resource to retain a record of each execution attempt. For this reason, it is usually best not to utilize a pod restart policy in conjunction with a job, unless you have to deal with pods that regularly fail or if you want to retain the execution environment between attempts.</p></div>