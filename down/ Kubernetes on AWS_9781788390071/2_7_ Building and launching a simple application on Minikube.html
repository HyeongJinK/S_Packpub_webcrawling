<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec14"></a>Building and launching a simple application on Minikube</h2></div></div><hr /></div><p>Let's take our first <span>steps</span><a id="id325750937" class="indexterm"></a> to building a <span>simple</span><a id="id325750946" class="indexterm"></a> application on our local minikube cluster and getting it to run.</p><p>The first thing we need to do is build a container image for our application. The simplest way to do this is to create a Dockerfile and use the <code class="literal">docker build</code> command.</p><p>Use your favorite text editor to create a file called Dockerfile with the following content:</p><pre class="programlisting"><span class="strong"><strong>Dockerfile</strong></span> 
FROM nginx:alpine 
RUN echo "&lt;h1&gt;Hello World&lt;/h1&gt;" &gt; /usr/share/nginx/html/index.html </pre><p>To build the application, first ensure your Docker client is pointing to the Docker instance inside the Minikube VM by running:</p><pre class="programlisting"><span class="strong"><strong>eval $(minikube docker-env)</strong></span></pre><p>Then use Docker to build the image. In this case, we are tagging the image <code class="literal">hello</code>, but you could use any tag you wanted:</p><pre class="programlisting"><span class="strong"><strong>docker build -t hello:v1 .</strong></span></pre><p>Kubectl has a <code class="literal">run</code> command that we can use to quickly get a pod running on the Kubernetes cluster. In the background, it creates a Kubernetes deployment resource that ensures that a single instance of our <code class="literal">hello</code> container runs within a pod (we will learn more about this later):</p><pre class="programlisting"><span class="strong"><strong>kubectl run hello --image=hello:v1 --image-pull-policy=Never \</strong></span><span class="strong"><strong>--port=80</strong></span></pre><p>We are setting <code class="literal">--image-pull-policy=Never</code> here to ensure that Kubernetes uses the local image that we just built, rather than the default of pulling the image from a remote repository, such as Docker Hub.</p><p>We can check that our container has started correctly with <code class="literal">kubectl get</code>:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get pods</strong></span><span class="strong"><strong>NAME                     READY     STATUS    RESTARTS   AGE</strong></span><span class="strong"><strong>hello-2033763697-9g7cm   1/1       Running   0          1m</strong></span></pre><p>Our hello world application was simple enough to set up, but we need some way to access it for our experiment to be considered a success. We can use the <code class="literal">kubectl expose</code> command to create a service pointing to the pod in the deployment that was just created:</p><pre class="programlisting"><span class="strong"><strong>kubectl expose deployment/hello --port=80 --type="NodePort" \</strong></span><span class="strong"><strong>--name=hello </strong></span></pre><p>We have set the service type to NodePort in this case so that Kubernetes will expose a random port on the Minikube VM so that we can access our service easily. In <a class="link" href="#" linkend="ch06"><span>Chapter 6</span></a>, <span class="emphasis"><em>Planning for Production</em></span>, we will discuss exposing our applications to the outside world in more detail.</p><p>When you create a service of the <code class="literal">NodePort</code> type, Kubernetes automatically allocates us a port number for the service to be exposed on. In a multi-node cluster, this port will be opened on every node in the cluster. Since we only have a single node, working out how to access the cluster is a little bit simpler.</p><p>First, we need to discover the IP address of the Minikube VM. Luckily, there is a simple command we can run to get this information:</p><pre class="programlisting"><span class="strong"><strong>minikube ip</strong></span><span class="strong"><strong>192.168.99.100</strong></span></pre><p>It is more than likely that when the <code class="literal">minikube</code> VM started on your machine, it was allocated a different IP address from my own, so make a note of the IP address on your own machine.</p><p>Next, in order to discover the port that Kubernetes has exposed our service on, let's use <code class="literal">kubectl get</code> on our service:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get svc/hello</strong></span><span class="strong"><strong>NAME      CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE</strong></span><span class="strong"><strong>hello     10.0.0.104   &lt;nodes&gt;       80:32286/TCP   26m</strong></span></pre><p>You can see, in this case, that Kubernetes has exposed port <code class="literal">80</code> on our container as port <code class="literal">32286</code> on our node.</p><p>You should now be able to construct a URL that you can visit in your browser to test out the application. In my case, it is <code class="literal"><span>http://192.168.99.100:32286</span></code>:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/151bbf4f-5e9e-4bc5-8fee-3241c37ca50e.png" /></div><p>You should be able to visit your application with your web browser</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec18"></a>What just happened?</h3></div></div></div><p>So far, we have managed to build, run, and expose a single container on our Minikube instance. If you are used to using Docker to perform similar tasks, you might notice that although the <span>steps</span><a id="id325753388" class="indexterm"></a> we took were quite simple, there is a little more complexity in getting a simple hello world application like this up and running.</p><p>A lot of this has to do with the scope of the tool. Docker provides a simple and easy to use workflow for building and running single containers on a single machine, whereas Kubernetes is, of course, first and foremost a tool designed to manage many containers running across multiple nodes.</p><p>In order to understand some of the complexity that Kubernetes introduces, even in this simple example, we are going to explore the ways that Kubernetes is working behind the scenes to keep our application running reliably.</p><p>When we executed <code class="literal">kubectl run</code>, Kubernetes created a new sort of resource: a deployment. A deployment is a higher level abstraction that manages the underlying <code class="literal">ReplicaSet</code> on our behalf. The advantage of this is that if we want to make changes to our application, Kubernetes can manage rolling out a new configuration to our running application:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/d9152ce6-6ee5-4003-a52a-64ad56ad045b.png" /></div><p>The architecture of our simple Hello application</p><p>When we executed kubectl expose, Kubernetes created a service with a label selector that matched the pods under management by the deployment that we referenced.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch02lvl3sec7"></a>Rolling out changes</h4></div></div></div><p>One of the key functions of <span>the</span><a id="id325759524" class="indexterm"></a> deployment resource is to manage the roll-out of new versions of an application. Let's look at an example of how you would do this.</p><p>First, let's update the Dockerfile for version 2 of our <code class="literal">Hello World</code> application:</p><pre class="programlisting"><span class="strong"><strong>Dockerfile</strong></span> 
FROM nginx:alpine 
COPY index.html /usr/share/nginx/html/index.html </pre><p>You may have noticed that the HTML we used for version 1 was a little incomplete, so we are using the <code class="literal">COPY</code> command in the <code class="literal">Dockerfile</code> to copy an <code class="literal">index.html</code> file into our container image.</p><p>Use your text editor to create an <code class="literal">index.html</code> file that will be visually distinguishable from version 1. I took the opportunity to add a proper DOCTYPE, and, of course, to use CSS to re-implement the sadly now defunct blink tag! Since this isn't a book about web design, feel free to make whatever changes you want:</p><pre class="programlisting"><span class="strong"><strong>index.html</strong></span> 
&lt;!DOCTYPE html&gt; 
&lt;html&gt; 
  &lt;head&gt; 
    &lt;style&gt; 
      blink { animation: blink 1s steps(1) infinite; } 
      @keyframes blink { 50% { color: transparent; } } 
    &lt;/style&gt; 
    &lt;title&gt;Hello World&lt;/title&gt; 
  &lt;/head&gt; 
  &lt;body&gt; 
    &lt;h1&gt;Hello &lt;blink&gt;1994&lt;/blink&gt;&lt;/h1&gt; 
  &lt;/body&gt; 
&lt;/html&gt; </pre><p>Next, use Docker to build your version 2 image:</p><pre class="programlisting"><span class="strong"><strong>docker build -t hello:v2 .</strong></span></pre><p>Now we can use kubectl to update the deployment resource to use the new image:</p><pre class="programlisting"><span class="strong"><strong>kubectl set image deployment/hello hello=hello:v2</strong></span></pre><p>Wait a few moments for Kubernetes to launch the new pod, and then refresh your browser; you should see your changes.</p><p>When we update a deployment, behind the scenes Kubernetes creates a new replica set with the new configuration and handles rolling the new version out. Kubernetes also keeps track of the different configurations you have deployed. This also gives you the ability to roll a deployment back if required:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl rollout undo deployment/hello</strong></span><span class="strong"><strong>deployment "hello" rolled back</strong></span></pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch02lvl3sec8"></a>Resilience and scaling</h4></div></div></div><p>Being able to provide services that are resilient to errors and issues in the underlying infrastructure is one of <span>the</span><a id="id325759718" class="indexterm"></a> key reasons why we might want to use Kubernetes to deploy our containerized applications.</p><p>We are <span>going</span><a id="id325761957" class="indexterm"></a> to experiment with our <code class="literal">Hello World</code> deployment to discover how Kubernetes can deal with problems like these.</p><p>The first experiment is to see what happens when we deliberately remove the pod where our <code class="literal">hello</code> container is running.</p><p>To do this, we need to find the name of this pod, which we can do with the <code class="literal">kubectl get</code> command:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get pods</strong></span><span class="strong"><strong>NAME                     READY     STATUS    RESTARTS   AGE</strong></span><span class="strong"><strong>hello-2473888519-jc6km   1/1       Running   0          7m</strong></span></pre><p>On our Minikube cluster, we currently only have one pod running from the one deployment that we have created so far. Once you start to deploy more applications, the output from commands such as kubectl get can get lengthier. We can use the <code class="literal">-l</code> flag to pass a label selector to filter down the results. In this case, we would use <code class="literal">kubectl get pods -l run=hello</code> to show just the pods where the run label is set to <code class="literal">hello</code>.</p><p>Then we can use the <code class="literal">kubectl delete</code> command to remove the resource. Deleting a pod also terminates the processes running inside of the constituent containers, effectively cleaning up the Docker environment on our node:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl delete pod/hello-2473888519-jc6km</strong></span><span class="strong"><strong>pod "hello-2473888519-jc6km" delete</strong></span></pre><p>If we then rerun the <code class="literal">get pods</code> command, you should notice that the pod we deleted has been replaced by a new one with a new name:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get pod</strong></span><span class="strong"><strong>NAME                     READY     STATUS    RESTARTS   AGE</strong></span><span class="strong"><strong>hello-2473888519-1d69q   1/1       Running   0          8s</strong></span></pre><p>In Kubernetes, we can use replica sets (and deployments) to ensure that pod instances continue to run in our cluster despite unexpected events, be they a failed server, or a fat-fingered admin deleting our pod (as has happened in this case).</p><p>You should begin to understand as part of this exercise that a pod is an ephemeral entity. When it is deleted or the node it is running on fails, it is gone forever. Kubernetes ensures that the missing pod is replaced by another, created in its image from the same template. This means that any state that is stored on the local filesystem or in memory, the identity of the pod itself is also lost when a pod inevitably fails and is replaced.</p><p>This makes pods well-suited to some kinds of workload where it is not necessary for a state to be stored locally across runs, such as web applications and most batch jobs. If you are building new applications that you intend to deploy to Kubernetes, you will make them easier to manage by delegating the storage of state to an external store, such as a database or a service like Amazon S3.</p><p>We will explore features in Kubernetes that allow us to deploy applications that need to store local state and/or maintain a stable identity in <span class="emphasis"><em>Chapter 9</em></span>, <span class="emphasis"><em>Storing State</em></span>.</p><p>One problem you may have noticed when we were testing the abilities of Kubernetes to replace a pod that was removed is that, for a short time, our service became unavailable. For a simple example service running on a single node cluster such as this, perhaps this is not the end of the world. But we do really need a way for our applications to run in a way that minimizes even momentary downtime.</p><p>The answer is, of course, to ask Kubernetes to run multiple pin stances for our application, so even if one is lost, a second can take the slack:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl scale deployment/hello --replicas=2</strong></span><span class="strong"><strong>deployment "hello" scaled</strong></span></pre><p>If we now check the pods running, we can see a second <code class="literal">hello</code> pod has joined the party:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl get pods</strong></span><span class="strong"><strong>NAME                     READY     STATUS    RESTARTS   AGE</strong></span><span class="strong"><strong>hello-2473888519-10p63   1/1       Running   0          1m</strong></span><span class="strong"><strong>hello-2473888519-1d69q   1/1       Running   0          25m</strong></span></pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec19"></a>Using the dashboard</h3></div></div></div><p>The Kubernetes dashboard is a <span>web</span><a id="id326464472" class="indexterm"></a> application that runs within your Kubernetes cluster and offers an alternative, more graphical solution, for exploring and monitoring your cluster.</p><p>Minikube automatically installs the dashboard and provides a command that will open it in your web browser:</p><pre class="programlisting"><span class="strong"><strong>$ minikube dashboard</strong></span></pre><div class="mediaobject"><img src="/graphics/9781788390071/graphics/e7227df4-f5f8-4fff-a592-154c6d0f0ca1.png" /></div><p>The Kubernetes dashboard</p><p>The dashboard interface is very easy to use, and you should begin to notice more than a few similarities with the way that <code class="literal">kubectl</code> works, since they both allow you to interact with the same underlying API.</p><p>The Navigation bar on the left of the screen gives access to screens showing a list of resources of a particular kind. This is similar to the functionality provided by <code class="literal">the</code><code class="literal">kubectl get</code> command:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/4413e236-f1a4-4126-b4ab-8d945f0ed24b.png" /></div><p>Using the Kubernetes dashboard to list currently running pods</p><p>In this view, we can click on the icon that looks like a stack of papers in order to open a log viewer to view the logs captured from standard out in each container in the pod:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/27953fa5-f605-4452-88d3-8acebd095e76.png" /></div><p>Viewing container logs in the Kubernetes dashboard</p><p>Other resources have other options appropriate to their function. For example, Deployments and Replica Sets have a dialog to scale the number of pods up or down.</p><p>By clicking on the name of a particular resource, we get a view that shows similar information to <code class="literal">kubectl describe</code>:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/4ede7f9f-131b-4cd7-a7bf-5b7dc6b15073.png" /></div><p>The detail screen provides us quite a lot of information about pods or other resources in Kubernetes:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/eef31bca-9fd1-4643-a6b9-5f33d0ad4fff.png" /></div><p>As well as an overview of the configuration <span>and</span><a id="id325741585" class="indexterm"></a> settings for the resources, if you scroll to the bottom of the page, you should be able to see a feed of events. This is very useful if you are trying to debug issues and will highlight any errors or problems with a running resource.</p><p>For pods, we get a number of other options for managing and inspecting the container. For example, opening an in-browser terminal by clicking the exec button:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/85e5b995-e4eb-45b4-ba3e-1a7b45a03981.png" /></div><p>Debugging a container using an interactive shell in the Kubernetes dashboard</p><p>Currently<span class="strong"><strong>,</strong></span> for this feature to work properly<span class="strong"><strong>,</strong></span> your container needs to have <code class="literal">/bin/bash</code> available. This might change in future versions of the dashboard, but for now, to make this work add <code class="literal">RUN apk add --no-cache bash</code> to your <code class="literal">Dockerfile</code> and deploy the newly built image.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec20"></a>Configuration as code</h3></div></div></div><p>Throughout this chapter, we have interacted with Kubernetes by using commands provided by <code class="literal">kubectl</code> or the Kubernetes dashboard. In practice, I find that these tools are useful <span>for</span><a id="id326057540" class="indexterm"></a> quickly getting a container running in a cluster. When the configuration becomes more complex or I want to be able to deploy the same application to multiple environments, having a configuration file that I can submit to the cluster, and store in a version control system, is very useful.</p><p><code class="literal">kubectl</code> and indeed the Kubernetes dashboard, will allow us to submit YAML or JSON formatted configurations for the resources we want to create on the cluster. We are going to take another look at how we would deploy the same <code class="literal">Hello World</code> application using YAML-formatted files rather than commands such as <code class="literal">kubectl run</code>.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip12"></a>Note</h3><p>This Kubernetes configuration is often referred to as a Manifest, and the YAML-or-JSON formatted files as Manifest files.</p></div><p>Let's start by removing the configuration we created with <code class="literal">kubectl</code> so we have a clean state to reproduce the same configuration:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl delete deployment/hello svc/hello</strong></span><span class="strong"><strong>deployment "hello" deleted</strong></span><span class="strong"><strong>service "hello" deleted</strong></span></pre><p>Let's define a deployment for version 1 of the <code class="literal">hello</code> service:</p><pre class="programlisting"><span class="strong"><strong>deployment.yaml</strong></span> 
apiVersion: apps/v1
kind: Deployment 
metadata: 
  name: hello 
spec: 
  replicas: 2 
  template: 
    metadata: 
      labels: 
        app: hello 
    spec: 
      containers: 
      - name: hello 
        image: hello:v1 
        ports: 
        - containerPort: 80 </pre><p>Now we can use <code class="literal">kubectl</code> to submit the deployment to Kubernetes:</p><pre class="programlisting"><span class="strong"><strong>$kubectl apply -f deployment.yaml</strong></span><span class="strong"><strong>deployment "hello" created</strong></span></pre><p>Next, let's do the same for a service:</p><pre class="programlisting"><span class="strong"><strong>service.yaml</strong></span> 
kind: Service 
apiVersion: v1 
metadata: 
  name: hello 
spec: 
  selector: 
    app: hello 
  type: NodePort 
  ports: 
  - protocol: TCP 
    port: 80 
    targetPort: 80 </pre><p>Submit the definition to Kubernetes with <code class="literal">kubectl</code>:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl apply -f service.yaml</strong></span><span class="strong"><strong>service "hello" created</strong></span></pre><p>You can see that while we have sacrificed the speed and simplicity of just running a command to create a deployment, by explicitly specifying the resources we want to create, we gain greater control over exactly how our pods are configured, and we now have this definition in a form that we can check into version control and reliably update.</p><p>When it comes to updating a resource, we can make an edit to the file and then use the <code class="literal">kubectl apply</code> command to <span>update</span><a id="id326184314" class="indexterm"></a> the resource. <code class="literal">kubectl</code> detects that we are updating an existing resource and updates it to match our configuration. Try editing the image tag in <code class="literal">deployment.yaml</code> and then re submitting it to the cluster:</p><pre class="programlisting"><span class="strong"><strong>$ kubectl apply -f deployment.yaml</strong></span><span class="strong"><strong>deployment "hello" configured</strong></span></pre><p>If we are just making changes to the resource on our local cluster, we might just want to quickly change something without having to edit the file at all. Firstly, as in our previous example, you can use <code class="literal">kubectl set</code> to update a property. Kubernetes doesn't really care how we created the resource, so everything we did previously is still valid. The other method of making a quick change is with the <code class="literal">kubectl edit</code> command. Assuming you have the <code class="literal">$EDITOR</code> environment variable set up correctly with your favorite text editor, you should be able to open YAML for a resource, edit it, and then save while <code class="literal">kubectl</code> seamlessly updates the resource for you.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec21"></a>Troubleshooting Minikube</h3></div></div></div><p>One common problem that you <span>might</span><a id="id326184361" class="indexterm"></a> run into when trying to use Minikube is that you might not be able to access the VM because its network overlaps with another network configured on your machine. This can often happen if you are using a corporate VPN, or you connect to another network that configures routes for the <code class="literal">192.168.99.1/24</code> IP address range used by Minikube by default.</p><p>It is simple to start Minikube with an alternative CIDR to be used for the VM. You can choose any private range that you want to use; just check that it won't overlap with other services on your local network:</p><pre class="programlisting"><span class="strong"><strong>$ minikube start --host-only-cidr=172.16.0.1/24</strong></span></pre></div></div>