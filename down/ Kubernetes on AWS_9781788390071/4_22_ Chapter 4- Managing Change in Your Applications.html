<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch04"></a>Chapter 4. Managing Change in Your Applications</h2></div></div></div><p>In <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Start Your Engines</em></span>, we took a first look at running an application on Kubernetes using deployments. In this chapter, we are going to go into depth with tools that Kubernetes provides to manage the pods that we run on your cluster.</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">We will learn how to ensure that batch tasks are successfully completed by using the <code class="literal">Job</code> resource</li><li style="list-style-type: disc">We will learn how to run jobs at scheduled intervals with the <code class="literal">CronJob</code> resource</li><li style="list-style-type: disc">Finally, we will learn how to use deployments to keep long-running applications running indefinitely, and to update them or their configuration when changes need to be made</li></ul></div><p>We will look at how we can launch pods in different ways with Kubernetes, depending on the workloads we are running.</p><p>You will learn a lot more about how to use the deployment resource to control the way Kubernetes rolls out changes to long-running applications. You will discover the ways you can use Kubernetes to perform common deploy patterns, such as blue-green and canary deployments.</p><p>By design, pods are not intended to be durable in any way. As we have discussed previously, there is a whole raft of conditions that can cause the life of a pod to be terminated. They include:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>The failure of an underlying node</strong></span>: Perhaps caused by some unexpected event, such as a hardware failure. Or perhaps by design; for example in a cluster utilizing spot priced instances nodes can be terminated without warning if demand for instances increases.</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Pod evictions initiated by the scheduler</strong></span>: The scheduler can initiate pod evictions when it needs to in order to optimize the usage of resources on the cluster. This could be because some processes have a higher priority than others, or just to optimize bin packing on the cluster.</li><li style="list-style-type: disc">Pods manually removed by the user.</li><li style="list-style-type: disc">Pods removed due to planned maintenance; for example, by using the <code class="literal">kubectl drain</code> command.</li><li style="list-style-type: disc">The node is no longer visible to the cluster due to a network partition.</li><li style="list-style-type: disc">Pods removed from the node in preparation of a scaling down action.</li></ul></div><p>So, if the design of Kubernetes expects pods to ephemeral, how can we deploy reliable applications? Surely, we need some way to run our programs without fail? Thankfully, this is not exactly the case. The important part of this design is that it accurately models the wide range of issues that can occur in the system due to the underlying hardware and software, and as a result of management processes. Rather than trying to make the primitive building block (the pod) resilient to failures itself, Kubernetes provides a number of controllers that we, as users, can interact with directly to build resilient services. These controllers handle creating replacements for pods that have been lost for any number of reasons.</p><p>These controllers fall into four groups, and our choice really depends on the type of workload we want to run:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">For processes that we expect to end, such as batch jobs or other finite processes, Kubernetes provides the job abstraction. Jobs ensure that a pod runs to completion at least once.</li><li style="list-style-type: disc">For pods that we expect to be long-running, such as a web server or a background processing worker, Kubernetes provides deployments and the lower level ReplicationController or ReplicaSet.</li><li style="list-style-type: disc">For pods that we want to run on all machines (or a subset of them), Kubernetes provides DaemonSet. DaemonSet are typically used to provide machine-specific services that form part of your platform, such as log management or monitoring agents, and commonly to deploy per node components of an overlay network.</li><li style="list-style-type: disc">For groups of pods where each pod requires a stable identity or to access persistent storage, Kubernetes provides <code class="literal">StatefulSets</code>. (We will cover <code class="literal">StatefulSets</code> in <a class="link" href="#" linkend="ch09">Chapter 9</a>, <span class="emphasis"><em>Storing State</em></span>.)</li></ul></div><p>If you think back to what we learned about the architecture of Kubernetes in <a class="link" href="#" linkend="ch01">Chapter 1</a>, <span class="emphasis"><em>Google's Infrastructure for the Rest of Us</em></span>, it is important to remember that the controller manager (the Kubernetes micro service that runs all these controllers) is a separate and distinct process from the scheduler. The core lower-level parts of Kubernetes, such as the scheduler and the kubelet, only know about pods, whereas the higher-level controllers don't need to understand any of the details of actually scheduling and running pods on nodes. They just make a request to the API server for a pod to be created and the lower-level machinery ensures that they are scheduled and run correctly.</p><p>In this chapter, we are going to walk through the important features and configuration options that jobs, deployments, and DaemonSet provide us. By working through some examples, you will start to get a feel for when to use each resource to deploy your applications. You should take your time to understand what each controller is doing and why you would want to use it.</p><p>Deploying software to a distributed environment can be a little bit unusual at first, because a lot of assumptions you might have made about the way that your software runs when deploying it to a single machine might not work in a distributed system.</p><p>Kubernetes does a great job of making it possible to deploy most software without any modifications at all. I like to think that Kubernetes lets us trade a little simplicity for a lot of reliability.</p></div>