<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec47"></a>Observability</h2></div></div><hr /></div><p>Observability is <span>shown</span><a id="id325162571" class="indexterm"></a> in the following diagram:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/0ef20a46-df0b-4bc2-9edf-1b215b7ada37.png" /></div><p>Being able to monitor and debug a cluster is one of the most important points to bear in mind when designing a cluster for production. Luckily, there are a number of solutions for managing logs and metrics that have very good support for Kubernetes.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec68"></a>Logging</h3></div></div></div><p>Whenever you want to know <span>what</span><a id="id325751178" class="indexterm"></a> your applications are doing, the first thing most operators will think to do is to look at the logs generated by the application.</p><p>Logs are simple to understand, and they don't require any special tools to produce, as your application probably already supports some sort of the logging already.</p><p>Out of the box, Kubernetes allows you to view and tail the logs that your application is writing to standard out and standard errors. Using the <code class="literal">kubectl logs</code> command should be familiar to you if you have used the <code class="literal">docker logs</code> command on your own machine or on a server.</p><p>It is more convenient than logging into each node to view the logs generated by a particular container. As well as viewing the logs from a particular pod, <code class="literal">kubectl logs</code> can show the logs from all the pods matching a particular label expression.</p><p>If you need to search the logs generated by your application for a particular event, or if you need to see the logs generated at a particular time in the past, then you need to consider deploying a solution to aggregate and manage your logs.</p><p>The most widely used <span>tool</span><a id="id325751212" class="indexterm"></a> to implement this function is <span class="strong"><strong>Fluentd</strong></span>. Fluentd is a very flexible tool that can be used to collect logs from a wide variety of sources and then push them to one or more destinations. If your organization already maintains or uses a third-party tool to aggregate application logs, you will almost certainly find a way to configure Fluentd to store the application logs from applications running on Kubernetes in your chosen tool. Members of the Fluentd team, and the <span>wider</span><a id="id325751223" class="indexterm"></a> community, maintain over 800 different plugins that support many different inputs, outputs, and filtering options.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note52"></a>Note</h3><p>As Fluentd is built upon the Ruby programming language, its plugins are distributed using the Rubygems package system. By convention, all Fluentd plugins have a name beginning with <span class="strong"><strong>fluent-plugin</strong></span>, and all currently available plugins are listed here: <span><a class="ulink" href="https://www.fluentd.org/plugins/all" target="_blank">https://www.fluentd.org/plugins/all</a>. </span>Because some of these plugins are maintained by the wider community, it is worth making some initial tests of a plugin you plan to use. The quality of plugins can be variable, depending on the stage of development a particular plugin is in and how often it is maintained. You can install and manage Fluentd plugins using the <code class="literal">gem install</code> command or control the exact versions of Fluentd plugins using the <span class="strong"><strong>bundler</strong></span> tool. You can read more about installing plugins in your Fluentd installation here: <span><a class="ulink" href="https://docs.fluentd.org/v1.0/articles/plugin-management" target="_blank">https://docs.fluentd.org/v1.0/articles/plugin-management</a>.</span></p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec69"></a>Monitoring</h3></div></div></div><p>Looking at the log output of <span>your</span><a id="id325753369" class="indexterm"></a> application can be useful if you know there is an issue with an application and want to debug the cause. But it is much harder if you don't know where in your system a problem is occurring, or if you simply want to assess the health of a system.</p><p>Your logs are very flexible because your applications can write any information in an unstructured way to a logging endpoint. This in a large system can become quite overwhelming, and the amount of effort required to filter and analyze this output can become complex.</p><p>Monitoring or metrics collection takes a different approach. By defining measurements that reflect the performance and operation of your system, of Kubernetes, and your infrastructure, you can much more quickly answer questions about the health and performance of your system.</p><p>Collected metrics are also one of the most useful sources for automated alerting systems. They can warn members of your organization about abnormal behavior in your applications or infrastructure.</p><p>There are a number of commercial and open source tools that can be used to collect metrics and create alerts. The decision you take will most likely be influenced by your organization and the requirements you have.</p><p>As I have already said, trying to introduce too many new tools or processes to your organization at once can risk your success. In many cases, many monitoring tools already support integration with Kubernetes. If this is the case, it may be prudent to consider continuing to use the existing tools your organization is used to.</p><p>Whichever tools you choose to record metrics from your applications and from the cluster and the underlying infrastructure, you should think carefully about how to make it simple for members of your organization who are responsible for developing and deploying applications to surface their metrics. As part of planning your cluster, try writing the documentation for the procedure to expose metrics that should be followed by a developer deploying a new application to your cluster. You should aim to keep this process as simple as possible. If you need to automate steps of the process and provide default configuration values, you should do so in order to make the process simple. If the process of exporting new metrics from your applications is complex or requires lots of manual steps, then it becomes less likely that your organization's applications will expose them.</p><p>If the process is simple and friction-free, it becomes much simpler to instill a culture of monitoring by default. If, for example, you choose to use Prometheus, you might document the process like this:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">*</code> expose an endpoint <code class="literal">/metrics</code> on port <code class="literal">9102</code></li><li style="list-style-type: disc">Add the annotation <code class="literal">"prometheus.io/scrape": true</code> to your pod</li></ul></div><p>In this example, by configuring Prometheus with sensible defaults, exposing metrics from a pod becomes quick and simple for a developer. It is possible to expose more complex configuration for the way that Prometheus will scrape metrics, but by using well-known default values, it makes the setup process simpler and makes it simpler to include a standard Prometheus library in the application. Whatever system you choose to use to collect metrics, try to follow these principles wherever possible.</p><p>Collecting metrics directly from application pods and the infrastructure provides deep and rich information about how your application is behaving. This information is very useful when you need to know specifics about the application and can be very useful for pre-empting issues. For example, metrics about disk usage could be used to provide alerts that warn operators about a state that could lead to an application failure if not addressed.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec70"></a>Blackbox monitoring</h3></div></div></div><p>Whilst application-specific <span>metrics</span><a id="id325759526" class="indexterm"></a> provide deep insight that is useful for root cause analysis and pre-emptive alerting, Blackbox monitoring takes the opposite approach. By treating the application as a sealed entity, and exercising user-facing endpoints, you can surface the symptoms of a badly performing application. Blackbox monitoring can be implemented by using a tool such as the Prometheus Blackbox exporter. But another common pattern is to use a commercial service. The main advantage of this is that they typically allow you to probe applications from a number of locations, perhaps globally, truly exercising the full stack of infrastructure between your users and your applications.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec71"></a>Alerting</h3></div></div></div><p>Recording metrics about the <span>state</span><a id="id325759542" class="indexterm"></a> of the systems you are running on Kubernetes is the first stage of making your systems simple to observe. Once you have collected your metrics there are several ways to make the data you collect simple to act upon.</p><p>Most metrics collection tools offer some way to build graphs and dashboards for the metrics that are important to different members of your organization. For example, many users of Prometheus use Grafana to build dashboards to expose important metrics.</p><p>Whilst a dashboard is a good way to get an idea of how a particular system or business process is performing, there are aspects of your system that need a more proactive approach.</p><p>Any metrics-gathering system worth its salt will offer a way to emit alerts to members of your organization. However, when you gather metrics and whatever system you use to <span>send</span><a id="id325759560" class="indexterm"></a> alerts to your team, there are a few principles you should consider:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Alerts should be actionable</strong></span>: When promoting a metric from a graph or gauge on a dashboard to an alert, make sure you only send alerts for states that need immediate human intervention, not merely warnings or information. Warnings or informational alerts belong on your dashboards, not on your pager.</li><li style="list-style-type: disc"><span class="strong"><strong>Alerts should be used sparingly</strong></span>: Alerts interrupt people from whatever they are doing at that moment: working, resting, or, worst of all, sleeping. If a person receives too many alerts they can be a cause of stress, and quickly become less effective as alert fatigue sets in and they lose their attention-grabbing power. When designing an alerting mechanism, you should make provision to record how often members of your organization are interrupted by your alerting.</li></ul></div><p>Alerts should be directed—you should think about who should be responsible for a particular alert and direct it appropriately. Alerts can be directed to a number of systems, such as bug trackers, emails, chat systems, and even pager applications. It is important that the person who receives the most mission-critical alerts from your organization is in a position to take ownership and manage a response. Less important alerts might be assigned to a team or group in a bug tracking tool. If your organization makes use of a chat system, such as Slack, HipChat, or IRC, you might want to direct alerts for a particular application to a channel or room used by the team that develops or is responsible for the operation of that application. Just remember to ensure that volumes are kept to an acceptable level or your alerts will quickly come to be ignored by the people who need to know about them.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec72"></a>Tracing</h3></div></div></div><p>Tracing is the youngest <span>member</span><a id="id325759702" class="indexterm"></a> of the observability family and is thus often the last one an organization will choose to implement. The idea of a tracing system is to measure the time a single request takes to pass through your applications.</p><p>This might not expose any more interesting information than well-configured metrics for a monolithic application. But for larger-scale systems with a distributed, or <span class="emphasis"><em>microservices</em></span> architecture, where a single request can pass through tens or even hundreds of separate processes, tracing can help to pinpoint exactly when and where performance issues are occurring.</p><p>When implementing a system to collect tracing information from your applications, you have a number of options.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note53"></a>Note</h3><p>AWS's built-in solution for tracing includes X-Ray ships with support for Java, Go Node.js, Python, Ruby, and .NET applications. For these technologies, adding distributed tracing to your applications is simply a question of adding a library to your applications and configuring it correctly. <span><a class="ulink" href="https://aws.amazon.com/xray/" target="_blank">https://aws.amazon.com/xray/</a>.</span></p></div><p>Competing with AWS's solution is a number of tools that are designed to work together under the OpenTracing banner.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note54"></a>Note</h3><p>OpenTracing provides client libraries for nine languages that are compatible with nine different open source and commercial tools designed to collect trace data. Because of the open nature of OpenTracing, several application frameworks, and infrastructure components, are choosing to add support for its trace format. You can find out more about OpenTracing at <span><a class="ulink" href="http://opentracing.io" target="_blank">http://opentracing.io</a>.</span></p></div></div></div>