<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec10"></a>Why do I need a Kubernetes cluster?</h2></div></div><hr /></div><p>At its core, Kubernetes is a container scheduler, but it is a much richer and fully featured toolkit that has <span>many</span><a id="id326532689" class="indexterm"></a> other features. It is possible to extend and augment the functionality that Kubernetes provides, as products such as RedHat's OpenShift have done. Kubernetes also allows you to extend it's core functionality yourself by deploying add-on tools and services to your cluster.</p><p>Here are some of the key features that are built into Kubernetes:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Self-healing</strong></span>: Kubernetes controller-based orchestration ensures that containers are restarted <span>when</span><a id="id326532708" class="indexterm"></a> they fail, and rescheduled when the nodes they are running on fail. User-defined health checks allow users to make decisions about how and when to recover from failing services, and how to direct traffic when they do.</li><li style="list-style-type: disc"><span class="strong"><strong>Service discovery</strong></span>: Kubernetes is designed from the ground up to make service discovery simple <span>without</span><a id="id326532723" class="indexterm"></a> needing to make modifications to your applications. Each instance of your application gets its own IP address, and standard discovery mechanisms such as DNS and load balancing let your services communicate.</li><li style="list-style-type: disc"><span class="strong"><strong>Scaling</strong></span>: Kubernetes <span>makes</span><a id="id326532737" class="indexterm"></a> horizontal scaling possible at the push of a button, and also provides autoscaling facilities.</li><li style="list-style-type: disc"><span class="strong"><strong>Deployment orchestration</strong></span>: Kubernetes not only helps you to manage running applications, but has <span>tools</span><a id="id326532750" class="indexterm"></a> to roll out changes to your application and its configuration. Its flexibility allows you to build complex deployment patterns for yourself or to use one of a number of add-on tools.</li><li style="list-style-type: disc"><span class="strong"><strong>Storage management</strong></span>: Kubernetes has built-in support for managing the underlying <span>storage</span><a id="id326532764" class="indexterm"></a> technology on cloud providers, such as AWS Elastic Block Store volumes, as well as other standard networked storage tools, such as NFS.</li><li style="list-style-type: disc"><span class="strong"><strong>Cluster optimization</strong></span>: The Kubernetes <span>scheduler</span><a id="id326533086" class="indexterm"></a> automatically assigns your workloads to machines based on their requirements, allowing for better utilization of resources.</li><li style="list-style-type: disc"><span class="strong"><strong>Batch workloads</strong></span>: As well as long-running workloads, Kubernetes can also <span>manage</span><a id="id326533101" class="indexterm"></a> batch jobs, such as CI, batch processing, and cron jobs.</li></ul></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec3"></a>The roots of containers</h3></div></div></div><p>Ask the average user what a Docker container is and you might get any one of a dozen responses. You might be <span>told</span><a id="id326533116" class="indexterm"></a> something about lightweight virtual machines, or how it is that this hot new disruptive technology is going to revolutionize computing. In reality, Linux containers are certainly not a new idea, nor are they really all that much like a virtual machine.</p><p>Back in 1979, the <code class="literal">chroot syscall</code> was added to Version 7 of Unix. Calling chroot changes the apparent root directory for the current running process and its subprocesses. Running a program in a so-called chroot jail prevents it from accessing files outside of the specified directory tree.</p><p>One of the first uses of chroot was for testing of the BSD build system, something that is inherited by the package build systems of most of our modern Linux distributions, such as Debian, RedHat, and SuSE. By testing packages in a clean chrooted environment, build scripts can detect missing dependency information.</p><p>Chroot is also commonly used to sandbox untrusted processes-for example, shell processes on shared FTP or SFTP servers. Systems designed specifically with security in mind, such as the Postfix mail transfer agent, utilize chroot to isolate individual components of a pipeline in order to prevent a security issue in one component from rippling across the system.</p><p>Chroot is in fact a very simple isolation tool that was never intended to provide either security or control over anything other than the filesystem access of the processes. For its intended purpose of providing filesystem isolation for the likes of build tools, it is perfect. But for isolating applications in a production environment, we need a little more control.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec4"></a>Enter the container</h3></div></div></div><p>Trying to understand what a Linux <span>container</span><a id="id326533143" class="indexterm"></a> is can be a little difficult. As far as the Linux kernel is concerned, there is no such thing as a container. The kernel has a number of features that allow a process to be isolated, but these features are much lower-level and granular than what we now think of as a container. Container engines such as Docker use two main kernel features to isolate processes:</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec0"></a>Cgroups</h4></div></div></div><p><span class="strong"><strong>Cgroups</strong></span>, or control groups, provide an <span>interface</span><a id="id326533196" class="indexterm"></a> for controlling one or a group of processes, hence the name. They allow the control of several aspects of the group's use of resources. Resource utilization can be controlled using a limit (for example, by limiting memory usage). Cgroups also allow priorities to be set to give processes a greater or lesser share of time-bound resources, such as CPU utilization or I/O. Cgroups can also be used to snapshot (and restore) the state of running processes.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec1"></a>Namespaces</h4></div></div></div><p>The other part of the container <span>puzzle</span><a id="id326533211" class="indexterm"></a> is kernel namespaces. They operate in a manner that is somewhat similar to our use of the chroot syscall in that a container engine instructs the kernel to only allow the process a particular view of the system's resources.</p><p>Instead of just limiting access to the filesystem kernel, namespaces limit access to a number of different resources.</p><p>Each process can be assigned to a namespace and can then only see the resources connected to that namespace. The kinds of resources that can be namespaced are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Mount</strong></span>: Mount namespaces <span>control</span><a id="id326533234" class="indexterm"></a> access to the filesystem.</li><li style="list-style-type: disc"><span class="strong"><strong>Users</strong></span>: Each namespace has its own set of user IDs. User ID namespaces are nested, and thus a <span>user</span><a id="id326533248" class="indexterm"></a> in a higher-level namespace can be mapped to another in a lower level. This is what allows a container to run processes as root, without giving that process full permission to the root system.</li><li style="list-style-type: disc"><span class="strong"><strong>PID</strong></span>: The process ID namespace, like the users namespace, is nested. This is why the <span>host</span><a id="id325819227" class="indexterm"></a> can see the processes running inside of the containers when inspecting the process list on a system that is running containers. However, inside of the namespace the numbers are different; this means that the first process created inside a PID namespace, can be assigned PID 1, and can inherit zombie processes if required.</li><li style="list-style-type: disc"><span class="strong"><strong>Network</strong></span>: A network namespace <span>contains</span><a id="id325819241" class="indexterm"></a> one or more network interfaces. The namespace has its own private network resources, such as addresses, the routing table, and firewall.</li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note4"></a>Note</h3><p>There are also namespaces for IPC, UTS, and for the Cgroups interface itself.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec2"></a>Putting the pieces together</h4></div></div></div><p>It is the job of the container engine (software such as Docker or rkt) to put these pieces together and <span>make</span><a id="id325819261" class="indexterm"></a> something usable and understandable for us mere mortals.</p><p>While a system that directly exposed all of the details of Cgroups and namespaces would be very flexible, it would be far harder to understand and manage. Using a system such as Docker gives us a simple-to-understand abstraction over these low-level concepts, but necessarily makes many decisions for us about how these low-level concepts are used.</p><p>The fundamental breakthrough that Docker made over previous container technologies was to take great defaults for isolating a single process and combine them with an image format that allows developers to provide all the dependencies that the process requires to run correctly.</p><p>This is an incredibly good thing because it allows anyone to install Docker and quickly understand what is going on. It also makes this kind of Linux container the perfect building block to build larger and more complex systems, such as Kubernetes.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec5"></a>Here, schedule this...</h3></div></div></div><p>At its heart, Kubernetes is a system for scheduling work to a cluster of computers—a scheduler. But why <span>would</span><a id="id325819283" class="indexterm"></a> you want a scheduler?</p><p>If you think about your own systems, then you'll realize that you probably already have a scheduler, but unless you are already using something like Kubernetes, it might look very different.</p><p>Perhaps your scheduler is a team of people, with spreadsheets and documentation about which services run on each server in your data center. Perhaps that team of people looks at past traffic statistics to try and guess when there will be a heavy load in the future. Perhaps your scheduler relies on your users alerting members of your team at any time of the night if your applications stop functioning.</p><p>This book is about these problems, about how we can move on from a world of manual processes and making guesses about the future usage of our systems. It is about harnessing the skill and experience of the humans that administer the systems to encode our operational knowledge into systems that can make decisions about your running system second by second, seamlessly responding to crashed processes, failed machines, and increased load without any human intervention.</p><p>Kubernetes chooses to model its scheduler as a control loop so that the system is constantly discovering the current state of the cluster, comparing it to a desired state, and then taking actions to reduce the difference between the desired and the actual state. This is summarized in the following diagram:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/855bdf59-e7e4-415e-b826-97aa8a217a7b.png" /></div><p>A typical control loop</p><p>Being able to declare the state that we want the system to be in, and then have the system itself take the actions needed to manifest that desired state, is very powerful.</p><p>You may previously have used an imperative tool or a script to manage a system, or you may even have used a written playbook of the manual steps to take. This sort of approach is very much like a recipe: you take a set of actions one after another and hopefully end up in the state that you desire.</p><p>This works well when describing how to install and bootstrap a system for the first time, but when you need to run your script against a system that is already running, your logic needs to become more complicated as, for each stage in your recipe, you have to stop and check what needs to be done before you do it.</p><p>When using a declarative tool such as Kubernetes to manage your system, your configuration is simplified and becomes much easier to reason about. One important side effect of this approach is that Kubernetes will repair your configuration if an underlying failure causes it to drift away from your desired state.</p><p>By combining control loops and declarative configuration, Kubernetes allows you to tell it what to do for you, not how to do it. Kubernetes gives you, the operator, the role of the architect and Kubernetes takes the role of the builder. An architect provides a builder with detailed plans for a building, but doesn't need to explain how to build the walls with bricks and mortar. Your responsibility is to provide Kubernetes with a specification of your application and the resources it needs, but you don't need to worry about the details of exactly how and where it will run.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec6"></a>The basics of Kubernetes</h3></div></div></div><p>Let's begin our look at <span>Kubernetes</span><a id="id326532409" class="indexterm"></a> by looking at some of the fundamental concepts that most of Kubernetes is built upon. Getting a clear understanding of how these core building blocks fit together will serve you well as we explore the multitude of features and tools that comprise Kubernetes.</p><p>It can be a little confusing to use Kubernetes without a clear understanding of these core building blocks so, if you don't have any experience with Kubernetes, you should take your time to understand how these pieces fit together before moving on.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec3"></a>The pod</h4></div></div></div><p>Like a group of whales, or perhaps a pea pod, a <span>Kubernetes</span><a id="id326532426" class="indexterm"></a> pod is a group of linked containers. As the following diagram shows, a pod can be made up of one or more containers; often a pod might just be a single container:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/329a5a5c-5ac7-480b-9d38-bee436146f26.png" /></div><p>Pods are a logical grouping of one or more containers</p><p>Each pod that Kubernetes schedules is allocated its own unique IP address. The network namespace (and thus the pod's IP address) is shared by each container in the pod.</p><p>This means that it is convenient to deploy several containers together that closely collaborate over the network. For example, you might deploy a reverse proxy alongside a web application to add SSL or caching capabilities to an application that does not natively support them. In the following example, we achieve this by deploying a typical web application server-for example, Ruby on Rails—alongside a reverse proxy—for example, NGINX. This additional container provides further capabilities that might not be provided by the native application. This pattern of composing functionality together from smaller isolated containers means that you are able to reuse components more easily, and makes it simple to add additional functionality to existing tools. The setup is shown in the following diagram:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/6c63f930-16b1-4cbf-820c-ea9180290b0e.png" /></div><p>Providing additional capabilities by composing multiple containers</p><p>As well as sharing the network namespace, Kubernetes also allows very flexible sharing of volume mounts between any number of containers in a pod. This allows for a number of scenarios where several components may collaborate to perform a particular task.</p><p>In this example, we are using three containers that coordinate to serve a website built with a static-site generator using the NGINX webserver.</p><p>The first container uses Git to pull and update the source code from a remote Git repository. This repository is cloned into a volume that is shared with the second container. This second container uses the Jekyll framework to build the static files that will be served by our webserver. Jekyll watches the shared directory for changes on the filesystem and regenerates any files that need to be updated.</p><p>The directory that Jekyll writes the generated files to is shared with a container running NGINX that serves HTTP requests for our website, as shown in the following diagram:</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note5"></a>Note</h3><p>We are using Jekyll here as an example, but there are many tools you can use to build static websites, such as Hugo, Hexo, and Gatsby. Splitting your application into separate containers like this means that it is simple to upgrade a single component, or even try an alternative tool.</p></div><div class="mediaobject"><img src="/graphics/9781788390071/graphics/6da4112c-c11a-4649-b1c6-179c8fe1cb01.png" /></div><p>Another use for pods that share <span>volume</span><a id="id326532489" class="indexterm"></a> mounts is to support applications that communicate using Unix sockets, as shown in the following diagram. For example, an <span class="strong"><strong>extract transform load</strong></span> (<span class="strong"><strong>ETL</strong></span>) system could be modeled as several independent processes that communicate with UNIX sockets. This might be beneficial if you are able to make use of third-party tools for some or all of your pipeline, or reuse tools that you may have built for internal use in a variety of situations:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/ad48fdf0-cbb4-4097-a158-c0a82f9da6ad.png" /></div><p>In this example, a custom application designed to scrape data from webpages communicates with an instance of Fluentd over a Unix domain socket located in a shared volume. The pattern of using a third-party tool such as Fluentd to push data to a backing datastore not only simplifies the implementation of the custom tool, but also provides compatibility with any store that Fluentd chooses to support.</p><p>Kubernetes gives you some strong guarantees that the containers in your pod have a shared lifecycle. This means that when you launch a pod, you can be sure that each container will be scheduled to the same node; this is important because it means that you can depend on the fact that other containers in your pod will exist and will be local. Pods are often a convenient way to glue the functionality of several different containers together, enabling the reuse of common components. You might, for example, use a sidecar container to enhance the networking abilities of your application, or provide additional log management or monitoring facilities.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec7"></a>Labeling all the things</h3></div></div></div><p><span class="strong"><strong>Labels</strong></span> are key-value pairs <span>that</span><a id="id326407056" class="indexterm"></a> are attached to resources, such as pods. They are intended to contain information that helps you to identify a particular resource.</p><p>You might add labels to your pods to identify the application that is being run, as well as other metadata, such as a version number, an environment name, or other labels that pertain to your application.</p><p>Labels are very flexible, as Kubernetes leaves it up to you to label your own resources as you see fit.</p><p>Once you begin working with Kubernetes, you will discover that you are able to add labels to almost every resource that you create.</p><p>The power of being able to add labels that reflect the architecture of your own application is that you are able to use selectors to query the resources using any combination of the labels that you have given your resources. This setup is shown in the following diagram:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/2485a85d-5825-4890-97fe-4c2bcff4bf76.png" /></div><p>You can add labels to many of the resources that you will create in Kubernetes and then query them with selectors.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note6"></a>Note</h3><p>Kubernetes doesn't enforce any particular schema or layout for the labels you give to objects in your cluster; and you are free to label your applications however you choose. If you want a little more structure however. Kubernetes does make some suggestions for labels you might want to apply to objects that can be grouped together into a logical Application. You can read more about this in the Kubernetes documentation: <a class="ulink" href="https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/" target="_blank">https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/</a>.</p></div><p> </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec8"></a>Replica sets</h3></div></div></div><p>In Kubernetes, a <code class="literal">ReplicaSet</code> is a resource <span>that</span><a id="id326407109" class="indexterm"></a> templates the creation of pods. The definition of a replica set contains a template definition of the pods that it creates, a desired count of replicas, and a selector to discover the pods under its management.</p><p>The <code class="literal">ReplicaSet</code> is used to ensure that the desired number of pods is always running. If the count of pods matching the selector drops below the desired count, then Kubernetes will schedule another.</p><p>Because the life of a pod is tied to that of the node that it is running on, a pod can be considered ephemeral. There are a number of reasons why the life of a particular pod could come to an end. Perhaps it was removed by the operator or an automated process. Kubernetes could have evicted the pod to better utilize the resources of the cluster or prepare the node for shutdown or restart. Or perhaps the underlying node failed.</p><p>A <code class="literal">ReplicaSet</code> allows us to manage our application by asking the cluster to ensure that the correct number of replicas is running across the cluster as a whole. This is a strategy that Kubernetes embraces across many of its APIs.</p><p>As a cluster operator, Kubernetes takes some of the complexity of running applications away from the user. When I decide that I need three instances of my application running, I no longer need to think about the underlying infrastructure: I can just tell Kubernetes to carry out my wishes. And if the worst happens and one of the underlying machines that my application is running on fails, Kubernetes will know how to self-heal my application and launch a new pod. No more pager calls and trying to recover or replace failed instances in the middle of the night.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip7"></a>Note</h3><p><code class="literal">ReplicaSet</code> replaces the <code class="literal">ReplicationController</code> that you might have read about in older tutorials and documentation. They are almost entirely identical, but differ in a few small ways.</p></div><p>Often, we want to update the software we run on our cluster. Because of this, we don't normally directly use <code class="literal">ReplicaSet</code> but, instead, manage them with a <code class="literal">Deployment</code> object. Deployments are used in Kubernetes to gracefully roll out new versions of a <code class="literal">ReplicaSet</code>. You will learn more about deployments in <a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Managing Change in Your Applications</em></span>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec9"></a>Services</h3></div></div></div><p>The final basic tool <span>that</span><a id="id325162738" class="indexterm"></a> Kubernetes gives us to manage our applications is the service. <span class="strong"><strong>Services</strong></span> give us a convenient way of accessing our services within our cluster, something often referred to as <span class="emphasis"><em>service discovery</em></span>.</p><p>In practice, a service allows us to define a label selector to refer to a group of pods and then map that to something that our application can consume, without having to be modified to query the Kubernetes API to gather this information. Typically, a service will provide a stable IP address or DNS name that can be used to access the underlying pods that it refers to in a round robin fashion.</p><p>By using a service, our applications don't need to know that they are running on Kubernetes-we just need to configure them correctly with the DNS name or IP address of a service that they depend on.</p><p>A service provides a way for other applications in the cluster to discover pods that match a particular label selector. It does this by providing a stable IP address and, optionally, a DNS name. This setup is shown in the following diagram:</p><div class="mediaobject"><img src="/graphics/9781788390071/graphics/d0d00b73-5ec8-4daa-89ea-b718150052d6.png" /></div></div></div>