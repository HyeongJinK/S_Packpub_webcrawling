<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec37"></a>Lights, Normals, and Materials</h2></div></div><hr /></div><p>In the real world, we see <span>objects</span><a id="id325358908" class="indexterm"></a> because <span>they</span><a id="id325359414" class="indexterm"></a> reflect light. The illumination of an object depends on its position relative to the light source, surface orientation, and its <span>material</span><a id="id325359422" class="indexterm"></a> composition. In this chapter, we will learn how to combine these three elements in WebGL to model different illumination schemes:</p><div class="mediaobject"><img src="/graphics/9781788629690/graphics/bc017adf-404b-4fc9-9e07-389381666890.png" /></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec36"></a>Positional Versus Directional Lights</h3></div></div></div><p>Light sources can be <span class="strong"><strong>positional</strong></span> or <span class="strong"><strong>directional</strong></span>. A light <span>source</span><a id="id325638045" class="indexterm"></a> is called positional when its location will affect how the scene is lit. For instance, a lamp <span>inside</span><a id="id325638054" class="indexterm"></a> a room is a positional light source. Objects far from the lamp will receive very little light and may even appear obscure. In contrast, directional lights are lights that produce the same luminous result, regardless of their position. For example, the light from the sun will illuminate all objects in a terrestrial scene, regardless of their distance from the sun. This is because the sun is so far away that all light rays are considered parallel when they intersect the surface of an object. Directional lighting assumes that the light is coming uniformly from one direction:</p><div class="mediaobject"><img src="/graphics/9781788629690/graphics/6c06414c-359a-48ee-aa74-3a0bf3154b17.png" /></div><p>A positional light is modeled by a point in space, while a directional light is modeled with a vector that indicates its direction. It is common to use a normalized vector for this purpose, given that this simplifies mathematical operations. Also, it is generally the case that computing directional lighting is actually simpler and less computationally expensive than positional lighting.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec37"></a>Normals</h3></div></div></div><p><span class="strong"><strong>Normals</strong></span> are vectors <span>that</span><a id="id325643374" class="indexterm"></a> are perpendicular to the surface we want to illuminate. Normals represent the orientation of the surface and are therefore critical to modeling the interaction between a light source and the object. Given that each vertex has an associated normal vector, we can use the cross product to calculate normals.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note34"></a>Note</h3><p><strong class="userinput"><code>Cross-Product</code></strong><span class="strong"><strong></strong></span> By definition, the cross-product of vectors <code class="literal">A</code> and <code class="literal">B</code> will be a vector perpendicular to both vectors <code class="literal">A</code> and <code class="literal">B</code>.</p></div><p>Let's break this down. If we have the triangle conformed by vertices <code class="literal">p0</code>, <code class="literal">p1</code>, and <code class="literal">p2</code>, we can define the <code class="literal">v1</code> vector as <code class="literal">p1 - p0</code> and the <code class="literal">v2</code> vector as <code class="literal">p2 - p0</code>. The normal is then obtained by calculating the <code class="literal">v1 x v2</code> cross-product. Graphically, this procedure looks something like the following:</p><div class="mediaobject"><img src="/graphics/9781788629690/graphics/1f5861e1-dca8-456f-9a2d-caed438d08b5.png" /></div><p>We then repeat the same calculation for each vertex on each triangle. But, what about the vertices that are shared by more than one triangle? Each shared vertex normal will receive a contribution from each of the triangles in which the vertex appears.</p><p>For example, say that the <code class="literal">p1</code> vertex is shared by the <code class="literal">#1</code> and <code class="literal">#2</code> triangles, and that we have already calculated the normals for the vertices of the <code class="literal">#1</code> triangle. Then, we need to update the <code class="literal">p1</code> normal by adding up the calculated normal for <code class="literal">p1</code> on the <code class="literal">#2</code> triangle. This is a <span class="strong"><strong>vector sum</strong></span>. Graphically, this <span>looks</span><a id="id325647093" class="indexterm"></a> similar to the following:</p><div class="mediaobject"><img src="/graphics/9781788629690/graphics/e95797a2-8f0e-4767-a9f3-4d223cad1c01.png" /></div><p>Similar to lights, normals are generally normalized to facilitate mathematical operations.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec38"></a>Materials</h3></div></div></div><p>In WebGL, the <span>material</span><a id="id325647118" class="indexterm"></a> of an object can be modeled by several parameters, including its color and texture. Material colors are usually modeled as triplets in the RGB (red, green, blue) space. Textures, on the other hand, correspond to images that are mapped onto the surface of the object. This process is usually called <span class="strong"><strong>texture mapping</strong></span>. We will cover texture mapping in later chapters.</p></div></div>