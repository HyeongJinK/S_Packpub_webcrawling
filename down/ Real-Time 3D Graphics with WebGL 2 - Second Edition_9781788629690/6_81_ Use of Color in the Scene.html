<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec87"></a>Use of Color in the Scene</h2></div></div><hr /></div><p>It’s time to discuss transparency and alpha blending. As <span>mentioned</span><a id="id325358908" class="indexterm"></a> before, the alpha channel can carry information about the opacity of the object color. However, as we saw in the cube example, it’s not possible to obtain a translucent object unless alpha blending is activated. Things get a bit more complicated when we have several objects in the scene. To manage these difficulties, we need to learn what to do in order to have a consistent scene with translucent and opaque objects.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec112"></a>Transparency</h3></div></div></div><p>The first approach to render <span>transparent</span><a id="id325358928" class="indexterm"></a> objects is to use <span class="strong"><strong>polygon stippling</strong></span>. This <span>technique</span><a id="id325617303" class="indexterm"></a> consists of discarding some fragments so that you can see through the object. Think of this as punching little holes in the surface of your object.</p><p>OpenGL supports polygon stippling through the <code class="literal">glPolygonStipple</code> function. This function is not available in WebGL. You could try to replicate this functionality by dropping some fragments in the fragment shader using the ESSL discard command.</p><p>More commonly, we can use the alpha channel information to obtain translucent objects. However, as we’ve seen in the cube example, modifying the alpha values does not produce <span>transparency</span><a id="id325617358" class="indexterm"></a> automatically.</p><p>Creating transparency corresponds to altering the fragments that we’ve already written to the framebuffer. Think, for instance, of a scene where there is one translucent object in front of an opaque object (from our camera view). In order for the scene to be rendered correctly, we need to be able to see the opaque object through the translucent object. Therefore, the fragments that overlap between the far and near objects need to be combined somehow to create the transparency effect.</p><p>The same idea applies when there is only one translucent object in the scene. The only difference is that the far fragments correspond to the back face of the object and the near fragments correspond to the front face of the object. To produce the transparency effect in this case, the far and near fragments need to be combined.</p><p>To properly render transparent surfaces, we need to learn about two important WebGL concepts: <span class="strong"><strong>depth testing</strong></span> and <span class="strong"><strong>alpha blending</strong></span>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec113"></a>Updated Rendering Pipeline</h3></div></div></div><p>Depth testing and alpha <span>blending</span><a id="id325617386" class="indexterm"></a> are two optional stages for fragments once they’ve been processed by the fragment shader. If the depth test is not activated, all the fragments are automatically available for alpha blending. If the depth test is enabled, those fragments that fail the test will automatically be discarded by the pipeline and will no longer be available for any other operation. This means that discarded fragments will not be rendered. This behavior is similar to using the ESSL discard command.</p><p>The following diagram shows the order in which depth testing and alpha blending are performed:</p><div class="mediaobject"><img src="/graphics/9781788629690/graphics/62a7b157-758a-4a76-a6e2-fa7acc3ca834.png" /></div><p>Now, let's see what depth testing is about and why it’s relevant to alpha blending.</p></div></div>