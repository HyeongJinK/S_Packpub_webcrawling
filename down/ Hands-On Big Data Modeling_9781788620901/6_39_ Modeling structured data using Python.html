<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec42"></a>Modeling structured data using Python</h2></div></div><hr /></div><p>Let's see what type of data we are going to <span>analyze</span><a id="id325804950" class="indexterm"></a> today using IPython. Download the CSV file from the <a class="ulink" href="https://github.com/PacktPublishing/Hands-On-Big-Data-Modeling" target="_blank">Chapter 6</a> codebase from GitHub. You should have access to the data file in the <code class="literal">CH06</code> folder. The CSV files <span>contain</span><a id="id325804937" class="indexterm"></a> the following entries:</p><pre class="programlisting">id,
date,
price,
bedrooms,
bathrooms,
sqft_living,
sqft_lot,
floors,waterfront,
view,
condition,
grade,
sqft_above,
sqft_basement,
yr_built,
yr_renovated,
zipcode,
lat,
long,
sqft_living15,
sqft_lot1</pre><p>First things first, we import our libraries and dataset. Then, using the <code class="literal">head</code> function, we check out the first few pieces of data to see how they look. After that, we use the <code class="literal">describe</code> function to see the percentiles and other key statistics. Let's start our IPython notebook by using the following command:</p><pre class="programlisting"><span class="strong"><strong>jupyter notebook</strong></span></pre><p><span>Now let's import the required libraries:</span></p><pre class="programlisting"><span>import</span><span>numpy</span><span>as</span><span>np</span><span>import</span><span>pandas</span><span>as</span><span>pd</span><span>import</span><span>matplotlib.pyplot</span><span>as</span><span>plt</span><span>import</span><span>seaborn</span><span>as</span><span>sns</span><span>import</span><span>mpl_toolkits</span></pre><p>Make sure you have all these libraries installed before you run the preceding code. Let's read the CSV file. Assuming the filename is <code class="literal">house_data.csv</code>, importing the data is pretty straightforward, just perform the following:</p><pre class="programlisting"><span>data</span><span>=</span><span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"house_data.csv"</span><span>)</span></pre><p>To find out more about the data, we can use the <code class="literal">describe</code> function:</p><pre class="programlisting"><span>data</span><span>.</span><span>describe</span><span>()</span></pre><p>The output of the <code class="literal">describe</code><span class="strong"><strong> </strong></span>command should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/fa15787f-8ccc-41df-8d86-6d30d0748b5a.png" /></div><p>Figure 6.1: Describing the dataset to get more insight into the data</p><p>The next step is to visualize the <span>data</span><a id="id325591987" class="indexterm"></a> we have in <span class="emphasis"><em>Figure 6.1</em></span>. We can use the same <code class="literal">matplotlib</code> library to visualize the data in the form of a  bar chart. Let's use Python Script to find out the most common house from the data based on the <span>number</span><a id="id325878519" class="indexterm"></a> of bedrooms:</p><pre class="programlisting"><span>data</span><span>[</span><span>'bedrooms'</span><span>]</span><span>.</span><span>value_counts</span><span>()</span><span>.</span><span>plot</span><span>(</span><span>kind</span><span>=</span><span>'bar'</span><span>)</span><span>plt</span><span>.</span><span>title</span><span>(</span><span>'number of Bedroom'</span><span>)</span><span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>'Bedrooms'</span><span>)</span><span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>'Count'</span><span>)</span><span>sns</span><span>.</span><span>despine</span></pre><div class="mediaobject"><img src="/graphics/9781788620901/graphics/d3fc3f7c-b54a-4466-a62c-15d51b65f582.png" /></div><p>Figure 6.2: Visualizing the dataset to find the most common bedroom</p><p>The diagram demonstrates that three-bedroom houses are sold the most frequently, followed by four-bedroom houses. This exemplifies how a new builder can build a new <span>apartment</span> in a place. This analysis is useful for both business owners and stakeholders. </p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec53"></a>Visualizing the location of houses based on latitude and longitude</h3></div></div></div><p>We have the latitude and <span>longitude</span><a id="id326584499" class="indexterm"></a> for each house in the dataset. Let's look at the most common locations and how the houses are placed:</p><pre class="programlisting"><span>plt</span><span>.</span><span>figure</span><span>(</span><span>figsize</span><span>=</span><span>(2</span><span>0</span><span>,</span><span>14</span><span>))</span>
<span>sns</span><span>.</span><span>jointplot</span><span>(</span><span>x</span><span>=</span><span>data</span><span>.</span><span>lat</span><span>.</span><span>values</span><span>,</span><span>y</span><span>=</span><span>data</span><span>.</span><span>long</span><span>.</span><span>values</span><span>,</span><span>size</span><span>=</span><span>10</span><span>)</span>
<span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>'Longitude'</span><span>,</span><span>fontsize</span><span>=</span><span>12</span><span>)</span>
<span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>'Latitude'</span><span>,</span><span>fontsize</span><span>=</span><span>12</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
<span><span>sns</span><span>.</span><span>despine</span></span></pre><p>The output of the preceding snippet should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/2b44f331-fc90-43a5-ad8b-e6b89f124b0d.png" /></div><p>Figure 6.3: Visualizing the dataset based on location</p><p>Seaborn is an amazing Python library for building a <span>multitude</span><a id="id325890193" class="indexterm"></a> of charts and visualizing our data. In this case, we use the same library to plot a chart based on location. We used the <code class="literal">jointplot</code> function from the library to see the concentration of the data. You can learn more about this function from the <a class="ulink" href="https://seaborn.pydata.org/generated/seaborn.jointplot.html" target="_blank">documentation site</a>. <span class="emphasis"><em>Figure 6.3</em></span> shows that there are more houses between latitudes 47.7 and 47.8 and the concentration of the houses is higher between longitudes -122.2 to -122.4. The concentration of the houses could indicate several conclusions, such as people like to buy houses in these areas.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec54"></a>Factors that affect the price of houses</h3></div></div></div><p>We analyzed common locations. In addition to the <span>previous</span><a id="id325890220" class="indexterm"></a> analysis, we can also see a few common factors that affect the price of houses. </p><p>The price versus the living area of the house:</p><pre class="programlisting"><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>.</span><span>price</span><span>,</span><span>data</span><span>.</span><span>sqft_living</span><span>)</span><span>plt</span><span>.</span><span>title</span><span>(</span><span>"Price vs Sq</span><span>uare Feet"</span><span>)</span></pre><p>The output of the preceding snippet should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/855e7ac1-fe61-4afa-89ce-518dd95c725b.png" /></div><p>The price versus the location of the area:</p><pre class="programlisting"><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>.</span><span>price</span><span>,</span><span>data</span><span>.</span><span>long</span><span>)</span><span>plt</span><span>.</span><span>title</span><span>(</span><span>"Price vs Location </span><span>of the area"</span><span>)</span></pre><p>The output of the preceding snippet should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/0c9ac214-237b-451b-8ad6-f568c22737fc.png" /></div><p>The price versus the number of bedrooms:</p><pre class="programlisting"><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>.</span><span>bedrooms</span><span>,</span><span>data</span><span>.</span><span>price</span><span>)</span><span>plt</span><span>.</span><span>title</span><span>(</span><span>"Bedroom and Price "</span><span>)</span><span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>"Bedrooms"</span><span>)</span><span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>"Price"</span><span>)</span><span>plt</span><span>.</span><span>show</span><span>()</span><span>sns</span><span>.</span><span>despine</span></pre><p>The output of the  preceding snippet should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/cfe4b6e6-03d7-4f3a-b5e2-c32e92d0170f.png" /></div><p>The price versus the latitude:</p><pre class="programlisting"><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>.</span><span>price</span><span>,</span><span>data</span><span>.</span><span>lat</span><span>)</span><span>plt</span><span>.</span><span>xlabel</span><span>(</span><span>"Price"</span><span>)</span><span>plt</span><span>.</span><span>ylabel</span><span>(</span><span>'Latitude'</span><span>)</span><span>plt</span><span>.</span><span>title</span><span>(</span><span>"Latitude vs </span><span>Pr</span><span>ice"</span><span>)</span></pre><p>The output of the preceding snippet should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/b055057d-fa7c-4881-8b42-879161141871.png" /></div><p>The price versus the waterfront:</p><pre class="programlisting"><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>data</span><span>.</span><span>waterfront</span><span>,</span><span>data</span><span>.</span><span>price</span><span>)</span><span>plt</span><span>.</span><span>title</span><span>(</span><span>"Waterfront vs Price ( 0= no wat</span><span>erfront)"</span><span>)</span></pre><p>The output of the preceding snippet should look like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/f7783ad0-6b0b-4bfe-b0a0-8ec5f1a1bafd.png" /></div><p>Many factors affect house prices in any area, including square footage, the location of the house, and the number and size of bedrooms. The preceding screenshot represents the same idea. In the next section, we are going to use a similar method to predict house prices based on other parameters. </p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec27"></a>Visualizing more than one parameter</h4></div></div></div><p>We have already seen that we can use Matplotlib to create a beautiful diagram. Here, we would like to introduce how we can use <code class="literal">mplot3d</code> to visualize more than three parameters. Let's say we want to see how the number of floors and the number of bedrooms are related to the bathroom. The first step is to import the library:</p><pre class="programlisting">from mpl_toolkits.mplot3d import Axes3D</pre><p>Then let's add the required parameters: </p><pre class="programlisting">fig=plt.figure(figsize=(19,12.5))
ax=fig.add_subplot(2,2,1, projection="3d")
ax.scatter(data['floors'],data['bedrooms'],data['bathrooms'],c="darkgreen",alpha=.5)
ax.set(xlabel='\nFloors',ylabel='\nBedrooms',zlabel='\nBathrooms / Bedrooms')
ax.set(ylim=[0,12])</pre><p>The snippet should give a 3D chart, as follows:</p><div class="mediaobject"><img src="/graphics/9781788620901/graphics/d9584cc2-edff-4be5-943a-616b15a62555.png" /></div><p> </p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec55"></a>Gradient-boosting regression</h3></div></div></div><p>There are several ways these models can be interpreted. It's one of the advanced topic, this can be used is a prediction. There are several algorithms that can be applied in order to predict <span>house</span><a id="id325987100" class="indexterm"></a> prices. In this chapter, we can try to use <span class="strong"><strong>gradient-boosting regression</strong></span> (<span class="strong"><strong>GBR</strong></span>).<span class="strong"><strong> </strong></span></p><p><code class="literal">Gradient boosting</code> is one of the most powerful techniques for building predictive models. You can read more about the algorithm <a class="ulink" href="https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d" target="_blank">from the links provided</a>. Let's see how we can employ this algorithm to predict house prices using our dataset: </p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Import the library from <code class="literal">sklearn</code>. </li><li>Create a variable for Gradient boosting and set the following parameters:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">n_estimators</code>: The number of boosting stages to perform. </li><li style="list-style-type: disc"><code class="literal">max_depth</code>: The depth of the tree model. </li><li style="list-style-type: disc"><code class="literal">learning_rate</code>: The rate of learning the data. </li><li style="list-style-type: disc"><code class="literal">loss</code>: The loss function to be optimized; <code class="literal">ls</code> refers to least-squares regression. </li></ul></div></li><li>Fit the training data into the <span class="strong"><strong>gradient-boosting model</strong></span> (<span class="strong"><strong>GBM</strong></span>).</li><li>Check for accuracy: </li></ol></div><pre class="programlisting"><span>from</span><span>sklearn</span><span>import</span><span>ensemble</span><span>clf</span><span>=</span><span>ensemble</span><span>.</span><span>GradientBoostingRegressor</span><span>(</span><span>n_estimators</span><span>=</span><span>400</span><span>,</span><span>max_depth</span><span>=</span><span>5</span><span>,</span><span>min_samples_split</span><span>=</span><span>2</span><span>,</span><span>learning_rate</span><span>=</span><span>0.1</span><span>,</span><span>loss</span><span>=</span><span>'ls'</span><span>)</span></pre><p>We just imported the <code class="literal">GradientBoostingRegressor</code> from the library and set the parameters. It is important to note that how you set these parameters really depends on an empirical approach, practice, and experience. </p><p>Now, let's just create a training sample list and test it from the dataset. To do so, we can choose a subset of data as training data and the remaining as the test data, to see how well our model has learned to classify. We can do that by following the snippet:</p><pre class="programlisting">x_df = data.drop(['id','date',], axis = 1)</pre><p>We dropped <code class="literal">id</code> and <code class="literal">date</code> from the preceding data frame. Now, let's drop the price from the training dataset: </p><pre class="programlisting">x_df2 = x_df.drop(['price'], axis = 1)</pre><p>We can use the <code class="literal">train_test_split</code> function available from the <code class="literal">sklearn</code> library to create training and test datasets: </p><pre class="programlisting">from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x_df2,data['price'],test_size=0.4,random_state=4)</pre><p>In the preceding snippet, it is important to understand that we created a training dataset and a testing dataset from the same dataset. Now let's try to fit our training data into the GBM: </p><pre class="programlisting"><span>clf</span><span>.</span><span>fit</span><span>(</span><span>x_train</span><span>,</span><span>y_train</span><span>)</span></pre><p>Fitting the training data gives the following result:</p><pre class="programlisting">GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=5, max_features=None,
             max_leaf_nodes=None, min_impurity_split=1e-07,
             min_samples_leaf=1, min_samples_split=2,
             min_weight_fraction_leaf=0.0, n_estimators=400,
             presort='auto', random_state=None, subsample=1.0, verbose=0,
             warm_start=False)</pre><p> Let's check for the accuracy of the prediction: </p><pre class="programlisting"><span>clf</span><span>.</span><span>score</span><span>(</span><span>x_test</span><span>,</span><span>y_test</span><span>)</span></pre><p>The preceding code gives us the following output:</p><pre class="programlisting">0.91948383097569342</pre><p>This is 91.95%, which is pretty good. You can try to apply these techniques to various other datasets. In addition to this gradient-boosting algorithm, you can try using linear regression. However, in our case, the gradient-boosting algorithm gives better accuracy. </p></div></div>