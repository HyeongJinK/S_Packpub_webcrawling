<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec56"></a>Landslide susceptibility modeling</h2></div></div><hr /></div><p>For landslide <span>susceptibility</span><a id="id325302936" class="indexterm"></a> analysis, we will follow these steps:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>We will load a <span class="strong"><strong>digital elevation model</strong></span> (<span class="strong"><strong>DEM</strong></span>) from SRTM (provided in the <code class="literal">Data</code> folder of <code class="literal">Chapter10</code>).</li><li>Compute the slope from this DEM.</li><li>Reproject each file to the <span>same</span><a id="id325302971" class="indexterm"></a> projection system so that we can compare one with another.</li><li>Extract the elevation and slope values corresponding to the landslide location using the DEM file and the computed slope.</li><li>Classify areas as safe or unsafe using the range of slopes within which landslides have occurred.</li><li>Get random points in the safe zone and extract their elevation and slope values.</li><li>Using the elevation and slope values from both the unsafe and safe locations, fit a logistic regression model.</li><li>Using the coefficient of the fitted model, make a landslide susceptibility map.</li></ol></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec81"></a>Data preprocessing</h3></div></div></div><p>Before we start modeling, we need to <span>have</span><a id="id326218029" class="indexterm"></a> all the <span>data</span><a id="id326218619" class="indexterm"></a> regarding the elevation and slope of safe and unsafe locations.</p><p>At first, we will load <code class="literal">DEM_PC.tif</code>, which is the DEM file corresponding to our study area. This appears as follows:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/65ff71e7-e820-47cf-87af-921d166146b2.png" /></div><p>Now, if we right-click on the <strong class="userinput"><code>DEM_PC</code></strong> layer and click on <strong class="userinput"><code>Properties</code></strong>, we will see that the coordinate reference system is <strong class="userinput"><code>WGS 84</code></strong>. We will now convert it to the projected coordinate reference system of <strong class="userinput"><code>UTM zone 46N</code></strong>, corresponding to Bangladesh. To reproject, click on <strong class="userinput"><code>Raster</code></strong> | <strong class="userinput"><code>Projections</code></strong> | <strong class="userinput"><code>Warp (Reproject)...</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/99718b2b-a38b-4242-b770-c29d168b939f.png" /></div><p>Now, we will get a window for reprojecting. Select <strong class="userinput"><code>DEM_PC</code></strong> for <span class="strong"><strong><strong class="userinput"><code>Input layer</code></strong></strong></span> and click on the small <span>box</span><a id="id326218962" class="indexterm"></a> to the <span>right</span><a id="id326218970" class="indexterm"></a> of <strong class="userinput"><code>Target CRS</code></strong> to reproject:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/8dfc5d67-db37-473f-8550-838e98b09eba.png" /></div><p>Select <strong class="userinput"><code>WGS 84 / UTM zone 46N (EPSG:32646)</code></strong> under <strong class="userinput"><code>Coordinate reference systems of the world</code></strong>. Now click <strong class="userinput"><code>OK</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/25829fda-75c5-4a91-90f6-2cd468ca7cd5.png" /></div><p>Now, click on <strong class="userinput"><code>Run in Background</code></strong>, and after it has run, close it. This will give us the reprojected raster layer of digital elevation. We can save this raster by right-clicking on the layer and then going to <strong class="userinput"><code>Export</code></strong> | <strong class="userinput"><code>Save As...</code></strong> Under <strong class="userinput"><code>File name</code></strong>, browse to the <code class="literal">Data</code> folder under <code class="literal">Chapter10</code> and save it as <code class="literal">DEM_PC_UTM.tif</code>. Finally, click <strong class="userinput"><code>OK</code></strong> to save the raster file:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/9d82a566-34e2-47d0-8edc-583d70136687.png" /></div><p>Now, load <code class="literal">DEM_PC_UTM.tif</code>, which we just created. We need to calculate the slope value <span>from</span><a id="id326219053" class="indexterm"></a> this file for <span>further</span><a id="id326219060" class="indexterm"></a> analysis. We do so by going to <strong class="userinput"><code>Raster</code></strong> | <strong class="userinput"><code>Analysis</code></strong> | <strong class="userinput"><code>Slope</code></strong>. This will look as follows:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/1326287c-1683-4547-9f53-347fb56c7160.png" /></div><p> </p><p>Select <strong class="userinput"><code>DEM_PC_UTM</code></strong> for <strong class="userinput"><code>Input layer</code></strong> and then click on <strong class="userinput"><code>Run in Background</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/8dca5bfa-1071-4255-a387-50799eaf5b34.png" /></div><p>After this command is run, we will get a raster of slope values for the CHT region. Save this as <strong class="userinput"><code>Slope_PC</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/904d7e0f-0a3a-4347-8f9d-7df77d478740.png" /></div><p>For a colored version of this or for better visualization, right-click on this raster layer and click on <strong class="userinput"><code>Properties</code></strong>. Select <strong class="userinput"><code>Symbology</code></strong> in the left panel, then select <strong class="userinput"><code>Single pseudocolor</code></strong><span>under</span><a id="id326307848" class="indexterm"></a><strong class="userinput"><code>Render type</code></strong><span>and</span><a id="id326307858" class="indexterm"></a> select <strong class="userinput"><code>Magma</code></strong> under <strong class="userinput"><code>Color ramp</code></strong>, and then click <strong class="userinput"><code>OK</code></strong> to visualize the slope in the color magma:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/00aa7b98-cb1f-4902-9b6c-9171dee9cc27.png" /></div><p>Now, we load the <code class="literal">landslide_locationreal.shp</code> shapefile from the <code class="literal">Data</code> folder, and we can check its properties to be sure that its coordinate reference system is <strong class="userinput"><code>WGS 84</code></strong>, which we need to convert to <strong class="userinput"><code>WGS 84 / UTM zone 46N (EPSG:32646)</code></strong>. Click <strong class="userinput"><code>Vector</code></strong> | <strong class="userinput"><code>Data Management Tools</code></strong> <span class="strong"><strong>| Reproject Layer...</strong></span>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/9a2d0422-4f1d-4905-847a-ec9de46872ad.png" /></div><p>Select <strong class="userinput"><code>landslide_locationreal</code></strong> for <strong class="userinput"><code>Input layer</code></strong> and select <strong class="userinput"><code>EPSG:32646 - WGS 84 / UTM zone 46N</code></strong> for <strong class="userinput"><code>Target CRS</code></strong>, then save it as <code class="literal">landslide_location_UTM.shp</code> by clicking on the box to the right of <strong class="userinput"><code>Reprojected</code></strong>. Click <strong class="userinput"><code>Run in Background</code></strong>, and after it is finished running, click <strong class="userinput"><code>Close</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/c2d3569d-c2e8-407e-b198-11545f0ed3c0.png" /></div><p>Our multipoint shapefile is now appropriately projected. Now, we need to get the elevation and slope values corresponding to hazard locations. Click on <strong class="userinput"><code>Plugins</code></strong> | <strong class="userinput"><code>Analyses</code></strong> | <strong class="userinput"><code>Point sampling tool</code></strong>. If <strong class="userinput"><code>Analyses</code></strong> is not shown under <strong class="userinput"><code>Plugins</code></strong>, install it from <strong class="userinput"><code>Plugins</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/6cb74a41-a3bb-4180-af6d-e5c16a181d33.png" /></div><p>Select <strong class="userinput"><code>Reprojected</code></strong> (the reprojected shapefile containing the locations of landslide events) under <strong class="userinput"><code>Layer containing sampling points</code></strong>. Highlight <strong class="userinput"><code>Longitude</code></strong> and <strong class="userinput"><code>Latitude</code></strong> as <span>source</span><a id="id326343434" class="indexterm"></a> points of <strong class="userinput"><code>Reprojected</code></strong> and <strong class="userinput"><code>Slope_PC</code></strong> as the raster from which the value will be extracted. Under <strong class="userinput"><code>Output point vector layer:</code></strong>, browse to the <code class="literal">Data</code> folder and save it as <code class="literal">slope_hazard.csv</code>. Click <strong class="userinput"><code>OK</code></strong> and it will save the slope <span>values</span><a id="id326345133" class="indexterm"></a> corresponding to the landslide locations in a CSV file named <code class="literal">slope_hazard</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/e8fd96be-3047-4086-8809-8216927f04c9.png" /></div><p><code class="literal">slope_hazard.csv</code> will have three columns: <code class="literal">Longitude</code>, <code class="literal">Latitude</code>, and <code class="literal">Slope_PC</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/c0157f6a-c222-4167-971f-b5725d61a7ff.png" /></div><p>Similarly, we extract values of elevation using <code class="literal">DEM_PC_UTM.tif</code> and save it as <code class="literal">dem_hazard.csv</code>.</p><p>Now, we will look at the range of the slope values in which landslide occurs. We do so by importing <code class="literal">slope_hazard.csv</code> in R and by looking at its range:</p><pre class="programlisting">landslide = read.csv("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/slope_hazard.csv")
str(landslide)
range(landslide$Slope_PC)</pre><p>We see that the range is between <code class="literal">0.33273</code> and <code class="literal">23.582223</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/d3adcec2-999b-40ae-85cf-7dee148f53a9.png" /></div><p>Now, we will classify the area of raster where the value of slope doesn't fall in this range. We will now create a <code class="literal">.txt</code> file where we will classify values from the minimum to 0.33273 as <code class="literal">0</code>, values from 0.33273 to 23.58223 as <code class="literal">NULL</code>, and values from 23.58223 to the highest as <code class="literal">0</code> again. We write the classification values in the <code class="literal">classify.txt</code> file in the following way:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/ed2756bb-14c2-4c55-895d-68caf25c5527.png" /></div><p>We will now use <strong class="userinput"><code>recode</code></strong> from <strong class="userinput"><code>GRASS</code></strong> under <strong class="userinput"><code>Processing Toolbox</code></strong> to classify <code class="literal">slope_PC.tif</code>. Write <code class="literal">recode</code> in the search bar under <strong class="userinput"><code>Processing Toolbox</code></strong> and double-click on <code class="literal">r.recode</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/ac08bbb0-44e2-4da8-b50c-cfdd735021a5.png" /></div><p>Select <strong class="userinput"><code>Slope_PC</code></strong> as <strong class="userinput"><code>Input layer</code></strong>, under <strong class="userinput"><code>File containing recode values</code></strong>, and browse to <code class="literal">classify.txt</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/1301d810-2210-41d9-82d0-4c59d7e20ba3.png" /></div><p>Browse a little further down, click on the <span>box</span><a id="id326218369" class="indexterm"></a> to the right of <strong class="userinput"><code>Recoded</code></strong>, and click on <strong class="userinput"><code>Save to File...<span class="strong"><strong>.</strong></span></code></strong> Now click <strong class="userinput"><code>Run</code></strong> to get a reclassified <span>raster</span><a id="id326218425" class="indexterm"></a> that has only two values: <code class="literal">0</code> for safe areas (original slope between 0.33273 and 23.58223) and <code class="literal">NULL</code> for other areas:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/bf09f711-9057-445f-8e2c-fef384722607.png" /></div><p>The raster file will now look something like the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/1734a27d-b3fa-4ca1-9b50-5d953d7a7fab.png" /></div><p>Our target is to generate random points within this safe zone. But, before that, we will need to convert the raster to a vector. We do this by clicking <strong class="userinput"><code>Raster</code></strong> | <strong class="userinput"><code>Conversion</code></strong> | <strong class="userinput"><code>Polygonize (Raster to vector)</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/6dd6fc54-fd6c-4a10-89c6-6aad094d4928.png" /></div><p>Select <strong class="userinput"><code>Recoded</code></strong> as the <strong class="userinput"><code>Input layer</code></strong> and then click on <strong class="userinput"><code>Run in Background</code></strong> to transform the raster to a vector:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/1eeabe1e-2fa1-4e94-b8d6-ec90b4c99f4d.png" /></div><p> </p><p>We will now get a polygon of safe zones as follows:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/5b1f510c-dfb5-46e7-908a-39441a1a8882.png" /></div><p>Now save this <span>vector</span><a id="id326307741" class="indexterm"></a> file by right-clicking <span>on</span><a id="id326307748" class="indexterm"></a> the file, clicking on <strong class="userinput"><code>Export</code></strong>, and then on <strong class="userinput"><code>Save Feature As....</code></strong> Name it <code class="literal">safe.shp</code> and click on <strong class="userinput"><code>Save</code></strong>, which will save <code class="literal">safe.shp</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/2c07227a-b95f-4dfe-a820-9115bad12b26.png" /></div><p>We will create 73 random points (the same as the number of hazard points) in the area covered by <code class="literal">safe.shp</code>. For those 73 points (in safe zone), we will again record their slope and elevation values. To create random points, click <strong class="userinput"><code>Vector</code></strong> | <strong class="userinput"><code>Research Tools</code></strong> <span class="strong"><strong>| Random Points in Layer Bounds...</strong></span>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/954c2851-33e1-49c5-9560-604d3ca5a711.png" /></div><p>Select <strong class="userinput"><code>safe</code></strong> as <strong class="userinput"><code>Input layer</code></strong>, write <code class="literal">73</code> in the value box under <strong class="userinput"><code>Number of points</code></strong>, and then click on <strong class="userinput"><code>Run in Background</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/19350cd4-5b78-4ea5-9aa0-5c89228d5e2b.png" /></div><p> </p><p>Now we will see that 73 new points are generated inside the <strong class="userinput"><code>safe</code></strong> vector. Save it as <code class="literal">safe_points.shp</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/4e7a043d-b4eb-4093-ba98-e68bdd895958.png" /></div><p>Now, similar to with hazard location, we first extract the elevation of the points in the safe zone by clicking <strong class="userinput"><code>Plugins</code></strong> | <strong class="userinput"><code>Analyses</code></strong> | <strong class="userinput"><code>Point sampling tool</code></strong>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/8915dfcd-774e-4897-8c1b-ffa6fcb15b00.png" /></div><p>Select <strong class="userinput"><code>safe_points</code></strong><span>under</span><a id="id326343482" class="indexterm"></a><strong class="userinput"><code>Layer containing <span>sampling</span><a id="id326343492" class="indexterm"></a> points:</code></strong> and highlight <strong class="userinput"><code>safe_points : id (source point)</code></strong> and <strong class="userinput"><code>DEM_PC_UTM : Band 1 (raster)</code></strong>. Save this as <code class="literal">dem_safe.csv</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/dd229579-0185-42ce-a34f-444796fdd5a7.png" /></div><p>Using the <strong class="userinput"><code>Point Sampling Tool</code></strong>, similarly extract the slope values by selecting only <strong class="userinput"><code>Slope_PC</code></strong> and <strong class="userinput"><code>safe_points</code></strong> and saving it as <code class="literal">slope_safe.csv</code>. </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec82"></a>Model building</h3></div></div></div><p>Now, we will build our model <span>using</span><a id="id326345042" class="indexterm"></a> all the data we have computed. We want to make a DataFrame of the elevation value, slope value, and an indicator variable indicating whether the location is unsafe or safe. First, load the elevation data corresponding to the safe zone:</p><pre class="programlisting">dem_safe = read.csv("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/dem_safe.csv")
str(dem_safe)
# Remove id column
dem_safe$id = NULL
str(dem_safe)</pre><p>By investigating the output, we can be sure that we have, in fact, removed the ID column from <code class="literal">dem_safe</code>.</p><p>Now, load the slope data corresponding to the safe zone and remove the ID column as previously mentioned:</p><pre class="programlisting">slope_safe = read.csv("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/slope_safe.csv")
str(slope_safe)
# Remove id column
slope_safe$id = NULL</pre><p>Now, combine a dataset of <code class="literal">dem_safe</code> and <code class="literal">slope_safe</code>:</p><pre class="programlisting">safe = cbind(dem_safe, slope_safe)</pre><p>Create a hazard indicator variable, which will have a value of <code class="literal">0</code> for safe points and a value of <code class="literal">1</code> for hazardous points:</p><pre class="programlisting">safe$hazard = 0</pre><p>Similar to what we have just done for safe zones, we need to do the same for landslide locations, but now the <code class="literal">hazard</code> indicator variable will have a value of <code class="literal">1</code> for all landslide location points:</p><pre class="programlisting">dem_hazard = read.csv("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/dem_hazard.csv")
str(dem_hazard)
# Remove Longitude and Latitude column
dem_hazard$Longitude = NULL
dem_hazard$Latitude = NULL
str(dem_hazard)

slope_hazard = read.csv("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/slope_hazard.csv")
str(slope_hazard)
# Remove Longitude and Latitude column
slope_hazard$Longitude = NULL
slope_hazard$Latitude = NULL
str(slope_hazard)

hazard = cbind(dem_hazard, slope_hazard)
# Indicator variable indicating landslide
hazard$hazard = 1</pre><p>Create a composite dataset of <code class="literal">safe</code> and <code class="literal">hazard</code> data:</p><pre class="programlisting">landslide = rbind(safe, hazard)
head(landslide)</pre><p>We see that the landslide DataFrame now has all the required values for model building:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/c450032f-57c8-49e8-acd8-15d7e420863d.png" /></div><p>Now we export this as a <code class="literal">.csv</code> file for further use:</p><pre class="programlisting">write.csv(landslide, "F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/model_data.csv")</pre><p> </p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec27"></a>Logistic regression</h4></div></div></div><p>We will use logistic regression <span>here</span><a id="id326300781" class="indexterm"></a> as it can be used to model dependent variables with values of <code class="literal">1</code> (for our case, landslide) and <code class="literal">0</code> (no landslide):</p><pre class="programlisting">logistic_fit = glm(as.factor(hazard)~ DEM_PC_UTM + Slope_PC, data=landslide, family=binomial)
summary(logistic_fit)</pre><div class="mediaobject"><img src="/graphics/9781788991674/graphics/a4c19f8a-879c-4bcc-abf8-79350547e5ab.png" /></div><p>Now, using the estimates of <code class="literal">Intercept</code> and coefficients, we calculate the susceptibility. For this case, the value of <code class="literal">(Intercept)</code> is <code class="literal">3.111299</code>, the value of <code class="literal">DEM_PC_UTM</code> is <code class="literal">-0.010680</code>, and the value of <code class="literal">Slope_PC</code>is <code class="literal">-0.123692</code>. You might find something different for these values.</p><p>Now, load the elevation and slope raster:</p><pre class="programlisting">library(raster)
dem = raster("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/DEM_PC_UTM.tif")
slope = raster("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/slope_PC.tif")</pre><p>We now calculate the probability or logistic function for all the cells, using the computed coefficients in the following way:</p><pre class="programlisting">val = 3.111299 + dem * (-0.010680) + slope * (-0.123692)
prob = 1/(1+exp(val *(-1)))</pre><p>Here, <code class="literal">rrob</code> is a raster file that contains the probability of a hazard at each pixel.</p><p>Let's get the predicted probability for each observation:</p><pre class="programlisting">logistic_prob = predict(logistic_fit, type="response")</pre><p>Now, create a vector of hazard where we assume that a hazard occurred if the probability is greater than <code class="literal">0.65</code>:</p><pre class="programlisting">pred_class = rep(0, nrow(landslide))
pred_class[logistic_prob &gt; 0.65] = 1</pre><p>Using a confusion matrix is a way to look at the performance of classification algorithms. It tabulates our classification against reality, the results of which we can use to gain an idea of the usefulness of our model:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/fba5a9e9-669a-484d-b3b0-aef7d5e96c27.png" /></div><p>We can create a confusion matrix using <code class="literal">table</code> in the following way:</p><pre class="programlisting">confusion = table(pred_class, landslide$hazard)
confusion</pre><p>This matrix now looks like this:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/6b454138-c00a-469f-81b4-bbfbce9d465d.png" /></div><p>Here the accuracy is found by having the total number of correct classifications divided by all classifications. We can compute this from <code class="literal">confusion</code> in the following way:</p><pre class="programlisting">sum(diag(confusion))/sum(confusion)</pre><p>We should see that the resulting accuracy value is <code class="literal">0.8767</code>.</p><p>Now, let's classify this probability with the following specifications: values between <code class="literal">0</code> and <code class="literal">0.3</code> as <code class="literal">0</code> (say, no risk); values between <code class="literal">0.3</code> and <code class="literal">0.7</code> as <code class="literal">1</code> (say, moderate risk); and values between <code class="literal">0.7</code> and <code class="literal">1</code> as <code class="literal">2</code> (say, high risk). Using <code class="literal">reclassify</code>, we classify the probabilities into three groups:</p><pre class="programlisting">class = c(0, 0.3, 1, 0.3, 0.7, 2, 0.7, 1, 3)
class_matrix = matrix(class, ncol=3, byrow = TRUE)
risk_class = reclassify(prob, class_matrix)
plot(risk_class)</pre><p>We will now get the following <span>landslide</span><a id="id326344934" class="indexterm"></a> susceptibility map with probability given in three classes:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/58963d7d-9831-4c99-b7d6-cd13bfed655a.png" /></div><p>If we want, we can also classify such that we predict a landslide only if the probability is greater than <code class="literal">0.65</code>, otherwise not. We can do so in the following way:</p><pre class="programlisting">prob[prob &lt;= 0.65] = 0
prob[prob &gt; 0.65] = 1
plot(prob)</pre><p>Now, we get the following landslide susceptibility map:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/c7ad62f2-0d34-4fbd-80a5-1b3be818d038.png" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec28"></a>CART</h4></div></div></div><p>A CART is a classification <span>algorithm</span><a id="id326344984" class="indexterm"></a> that divides the feature space (or independent variable space) into several sections and assigns classes to each subsection. We will not discuss this in detail and will be using R to achieve the classification of areas. </p><p>We will now split data into training and testing sets. Training data is normally 70% or 80% of the original dataset that is selected randomly, and this is what's used for fitting the model. After we fit the model, we evaluate our model by fitting it on the remaining 30% or 20% of the data, which we call the test data.</p><p> </p><p>Now, we will import the <code class="literal">landslide</code> dataset that we exported at the end of our data-preprocessing steps. We will delete the unnecessary <code class="literal">X</code> column and convert <code class="literal">hazard</code> into a factor variable for modeling with CART algorithms:</p><pre class="programlisting">landslide_model = read.csv("F:/Hands-on Geospatial Analysis Using R and QGIS/Chapter 10/Data/model_data.csv")
landslide_model$X = NULL
landslide_model$hazard = as.factor(landslide_model$hazard)
str(landslide_model)</pre><p>Now, install and load all the necessary packages to build a decision tree:</p><pre class="programlisting">install.packages("rpart")
library(rpart)
install.packages("rattle")
library(rattle)
install.packages("rpart.plot")
library(rpart.plot)</pre><p>Now, create training and testing datasets:</p><pre class="programlisting"># Randomly arrange the dataset
set.seed(0)
n = nrow(landslide_model)
random_data = landslide_model[sample(n),]
train = random_data[1:round(0.7 * n),]
test = random_data[(round(0.7 * n) + 1):n,]</pre><p>Now, build a decision tree:</p><pre class="programlisting">tree_train = rpart(hazard ~ ., train, method = "class", control = rpart.control(cp=0.010))</pre><p>In the preceding code, we use <code class="literal">rpart()</code> to build a decision tree. In the code, <code class="literal">hazard ~ ., train</code> says that <code class="literal">hazard</code> depends on all other variables in the training dataset, which are <code class="literal">DEM_PC_UTM</code> and <code class="literal">slope_UTM</code>. Then, <code class="literal">method = "class"</code> says that it is a classification problem and <code class="literal">control = rpart.control(cp = 0.010)</code> defines the model complexity; the lower the value of <code class="literal">cp</code>, the more complex or the deeper the tree fits.</p><p>We can predict the outcome on the test set in the following way:</p><pre class="programlisting"># Predict the outcome
pred = predict(tree_train, test, type = "class")</pre><p>In the preceding code, we fit the model <code class="literal">tree_train</code> object on the <code class="literal">test</code> dataset and we get the predicted class (0 or 1) for each observation in the test dataset.</p><p>We can calculate a confusion matrix in the following way:</p><pre class="programlisting"># Calculate the confusion matrix
(confusion = table(test$hazard, pred))</pre><p>By putting the code inside <code class="literal">()</code>, we execute code and see its content at the same time. The confusion matrix looks as follows:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/c63f0d84-f901-4cdf-a90b-e4326a7cb864.png" /></div><p>Here we see that for safe cases (value <code class="literal">0</code>), a safe zone was predicted <code class="literal">18</code> times and a landslide was never predicted (value <code class="literal">1</code>). For landslide cases, it predicted a landslide <code class="literal">24</code> times (value <code class="literal">1</code>) and wrongly predicted a safe zone <code class="literal">2</code> times (value <code class="literal">0</code>).</p><p>We can check the accuracy of the model in the following way:</p><pre class="programlisting">sum(diag(confusion))/sum(confusion)</pre><p>We see that the accuracy is higher than that of the logistic regression model now; in fact, it is <code class="literal">0.95</code>:</p><div class="mediaobject"><img src="/graphics/9781788991674/graphics/ddf15706-ec23-4f18-b4fc-09f3b063ae38.png" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec29"></a>Random forest</h4></div></div></div><p>With random forest classification, we build a <span>number</span><a id="id325945966" class="indexterm"></a> of decision trees on training samples (sampling with replacement), and for each split on the tree, a random sample of predictors is chosen. Random forests generally perform very well with classifications. But, for our case, as we have only two predictors, we will not <span>see</span><a id="id325945975" class="indexterm"></a> any improvement. In practical cases, if we took more predictors of landslides, such as the <span class="strong"><strong>normalized difference vegetation index</strong></span> (<span class="strong"><strong>NDVI</strong></span>), aspect, and so on, this algorithm would show (for most cases) improved performance.</p><p> </p><p> </p><p>Similar to what we did with CART, we build the model on the <code class="literal">training</code> dataset and test its accuracy on the <code class="literal">test</code> dataset. Now, we build a random forest using the <code class="literal">randomForest()</code> function of the <code class="literal">randomForest</code> package:</p><pre class="programlisting">library(randomForest)
rf = randomForest(hazard ~ ., train)</pre><p><code class="literal">rf</code> is a random forest object, and we fit <code class="literal">rf</code> on the <code class="literal">test</code> data to test its accuracy:</p><pre class="programlisting">pred = predict(rf, test, type = "class")
mean(pred == test$hazard)</pre><p>Using <code class="literal">predict()</code>, we predict classes on the <code class="literal">test</code> dataset, and using <code class="literal">mean(pred == test$hazard)</code>, we get the accuracy of this classifier. As before, the accuracy is still <code class="literal">0.95</code>.</p></div></div></div>