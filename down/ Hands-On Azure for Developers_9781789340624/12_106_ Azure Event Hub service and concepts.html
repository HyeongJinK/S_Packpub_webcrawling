<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec103"></a>Azure Event Hub service and concepts</h2></div></div><hr /></div><p>Nowadays, we <span>gather</span><a id="id325919339" class="indexterm"></a> more and more data, which has to be aggregated, processed, and stored somewhere. This implies using services that can handle increasing loads, scale to growing demands, and offer the smallest latency available. All these requirements are often mentioned when building so-called big data pipelines—parts of a system designed to process as much data as possible, so it is later accessible by tools such as Hadoop, Spark, ML, AI, and so on. If you are looking for a service in Azure that can handle millions of messages per second, Azure Event Hub<span class="emphasis"><em> </em></span>is the right choice. In this chapter, you will learn the basics of this Azure component and get familiar with messaging solutions in Azure. </p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec122"></a>Azure Event Hub concepts</h3></div></div></div><p>In general, Azure Event Hub<span class="emphasis"><em> </em></span>is a <span>simple</span><a id="id325125000" class="indexterm"></a> service that is built on top of two concepts:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Event publishers</li><li style="list-style-type: disc">Event processor hosts</li></ul></div><p>Of course, these are not the only topics we will cover here. However, before we proceed, I would like to focus a little bit on the distinction between a publisher<span class="strong"><strong> </strong></span>and a processor:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Publisher</strong></span>:<span class="strong"><strong> </strong></span>This is an entity that <span>sends</span><a id="id325128279" class="indexterm"></a> data to an instance of Azure Event Hub. It can use one of the two available protocols (HTTP or AMQP) and is unaware of the current Event Hub capabilities.</li><li style="list-style-type: disc"><span class="strong"><strong>Processor</strong></span>: An entity that reads events from Azure Event Hub<span class="emphasis"><em> </em></span>as <span>they</span><a id="id325128296" class="indexterm"></a> become available. It uses AMQP for communication and relies on additional concepts such as consumer groups<span class="strong"><strong> </strong></span>and partitions.</li></ul></div><p>The following <span>shows</span><a id="id325128344" class="indexterm"></a> how Azure Event Hub<span class="emphasis"><em> </em></span>works:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/51bcb6e3-b8ac-48b6-8cd3-b54d119373fd.png" /></div><p>As you can see, there are an additional two concepts mentioned here:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Partition</strong></span>: Each partition is an <span>independent</span><a id="id325128377" class="indexterm"></a> event log that stores data separately. In general, it is Event Hub's responsibility to ensure that each event sharing the same partition key is stored within the same partition in order. Of course, you can set this value by yourself—in such a scenario you have to make sure you are not overloading one specific partition.</li><li style="list-style-type: disc"><span class="strong"><strong>Consumer group</strong></span>: If you would like to <span>allow</span><a id="id325128391" class="indexterm"></a> separate processors to consume events separately, you have to use different consumer groups to do so. </li></ul></div><p>As you can see, Azure Event Hub<span class="emphasis"><em> </em></span>does not use things such as instance topics for distributing data—instead it acts as a single event pipeline that you can read anytime with high throughput. To define this value, Event Hub uses a <span>concept</span><a id="id325143089" class="indexterm"></a> named <span class="strong"><strong>throughput units</strong></span> (<span class="strong"><strong>TU</strong></span>). 1 TU<span class="strong"><strong> </strong></span>is defined as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Up to 1 MB/s or 1,000 events for ingress</li><li style="list-style-type: disc">Up to 2 MB/s or 4,096 events for egress</li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip148"></a>Note</h3><p>Note that Azure Event Hub<span class="emphasis"><em> </em></span>shares TUs for all consumer groups you are using. If you have 1 TU and 5 consumer groups, the maximum egress will be divided among all consumers (so when all 5 read events at the same time, a maximum of 400 events per second will be available).</p></div><p>If you happen to exceed the available limit, Event Hub will start throttling your requests, finally returning <code class="literal">ServerBusyException</code>. This is, however, true only for incoming events—for egress you just cannot read more than the current TU value allows.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note149"></a>Note</h3><p>By default, you cannot have more than 20 TUs per Event Hub namespace. However, this is just a soft limit—you can extend it by contacting Azure support.</p></div><p>Now, let's focus a little bit on partitions. Each hub in Event Hub can have a maximum number of 32 partitions. You may wonder what this implies—in fact, this gives some additional options:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Because each partition can have a corresponding consumer, by default, you can process messages in parallel using 32 consumers.</li><li style="list-style-type: disc">Because you cannot change the number of partitions after the hub's creation, you have to carefully design it at the very beginning.
</li><li style="list-style-type: disc">Using the maximum number of partitions by default is not always the best option—it should reflect the number of readers you are planning to support. If you choose too many, they will start to race to acquire a lease on a partition.</li></ul></div><p>The following shows globally how data could be stored among different partitions within a hub:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/4a2c66b0-2beb-4847-9a89-66d179216194.png" /></div><p>As mentioned earlier, each partition can grow independently—what is more, each one has an individual offset<span class="strong"><strong> </strong></span>value. What is an offset<span class="strong"><strong> </strong></span>value? You could think about it as a pointer to some specific point within a log—if it stores events numbered from 1 to 10,000 and you have read 1,000, an offset<span class="strong"><strong> </strong></span>value will be 1,001. In such a case, it means that a reader should start reading data from the 1,001<sup>st</sup> event.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note150"></a>Note</h3><p>In fact, offset and consumer groups are connected with each other conceptually—each consumer group has an individual offset value; that is why,by introducing it, you can read all available logs once more.</p></div><p>However, remember that to set an offset, a consumer has to perform a checkpoint. If it fails to do so, the next time it connects, it will read all the data once more. This is very important if you want to avoid processing duplicates—either you have to implement a very durable process for processing events, so you can be sure that a checkpoint will be performed even if something fails, or you need to have a mechanism for detecting duplicates.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip151"></a>Note</h3><p>If you have to do so, you can easily read previous events by providing the offset<span class="strong"><strong> </strong></span>value you are interested in when starting a processor.</p></div><p> </p><p>The last thing to consider for now is Azure Event Hub's<span class="emphasis"><em> </em></span>retention policy for stored events. By default (or in other words, by using the Basic<span class="strong"><strong> </strong></span>tier), events can be stored only for 24 hours to be consumed; after that period, they are lost. Of course, it is possible to extend it by using the Standard tier; you will have an option to do so up to a maximum of 7 days from event retention. In general, you should avoid using this service as some kind of a standard queue or cache—its main purpose is to provide functionality for aggregating thousands of messages per second and pushing them further.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec123"></a>Azure Event Hub durability</h3></div></div></div><p>In many scenarios, Azure Event Hub<span class="emphasis"><em> </em></span>is one of the <span>main</span><a id="id325310692" class="indexterm"></a> entry points to the system, making it a critical component that should be replicated and highly available. In this particular service, the geo-disaster recovery feature is available when selecting the standard<span class="strong"><strong> </strong></span>tier and requires you to set up and configure the appropriate environment. To do so, you need to understand the following topics:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Alias</strong></span>: Instead of providing multiple connection strings, you can use an alias to make a connection with a single stable one.</li><li style="list-style-type: disc"><span class="strong"><strong>Failover</strong></span>: This is the process of initiating a switch between namespaces.</li><li style="list-style-type: disc"><span class="strong"><strong>Primary/secondary namespace</strong></span>: When using the Azure Event Hub<span class="emphasis"><em> </em></span>geo-disaster recovery feature, you have to define which namespace is the primary and which is the secondary one. The important thing here is that you can send events to both namespaces, but the second one remains passive—that means events from an active<span class="emphasis"><em> </em></span>namespace are not transferred.</li></ul></div><p>Now, to implement the feature in Event Hub, you can to do two things:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Monitor your primary namespace to detect any anomalies</li><li style="list-style-type: disc">Initiate failover</li></ul></div><p>Of course, if a disaster occurs, you will have to create a new pairing after finishing a failover.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip152"></a>Note</h3><p>You have to know the difference between outage, when there are temporary problems within a data center, and a disaster, which often means permanent damage and possible loss of data. The geo-disaster recovery feature is designed for disasters; in the case of an outage, you should implement another way of dealing with it, such as caching data locally.</p></div><p> </p></div></div>