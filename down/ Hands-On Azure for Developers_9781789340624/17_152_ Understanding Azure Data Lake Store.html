<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch17lvl1sec144"></a>Understanding Azure Data Lake Store</h2></div></div><hr /></div><p>When considering your storage solution, you <span>have</span><a id="id326088013" class="indexterm"></a> to take into account the amount of data you want to store. Depending on your answer, you may choose a different option from services available in Azure—Azure Storage, Azure SQL, or Azure Cosmos DB. There is also a variety of databases available as images for VMs (such as Cassandra or MongoDB); the ecosystem is quite rich so everyone can find what they are looking for. The problem arises when you do not have an upper limit for the amount of data stored or, considering the characteristics of today's applications, that amount grows so rapidly that there is no possibility to declare a safe limit, which we will never hit. For those kinds of scenario, there is a separate kind of storage named Data Lakes. They allow you to store data in its natural format, so it does not imply any kind of structure over information stored. In Azure, a solution for that kind of problem is named Azure Data Lake Store; in this chapter, you will learn the basics of this service, which allows you to dive deeper into the service and adjust it to your needs.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch17lvl2sec173"></a>Azure Data Lake Store fundamentals</h3></div></div></div><p>Azure Data Lake Store is called a hyper-scale repository for data for a reason—there is no limit when it comes to storing files. It can <span>have</span><a id="id325128277" class="indexterm"></a> any format, be any size, and store information structured differently. This is also a great model for big data analytics as you can store files in the way that is the best for your processing services (some prefer a small number of big files, some prefer many small files – choose what suits you the most). This is not possible for other storage solutions such as relational, NoSQL, or graph databases, as they always have some restrictions when it comes to saving unstructured data. Let's check an example comparison between Azure Data Lake Store and Azure Storage:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col /><col /><col /></colgroup><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><span class="strong"><strong>AZDS</strong></span></p></td><td style="border-bottom: 0.5pt solid ; "><p><span class="strong"><strong>Azure Storage</strong></span></p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><span class="strong"><strong>Limits</strong></span></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>No file size/number of files limits</p></td><td style="border-bottom: 0.5pt solid ; "><p>Maximum account capacity of 500 TBs, the maximum size of files</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p><span class="strong"><strong>Redundancy</strong></span></p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>LRS</p></td><td style="border-bottom: 0.5pt solid ; "><p>LRS/ZRS/GRS/RA-GRS</p></td></tr><tr><td style="border-right: 0.5pt solid ; "><p><span class="strong"><strong>API</strong></span></p></td><td style="border-right: 0.5pt solid ; "><p>WebHDFS</p></td><td style=""><p>Azure Blob Storage API</p></td></tr></tbody></table></div><p> </p><p>The important thing here is the redundancy—for now, the only model which Azure Data Lake Store supports is LRS. That means that, in the event of a disaster, you may lose data stored inside a single data center. To avoid that, you will have to implement your own policy to copy data to a replica. In fact, you have available two models—synchronous replication, as follows:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/d1dc0419-ba27-4cf7-8a12-1d0124ef21f1.png" /></div><p>Or you have asynchronous, as follows:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/463a96f9-2aa0-43cb-9ab9-c299bd5e05be.png" /></div><p>There are some obvious pros and cons of both solutions:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Synchronous</strong></span>: Ensures that a <span>copy</span><a id="id325143104" class="indexterm"></a> of data was saved to a replica, more difficult to handle when considering duplicates, and lower performance.</li><li style="list-style-type: disc"><span class="strong"><strong>Asynchronous</strong></span>: Data can be lost (because you will not move data to a <span>replica</span><a id="id325143117" class="indexterm"></a> before a disaster), better performance (because you just save without waiting for replication), and easier to handle.</li></ul></div><p> </p><p> </p><p>While replication may look better for Azure Storage, remember that the Azure Data Lake Store filesystem is based on HDFS—this allows for a seamless integration with many OSS tools, such as:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Apache Hive</li><li style="list-style-type: disc">Apache Storm</li><li style="list-style-type: disc">Apache Spark</li><li style="list-style-type: disc">MapReduce</li><li style="list-style-type: disc">Apache Pig</li><li style="list-style-type: disc"> And many more...!</li></ul></div><p>This gives you a much better ecosystem, tool-wise. If you want to store data inside Azure Data Lake Store and prefer to use HDInsights to perform analysis and transformations over your files, instead of other Azure tools, you can easily connect to your instance and start working on them.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note200"></a>Note</h3><p>Note that for now, ADLS supports HDInsight 3.2, 3.4, 3.5, and 3.6 distributions.</p></div><p>When it comes to accessing files stored inside an instance of Azure Data Lake Store, it leverages the POSIX-style permissions model; you basically operate on three different permissions, which can be applied to a file or a folder:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Read (R)</strong></span>: For reading data</li><li style="list-style-type: disc"><span class="strong"><strong>Write (W)</strong></span>: For writing data</li><li style="list-style-type: disc"><span class="strong"><strong>Execute (E)</strong></span>: Applicable to a folder, used to give read/write permissions in a folder context (such as creating children or listing files)</li></ul></div><p>We will cover more security concepts in the security section.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch17lvl2sec174"></a>Creating an Azure Data Lake Store instance</h3></div></div></div><p>To create an Azure Data Lake <span>Store</span><a id="id325304721" class="indexterm"></a> instance, you will need to search for <code class="literal">Azure Data Lake</code><span class="emphasis"><em> </em></span>in the portal and fill in the following form:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/fca26449-8ead-4ba7-ba58-16b368fec626.png" /></div><p>However, you need to take into consideration the following facts:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><strong class="userinput"><code>Location</code></strong>: Currently there are four different locations available—<strong class="userinput"><code>Central US</code></strong>, <strong class="userinput"><code>East US 2</code></strong>, <strong class="userinput"><code>North Europe</code></strong>, and <strong class="userinput"><code>West Europe</code></strong>. Do remember that transferring data between DCs costs you extra money, so if you plan to use this service, plan your architecture carefully.</li><li style="list-style-type: disc"><strong class="userinput"><code>Pricing package</code></strong>: There are two pricing models available—<strong class="userinput"><code>Pay-as-You-Go</code></strong> and fixed <strong class="userinput"><code>Monthly commitment</code></strong>. They have pros and cons (fixed pricing is in general cheaper but it is not that flexible when your application grows, it is difficult sometimes to plan required capacity ahead), so try to understand as best you can the characteristics of your applications using that service to choose whatever suits you the most.
</li><li style="list-style-type: disc"><strong class="userinput"><code>Encryption settings</code></strong>: By default, encryption of your data is <strong class="userinput"><code>Enabled</code></strong> for a new account. While it is possible to disable it, in most cases you will stay with the default settings. What is more, there are two models of encryption—either you let the service  manage encryption keys for you, or you provide your own keys (stored inside Azure Key Vault).</li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip201"></a>Note</h3><p>Since it is a good idea to rotate encryption keys, you may face the issue when, due to a failure, even redundant copies of your data are inaccessible. While it is possible to recover from backup data, you will need an old key to decrypt it. Because of that, it is advisable to store a copy of old keys in case of unexpected outages.</p></div><p>When you click on the <strong class="userinput"><code>Create </code></strong>button, your service will be provisioned—you can access it to see the overview:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/8f085a2e-89d2-4775-96e4-7ee8e352b52e.png" /></div><p> </p><p> </p><p>Since it is freshly created, we cannot see different metrics which describe how much data we are storing. What is more, the current cost is 0 USD—this is, of course, something we expected as no file was uploaded to the service. From the UI perspective, there is not much that we can do for now; some additional features such as <strong class="userinput"><code>Firewall </code></strong>will be described later in that chapter. Besides the portal, you can also easily access your instance of Azure Data Lake <span>Store</span><a id="id325317143" class="indexterm"></a> by using Microsoft Azure Storage Explorer:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/f7163c3a-7ded-4a1a-80bc-44579067fc12.png" /></div><p>It makes things much easier when you have multiple files and folders and you try to navigate through them.</p></div></div>