<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch18lvl1sec155"></a>Scaling Azure Service Fabric</h2></div></div><hr /></div><p>We have discussed two different models for <span>scaling</span><a id="id325115447" class="indexterm"></a> by working with two separate Azure services; Azure App Services and Azure Functions.</p><p>They are quite different when it comes to adding new instances or improving hardware performance, in that they introduce multiple concepts, and offer a different level of flexibility. In the last section of this chapter, we will cover one more service, Azure Service Fabric. This particular Azure product behaves in a slightly different manner when it comes to scaling up or out, as it requires you to manage VMs. In addition, a distinct set of skills is necessary to perform this operation seamlessly and in the right fashion.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch18lvl2sec190"></a>Scaling a cluster manually</h3></div></div></div><p>Clusters in Azure Service <span>Fabric</span><a id="id325115429" class="indexterm"></a> can be scaled in two ways:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Manually</strong></span>: By choosing appropriate options in the cluster configuration</li><li style="list-style-type: disc"><span class="strong"><strong>Programatically</strong></span>: By using the Azure SDK</li></ul></div><p>In fact, the characteristics of your cluster are selected at the very beginning, when you are choosing node types and their configuration, as shown in the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/3f357350-44d8-4f68-a76c-e42ecd4672b8.png" /></div><p>Scaling Azure Service Fabric service is similar to scaling VMs, as it is based on nodes containing an unspecified number of virtual machines, which means you really depend on scale sets. </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip215"></a>Note</h3><p>It is always better to set up a cluster that will handle the planned load than scale it under pressure, especially when you require strict transactional assurances, which may impact scaling time. Take a look at the <span class="emphasis"><em>Further reading</em></span><span class="strong"><strong> </strong></span>section, where you will find an article describing efficient cluster planning.</p></div><p>When using scaling with Azure Service Fabric, remember that adding machines to the scale set always takes time. Therefore, consider planning such operations early, so the impact on the <span>current</span><a id="id324830081" class="indexterm"></a> operations will be minimized. To actually scale out your cluster, you have use the <strong class="userinput"><code>Scaling </code></strong>feature of the scale set, which was created with it, as shown in the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/3ec9785d-7c91-4ff3-939a-4a4240aafade.png" /></div><p>The other option to perform such operation is to use ARM template with the following snippet:</p><pre class="programlisting">"resources":[
    {
      "type":"Microsoft.Compute/virtualMachineScaleSets",
      "apiVersion":"2017-03-30",
      "name":"[parameters('&lt;scale-set-name&gt;')]",
      "location":"[resourceGroup().location]",
      "sku":{
        "name":"[parameters('&lt;sku&gt;')]",
        "tier":"&lt;tier&gt;",
        "capacity":"[parameters('&lt;capacity&gt;')]"
      }
    }
]</pre><p>By providing the <code class="literal">&lt;capacity&gt; </code>value, you may easily change the number of virtual machines powering your SF cluster.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch18lvl2sec191"></a>Using Azure SDK to scale your cluster</h3></div></div></div><p>Another option to scale your cluster is to use the <span>Azure</span><a id="id325124985" class="indexterm"></a> compute SDK. You may wonder what are the use cases for that particular feature—all in all, we already have manual/auto-scaling available. However, there are more advanced scenarios, which may be suitable for scaling using your own controller:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Scaling using a custom metric, which is not available for autoscaling.</li><li style="list-style-type: disc">Performing additional operations before scaling can happen.</li><li style="list-style-type: disc">Full control over scaling operation in case of critical workloads.</li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note216"></a>Note</h3><p>To get the Azure compute SDK, you have to download the following NuGet package: Microsoft.Azure.Management.Fluent available at: <a class="ulink" href="https://www.nuget.org/packages/Microsoft.Azure.Management.Fluent/" target="_blank">https://www.nuget.org/packages/Microsoft.Azure.Management.Fluent/</a>. Similar libraries can be found for other languages (like Java or Python—you can find them in the link in the <span class="emphasis"><em>Further Reading</em></span> section).</p></div><p>To scale out your cluster, you may use the following code snippet:</p><pre class="programlisting">var vmScaleSet = AzureClient.VirtualMachineScaleSets.GetById(ScaleSetId);
var capacity = (int)Math.Min(MaximumNodeCount, vmScaleSet.Capacity + 1);
vmScaleSet.Update().WithCapacity(capacity).Apply(); </pre><p>The same can be used for Java:</p><pre class="programlisting">vmScaleSet.update().withCapacity(capacity).apply();</pre><p>As you can see, it is a pretty simple piece of code—you just need to obtain the current scale set ID to get a reference to it, and then change its capacity. In this example, I used a value of <code class="literal">1</code>, but there is nothing that prevents you from using other numbers.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip217"></a>Note</h3><p>With the preceding example, you can also scale down your cluster. However, remember that you should not scale down below the cluster's reliability tier. If you do so, you no longer can rely on it and may destabilize it.</p></div><p>If you are using a higher reliability tier than bronze<span class="strong"><strong>,</strong></span> you do not need to worry about unused machines as they will be automatically removed. Otherwise, you have to do it manually. To do so, you actually have to know which VMs are not currently used. To remove a node that is no <span>longer</span><a id="id325128291" class="indexterm"></a> required, you can use the following operations:</p><pre class="programlisting">await client.ClusterManager.DeactivateNodeAsync(node.NodeName, NodeDeactivationIntent.RemoveNode);
scaleSet.Update().WithCapacity(capacity).Apply(); 
await client.ClusterManager.RemoveNodeStateAsync(node.NodeName);</pre><p>They basically do three different things:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Deactivate and remove a node from a cluster</li><li>Decrease a scale set capacity</li><li>Remove a node state</li></ol></div><p>To find a node to be removed, you have to query a cluster and seek the most recent machine added:</p><pre class="programlisting">using (var client = new FabricClient())
{
    var node = (await client.QueryManager.GetNodeListAsync())
        .Where(n =&gt; n.NodeType.Equals(NodeTypeToScale, StringComparison.OrdinalIgnoreCase))
        .Where(n =&gt; n.NodeStatus == System.Fabric.Query.NodeStatus.Up)
        .OrderByDescending(n =&gt;
        {
            var instanceIdIndex = n.NodeName.LastIndexOf("_");
            var instanceIdString = n.NodeName.Substring(instanceIdIndex + 1);
            return int.Parse(instanceIdString);
        })
        .FirstOrDefault();
}</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note218"></a>Note</h3><p>You may wonder why the most recently added machine is selected to be the victim of the scaling operation. This is because work was delegated to it as the result of higher cluster utilization. Originally it was not a part of the set. and once it finished its job, it can be removed.</p></div></div></div>