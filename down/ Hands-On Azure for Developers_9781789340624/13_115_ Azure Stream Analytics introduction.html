<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec111"></a>Azure Stream Analytics introduction</h2></div></div><hr /></div><p>In the previous chapter, we <span>discussed</span><a id="id325217432" class="indexterm"></a> Azure Event Hub, which is a solution for receiving and processing thousands of messages per second, by introducing the implementation of event processor hosts. While it is great for workloads such as big data pipelines or IoT scenarios, it is not a solution to everything, especially if you want to avoid hosting VMs. Scaling such architectures can be cumbersome and nonintuitive; this is why there is Azure Stream Analytics, which is an event-processing engine designed for high volumes of data. It fills a gap where other services such as Event Hub or IoT Hub do not perform well (or where to do so they require much more skill and/or more sophisticated architecture), particularly for real-time analytics, anomaly detection, and geospatial analytics. It is an advanced tool for advanced tasks, which will greatly improve your cloud and message-processing skills.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec131"></a>Stream ingestions versus stream analysis</h3></div></div></div><p>To get started, we will <span>compare</span><a id="id325117139" class="indexterm"></a> two topics:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Stream ingestion</strong></span>: This is a process <span>where</span><a id="id325117156" class="indexterm"></a> you introduce a service/API for receiving messages from your producers. Such a service is designed to ingest data only—it does nothing more (such as transforming or analyzing). To perform any kind of analysis of ingested data, you have to introduce your own processors.</li><li style="list-style-type: disc"><span class="strong"><strong>Stream analysis</strong></span>: This is a process where you actually analyze the data. You search for anomalies, duplicates, or malformed data, process it, and push it further to other services for storing, presenting, and triggering other actions.</li></ul></div><p>To make things even clearer, we can take a look at the following diagram:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/f07f45fa-be17-4fa6-b98d-1875d5b04fce.png" /></div><p>It shows the four steps of data processing:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Produce</strong></span>: Where data is actually <span>produced</span><a id="id325120019" class="indexterm"></a> by different services, devices, and clients</li><li style="list-style-type: disc"><span class="strong"><strong>Ingest</strong></span>: This is when the data is consumed from different sources</li><li style="list-style-type: disc"><span class="strong"><strong>Analyze</strong></span>: During this step data is analyzed, transformed, and routed to appropriate services and components</li><li style="list-style-type: disc"><span class="strong"><strong>Use</strong></span>: Storing, displaying, and processing data further in other services, such as PowerBI, Azure Functions, and many others</li></ul></div><p>While Azure Event Hub or Azure IoT Hub is a part of the ingest step, Azure Stream Analytics is responsible for <span class="strong"><strong>analyzing</strong></span>.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip159"></a>Note</h3><p>Note that you are not limited to Azure services when it comes to ingesting data. In such a scenario, you can also use any kind of queue or API, as long as it is capable of processing thousands of events per second.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec132"></a>Azure Stream Analytics concepts</h3></div></div></div><p>In Azure Stream Analytics, the most <span>important</span><a id="id325122105" class="indexterm"></a> concept is a <span class="strong"><strong>stream</strong></span>. You can <span>think</span><a id="id325124984" class="indexterm"></a> about it as a flow of many events carrying data—they do not necessarily have to be the same or share schema. Analyzing such a stream is not a trivial task. If you have to decode hundreds of thousands of events, the process has to be quick, robust, and reliable. We will discuss the main concepts of this service to verify whether it is capable of acting as our analyzing solution and the main events processor:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Fully managed</strong></span>: Azure Stream <span>Analytics</span><a id="id325124999" class="indexterm"></a> is a fully managed platform as a service(PaaS), so you do not have to worry about provisioning resources and scaling it—the runtime will take care of that, so you can focus on providing optimal queries for data analysis.</li><li style="list-style-type: disc"><span class="strong"><strong>An SQL-based query language</strong></span>: To analyze data, Azure Stream <span>Analytics</span><a id="id325125013" class="indexterm"></a> uses an SQL-based query language, which enables developers to build advanced procedures quickly, which extract from a stream exactly what they want. Additionally, you can bring your own extensions such as ML solutions or user-defined aggregates to perform extra calculations, using tools unavailable to the service.</li><li style="list-style-type: disc"><span class="strong"><strong>Performance</strong></span>: Azure Stream <span>Analytics</span><a id="id325128270" class="indexterm"></a> is focused on <span class="strong"><strong>streaming units </strong></span>(<span class="strong"><strong>SUs</strong></span>) instead of some hardcoded values of CPUs or memory. This is because it is <span>designed</span><a id="id325128285" class="indexterm"></a> to provide stable performance and recurrent execution time. What is more, thanks to this concept, you can easily scale your solution to meet your demands.</li><li style="list-style-type: disc"><span class="strong"><strong>Low cost of ownership</strong></span>: In Azure Stream <span>Analytics</span><a id="id325128332" class="indexterm"></a> you pay only for what you choose. As pricing depends on the number of SUs per hour, there is no additional cost to be incorporated in the overall payment.</li></ul></div><p>There are also some extra technical concepts (such as input/output types, checkpoints, or replays), which we will cover in the next parts of this chapter. To see the big picture of the whole pipeline using Azure Stream Analytics, please check the following image:</p><div class="mediaobject"><img src="/graphics/9781789340624/graphics/fffba287-98fc-43e1-bfeb-946c1598c62c.png" /></div><p>Of course, there could be other references on this picture (additional services, user functions, and analyzers), but for the sake of simplicity, I did not include them.</p></div></div>