<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec68"></a>Understanding the transaction log</h2></div></div><hr /></div><p>Every modern database <span>system</span><a id="id326644541" class="indexterm"></a> provides functionality to make sure that the system can survive a crash in case something goes wrong or somebody pulls the plug. This is true for filesystems and database systems alike.</p><p>PostgreSQL also provides a means to ensure that a crash cannot harm the data's integrity or the data itself. It is guaranteed that if the power cuts out, the system will always be able to come back on again and do its job.</p><p>The means to providing this kind of security is achieved by the <span class="strong"><strong>Write Ahead Log</strong></span> (<span class="strong"><strong>WAL</strong></span>), or <span class="strong"><strong>xlog</strong></span>. The idea is to not write into the data file directly, but instead <span>write</span><a id="id325870750" class="indexterm"></a> to the <span>log</span><a id="id325870757" class="indexterm"></a> first. Why is that important? Imagine that we are writing some data, as follows:</p><pre class="programlisting"><span class="strong"><strong>INSERT INTO data ... VALUES ('12345678');</strong></span></pre><p>Let's assume that data was written directly to the data file. If the operation fails midway, the data file would be corrupted. It might contain half-written rows, columns without index pointers, missing commit information, and so on. As hardware does not really guarantee atomic writes of large chunks of data, a way has to be <span>found</span><a id="id325870772" class="indexterm"></a> to make this more robust. By writing to the log instead of writing to the file directly, this problem can be solved.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note73"></a>Note</h3><p>In PostgreSQL, the transaction log consists of records.</p></div><p>A single write can consist of various records that all have a checksum and are chained together. A single transaction might contain a B-tree, index, storage manager, commit records, and a lot more. Each type of object has its own <code class="literal">WAL</code> entries and ensures that the object can survive a crash. If there is a crash, PostgreSQL will start up and repair the data files based on the transaction <span>log</span><a id="id325870791" class="indexterm"></a> to ensure that no permanent corruption is allowed to happen.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec96"></a>Looking at the transaction log</h3></div></div></div><p>In PostgreSQL, the <code class="literal">WAL</code> can usually be <span>found</span><a id="id326084820" class="indexterm"></a> in the <code class="literal">pg_wal</code> directory in the data directory, unless specified otherwise on <code class="literal">initdb</code>. In older versions of PostgreSQL, the <code class="literal">WAL</code> directory was called <code class="literal">pg_xlog</code>, but with the introduction of PostgreSQL 10.0, the directory has been renamed.</p><p>The reason for this is that more often than not, people would delete the content of the <code class="literal">pg_xlog</code> directory, which of course led to serious issues and potential database corruption. The community has therefore taken the unprecedented step of renaming a directory inside a PostgreSQL instance. The hope is to make the name scary enough that nobody dares to delete the content again.</p><p>The following listing shows what the <code class="literal">pg_wal</code> directory looks as follows:</p><pre class="programlisting"><span class="strong"><strong>[postgres@zenbook pg_wal]$ pwd </strong></span>
<span class="strong"><strong>/var/lib/pgsql/11/data/pg_wal </strong></span>
<span class="strong"><strong>[postgres@zenbook pg_wal]$ ls -l </strong></span>
<span class="strong"><strong>total 688132 </strong></span>
<span class="strong"><strong>-rw-------. 1 postgres postgres 16777216 Jan 19 07:58 0000000100000000000000CD </strong></span>
<span class="strong"><strong>-rw-------. 1 postgres postgres 16777216 Jan 13 17:04 0000000100000000000000CE </strong></span>
<span class="strong"><strong>-rw-------. 1 postgres postgres 16777216 Jan 13 17:04 0000000100000000000000CF </strong></span>
<span class="strong"><strong>-rw-------. 1 postgres postgres 16777216 Jan 13 17:04 0000000100000000000000D0 </strong></span>
<span class="strong"><strong>-rw-------. 1 postgres postgres 16777216 Jan 13 17:04 0000000100000000000000D1 </strong></span>
<span class="strong"><strong>-rw-------. 1 postgres postgres 16777216 Jan 13 17:04 0000000100000000000000D2</strong></span></pre><p>What we can see is that the transaction log is a 16 MB file that consists of 24 digits. The numbering is hexadecimal. As we can see, CF is followed by D0. The files are always a fixed size.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note74"></a>Note</h3><p>One thing to notice is that in PostgreSQL, the number of transaction log files is not related to the size of a transaction. You can have a very small set of transaction log files and still run a multi-TB transaction easily.</p></div><p>Traditionally, the <code class="literal">WAL</code> typically consists of 16 MB files. However, since the introduction of PostgreSQL, the size of a <code class="literal">WAL</code> segment can now be set at <code class="literal">initdb</code>. In some cases, this can speed things up. Here is how it works. The following example shows us how the <code class="literal">WAL</code> file size can be <span>changed</span><a id="id326136670" class="indexterm"></a> to 32 MB:</p><pre class="programlisting"><span class="strong"><strong>initdb -D /pgdata --wal-segsize=32</strong></span></pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec97"></a>Understanding checkpoints</h3></div></div></div><p>As I mentioned earlier, every <span>change</span><a id="id326136692" class="indexterm"></a> is written to the <code class="literal">WAL</code> in binary format (it does not contain SQL). The problem is this—the database server cannot keep writing to the <code class="literal">WAL</code> forever as it will consume more and more space over time. So, at some point, the transaction log has to be recycled. This is done by a <span class="strong"><strong>checkpoint</strong></span>, which happens automatically in the background.</p><p>The idea is that when data is written, it first goes to the transaction log, and then a dirty buffer is put into shared buffers. Those dirty buffers have to go to disk and are <span>written</span><a id="id326234439" class="indexterm"></a> out to the data files by the background writer or during a checkpoint. As soon as all of the dirty buffers up to that point have been written, the transaction log can be deleted.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note75"></a>Note</h3><p>Please, never <span class="emphasis"><em>ever</em></span> delete transaction log files manually. In the event of a crash, the database server will not be able to start up again, and the amount of disk space needed will be reclaimed anyway as new transactions come in. Never touch the transaction log manually. PostgreSQL takes care of things on its own, and doing things in there is really harmful.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec98"></a>Optimizing the transaction log</h3></div></div></div><p>Checkpoints happen automatically and are triggered by the server. However, there are <span>configuration</span><a id="id326234462" class="indexterm"></a> settings that decide when a checkpoint is initiated. The following parameters in the <code class="literal">postgresql.conf</code> file are in charge of handling checkpoints:</p><pre class="programlisting"><span class="strong"><strong>#checkpoint_timeout </strong></span><span class="strong"><strong>= 5min            # range 30s-1d</strong></span>
<span class="strong"><strong>#max_wal_size </strong></span><span class="strong"><strong>= 1GB</strong></span>
<span class="strong"><strong>#min_wal_size </strong></span><span class="strong"><strong>= 80MB</strong></span></pre><p>There are two reasons to initiate a checkpoint:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>We can run out of time or we can run out of space.</li><li>The maximum time between two checkpoints is defined by the <code class="literal">checkpoint_timeout</code> variables.</li></ol></div><p> </p><p>The amount of space provided to store transaction logs will vary between the <code class="literal">min_wal_size</code> and <code class="literal">max_wal_size</code> variables. PostgreSQL will automatically trigger checkpoints in a way that the amount of space really needed will be between those two numbers.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note76"></a>Note</h3><p>The <code class="literal">max_wal_size</code> variable is a soft limit and PostgreSQL may (under heavy load) temporarily need a bit more space. In other words, if our transaction log is on a separate disk, it makes sense to make sure that there is actually a bit more space available to store the <code class="literal">WAL</code>.</p></div><p>How can somebody tune the transaction log in PostgreSQL 9.6 and 10.0? In 9.6, some changes have been made to the background writer and check-pointing machinery. In older versions, there were some use cases where smaller checkpoint distances could actually make sense from a performance point of view. In 9.6 and beyond, this has pretty much changed, and wider checkpoint distances are basically always highly favorable because many optimizations can be applied at the database and OS-level to speed things up. The most noteworthy optimization is that blocks are sorted before they are written out, which greatly reduces random I/O on mechanical disks.</p><p>But there's more. Large checkpoint distances will actually decrease the amount of <code class="literal">WAL</code> created. Yes, that's right—larger checkpoint distances will lead to less <code class="literal">WAL</code>.</p><p>The reason for this is simple. Whenever a block is touched after a checkpoint for the first time, it has to be sent to the <code class="literal">WAL</code> completely. If the block is changed more often, only the changes make it to the log. Larger distances basically cause fewer full-page writes, which in turn reduces the amount of <code class="literal">WAL</code> created in the first place. The difference can be quite substantial, as can be seen in one of my <span>blog</span><a id="id326300503" class="indexterm"></a> posts at <a class="ulink" href="https://www.postgresql-support.com/checkpoint-distance-and-amount-of-wal/" target="_blank">https://www.postgresql-support.com/checkpoint-distance-and-amount-of-wal/</a>.</p><p>PostgreSQL also allows us to configure whether checkpoints should be short and intense or whether they should be spread out over a longer period. The default value is <code class="literal">0.5</code>, which means that the checkpoint should be done in a way that the process has finished halfway between the current and the next checkpoint. The following listing show <code class="literal">checkpoint_completion_target</code>:</p><pre class="programlisting"><span class="strong"><strong>#checkpoint_completion_target </strong></span><span class="strong"><strong>= 0.5</strong></span></pre><p>Increasing this value basically means that the <span>checkpoint</span><a id="id326374075" class="indexterm"></a> is stretched out and less intensive. In many cases, a higher value has proven beneficial for flattening out I/O spikes caused by intense check pointing.</p></div></div>