<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec10"></a>What is new in PostgreSQL 11.0?</h2></div></div><hr /></div><p>PostgreSQL 11 was released in the fall of 2018 and provides users with a couple of modern features. These are useful to professionals and beginners alike. PostgreSQL 11 is the second major release following the <span>new numbering scheme</span> introduced by the PostgreSQL community. The next major release of PostgreSQL after version 11 will be 12. The <span>service</span><a id="id325939060" class="indexterm"></a> releases will be called <span class="strong"><strong>PostgreSQL 11.1</strong></span>, <span class="strong"><strong>11.2</strong></span>, <span class="strong"><strong>11.3</strong></span>, and so on. Compared to the pre-10 world, this is a major change, which should be pointed out.</p><p>Which version should you use? The recommendation is to always use the most recent release. There is no point in getting started with, say, PostgreSQL 9.6 or so anymore. If you are new to PostgreSQL, begin with version 11. There is no such thing known as bugs in PostgreSQL—the community will always provide you with working code so there is no need to be afraid of PostgreSQL 10 or PostgreSQL 11. It just works.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec2"></a>Understanding the new database administration functions</h3></div></div></div><p>PostgreSQL 11 has many new <span>features</span><a id="id325939705" class="indexterm"></a> that can help the <span>administrator</span><a id="id325939714" class="indexterm"></a> reduce work and run the system more reliably and in a more robust way.</p><p><span>One of the features</span> that is supposed to help people to run even more efficient <span>databases</span><a id="id325939729" class="indexterm"></a> is the ability to configure the size of database instances, commonly known as <span class="strong"><strong>WAL-s</strong></span><span class="strong"><strong>egments.</strong></span></p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec0"></a>Using configurable WAL-segment sizes</h4></div></div></div><p>Since PostgreSQL was <span>introduced</span><a id="id325943162" class="indexterm"></a> 20 years ago, the size of a single WAL file has always been 16 MB. In the beginning, it was even a compiled in limit, which was <span>later</span><a id="id325943171" class="indexterm"></a> changed to a compile-time option. Starting with PostgreSQL 11 the size of those WAL segments can be changed at instance creation, which gives administrators an additional knob to configure and optimize PostgreSQL. Here is how it works. The following example shows how to configure the WAL-segment size when running initdb: </p><pre class="programlisting"><span class="strong"><strong>initdb -D /pgdata --wal-segsize=32</strong></span></pre><p>The <code class="literal">initdb</code> command is the tool that is called to create a database instance. It is usually the call you see, if hidden by some operating system scripts provided by your favorite Linux distribution, Windows, or whatever you like to use. However, <code class="literal">initdb</code> now has an option to pass the desired WAL-segment size directly to the program.</p><p> </p><p>As I have already mentioned, the default size is 16 MB; hence, in most cases, it makes sense to use larger segments to improve performance. There is no point in using smaller ones unless you are running a really, really small database instance on an embedded system.</p><p>What is the real performance impact going to be? As always, this really depends on what you are doing. If you are a running a database system facing 99% reads, the impact of larger WAL-segments will be zero. Yes, you heard it right—ZERO. If you are facing writes while your system is 95% idle and not under severe load, the impact will still be zero or close to zero. You will only be able to witness gains if you are running a heavy, write-intense workload. Then, and only then, might a change be worth it. If you are only running a couple of online forms visited by an occasional customer—why bother? The new <span>feature</span><a id="id325943202" class="indexterm"></a> will only show its strength when there are many changes <span>leading</span><a id="id325943210" class="indexterm"></a> to a lot of WAL.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec1"></a>Larger queryid in pg_stat_statements</h4></div></div></div><p>If you really want to dig into PostgreSQL performance, <code class="literal">pg_stat_statements</code> is the tool to look at. Personally, I consider it to be the <span>gold</span><a id="id325945516" class="indexterm"></a> standard, that is, if <span>you</span><a id="id325945525" class="indexterm"></a> really want to figure out what is going on in the system. The <code class="literal">pg_stat_statements</code> command is loaded via <code class="literal">shared_preload_libraries</code> as soon as PostgreSQL starts and aggregates statistics about queries running in your server. It will instantly show you if something goes wrong. </p><p>The <code class="literal">pg_stat_statements</code> command provides a field called <code class="literal">queryid</code>, which used to be a 32-bit identifier up to now. In some cases, this has led to problems because it is possible that keys collide in certain cases. Magnus Hagander calculated in one of his papers that after running 3 billion different queries, around 50,000 collisions could be expected. By introducing a 64-bit<code class="literal">queryid</code>, this number is expected to drop to around 0.25 conflicts after 3 billion different types of queries, which is a substantial improvement.</p><p>Keep in mind that you might have to update your scripts if you are moving to PostgreSQL 11 and also if you are using <code class="literal">pg_stat_statements</code> to track down performance problems.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec3"></a>Improved indexing and better optimization</h3></div></div></div><p>PostgreSQL 11 offers <span>more</span><a id="id325945564" class="indexterm"></a> than just a couple of <span>improved</span><a id="id325945573" class="indexterm"></a> functions to handle administration. There is also improved functionality around indexes. One of the most important <span>features</span><a id="id325945925" class="indexterm"></a> is related to indexes and statistics.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec2"></a>Expression index statistics</h4></div></div></div><p>If you are running a <span>simple</span><a id="id325945941" class="indexterm"></a> query, PostgreSQL will optimize it by looking at internal statistics. Here is an example:</p><pre class="programlisting"><span class="strong"><strong>SELECT * FROM person WHERE gender = 'female';</strong></span></pre><p>In this case, PostgreSQL will consult the internal stats and estimate the number of girls in the table. If the number is low, PostgreSQL will consider an index. If the majority are female, PostgreSQL will consider a sequential scan instead of an index. Statistics are available per column. In addition, it is also possible to keep track of cross-column statistics, which have been introduced in PostgreSQL 10 (check out the <code class="literal">CREATE STATISTICS</code> command to find out more). The good news is that PostgreSQL will also keep track of statistics for functional indexes:</p><pre class="programlisting"><span class="strong"><strong>CREATE INDEX idx_cos ON t_data (cos(data));</strong></span></pre><p>What has not been possible so far is to use more sophisticated statistics on functional indexes.</p><p>Consider the following example of an index covering various columns:</p><pre class="programlisting"><span class="strong"><strong>CREATE INDEX coord_idx ON measured (x, y, (z + t)); </strong></span>
<span class="strong"><strong>ALTER INDEX coord_idx ALTER COLUMN 3 SET STATISTICS 1000;</strong></span></pre><p>In this case, there is an index on two columns, which also provides a virtual third column represented by the expression. The new feature allows us to create more statistics explicitly for the third column, which would otherwise be suboptimally covered. In my example, we will tell PostgreSQL explicitly that we want the third column to have 1,000 entries in the system statistics. It will allow the optimizer to come up with better estimates and therefore potentially create better plans. It will be a <span>highly</span><a id="id325945986" class="indexterm"></a> valuable contribution to the efficiency of some specialized applications.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec3"></a>INCLUDE indexes or covering indexes</h4></div></div></div><p>Many other database <span>systems</span><a id="id325946720" class="indexterm"></a> have long provided a feature <span>known</span><a id="id325946728" class="indexterm"></a> as <span class="strong"><strong>covering indexes</strong></span>. What does this mean? Consider the following example, which <span>simply</span><a id="id325946739" class="indexterm"></a> selects two columns from a table:</p><pre class="programlisting"><span class="strong"><strong>SELECT id, name FROM person WHERE id = 10;</strong></span></pre><p>Suppose we have an index on <code class="literal">id</code> only. In this case, PostgreSQL will look up the index and do a lookup in the table to fetch those additional fields. This is generally known as an index scan. It consists of checking the index and the underlying table to compose a row. The solution here used to be to create an index consisting of two columns. The idea is to allow PostgreSQL to perform an index-only scan instead of an index scan. If an index has all the columns needed, there is no need to do additional lookups in the table (for most cases).</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip3"></a>Note</h3><p>Only select the columns you really need—otherwise you might trigger pointless table lookups. The following type of query is therefore generally assumed to be quite bad for performance: <code class="literal">SELECT * FROM person WHERE id  = 10;</code></p></div><p>The problem here would be if you need a primary key constraint on the <code class="literal">id</code> and still want to end up triggering an index-only scan when reading an additional column. This is where the new feature steps in to save the day:</p><pre class="programlisting"><span class="strong"><strong>CREATE UNIQUE INDEX some_name ON person USING btree (id) INCLUDE (name);</strong></span></pre><p>PostgreSQL will ensure that the <code class="literal">id</code> is unique but will still store additional fields in the index to trigger an index-only scan if asked for both columns. In a high-volume OLTP environment, this will increase performance dramatically. Of course, it is always hard to provide you with hard numbers because every table and every type of query is different. However, the gain can be <span>absolutely</span><a id="id326010647" class="indexterm"></a> substantial. PostgreSQL 11 will give us even more options to <span>trigger</span><a id="id326010656" class="indexterm"></a> even <span>more</span><a id="id326010662" class="indexterm"></a> index-only scans.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec4"></a>Parallel index creation</h4></div></div></div><p>When an index is built in PostgreSQL, the <span>database</span><a id="id326010675" class="indexterm"></a> traditionally <span>used</span><a id="id326010683" class="indexterm"></a> one core to do the job. In many cases, this was not an issue. However, PostgreSQL is used for ever-growing systems and therefore index creation starts to be an issue in many cases. <span>At the moment the community is trying to improve sorting as well. The first step is therefore to allow for the parallel creation of <span class="strong"><strong>btrees</strong></span>, which has made it into PostgreSQL 11.</span> Future versions of PostgreSQL will also allow provide parallel sorts for normal operations, which is unfortunately not yet supported by PostgreSQL 11.</p><p>Parallel index creation can speed up indexing dramatically and we are eager to see future improvements in this area (maybe support for other index types, and so on).</p><p> </p><p> </p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec4"></a>Better cache management</h3></div></div></div><p>PostgreSQL 11 will also <span>provide</span><a id="id326011093" class="indexterm"></a> you with better <span>ways</span><a id="id326011101" class="indexterm"></a> to manage the I/O cache (the shared buffers). The <code class="literal">pg_prewarm</code> command is especially noteworthy.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec5"></a>Improving pg_prewarm</h4></div></div></div><p>The <code class="literal">pg_prewarm</code> command allows you to <span>restore</span><a id="id326011123" class="indexterm"></a> the <span>content</span><a id="id326011131" class="indexterm"></a> of the PostgreSQL I/O cache after a restart. It has already been around for quite some time and is widely used by the PostgreSQL user base. In PostgreSQL 11, <code class="literal">pg_prewarm</code> has been extended and allows for automatic dumping of the buffer list in regular intervals.</p><p>It is also possible to <span>automatically preload the old cache contents</span> so that users will have better database performance after a restart. In particular, systems with a lot of RAM can benefit from these new improvements.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec5"></a>Enhancing windowing functions</h3></div></div></div><p>Windowing functions and <span>analytics</span><a id="id326011294" class="indexterm"></a> are a <span>cornerstone</span><a id="id326011303" class="indexterm"></a> of any modern SQL implementation and are therefore widely used by professionals. PostgreSQL has provided support for windowing functions for quite some time now. However, there were still some small features proposed by the SQL standard missing. PostgreSQL 11 now fully supports what SQL: 2011 proposes.</p><p>The following features have been added:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Range between:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Previously just <code class="literal">ROWS</code></li><li style="list-style-type: disc">Now handles values</li></ul></div></li><li style="list-style-type: disc">Exclusion clauses:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Exclude current row</li><li style="list-style-type: disc">Exclude ties</li></ul></div></li></ul></div><p>To demonstrate how the new features work, I have decided to include an example. The code contains two windowing functions. They are explained as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">The first one uses what is already available in PostgreSQL 10 and previously.</li><li style="list-style-type: disc">The second <code class="literal">array_agg</code> excludes the current row, which is a new feature provided by PostgreSQL 11.</li></ul></div><p>The following code generates five rows and contains two windowing functions:</p><pre class="programlisting"><span class="strong"><strong>test=# SELECT *,</strong></span>
<span class="strong"><strong>         array_agg(x) OVER (ORDER BY x ROWS BETWEEN </strong></span>
<span class="strong"><strong>                        1 PRECEDING AND 1 FOLLOWING),</strong></span>
<span class="strong"><strong>         array_agg(x) OVER (ORDER BY x ROWS BETWEEN </strong></span>
<span class="strong"><strong>                        1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)</strong></span>
<span class="strong"><strong>     FROM generate_series(1, 5) AS x;</strong></span>
<span class="strong"><strong>  x | array_agg | array_agg</strong></span>
<span class="strong"><strong> ---+-----------+-----------</strong></span>
<span class="strong"><strong> 1  | {1,2}     | {2}</strong></span>
<span class="strong"><strong> 2  | {1,2,3}   | {1,3}</strong></span>
<span class="strong"><strong> 3  | {2,3,4}   | {2,4}</strong></span>
<span class="strong"><strong> 4  | {3,4,5}   | {3,5}</strong></span>
<span class="strong"><strong> 5  | {4,5}     | {4}</strong></span>
<span class="strong"><strong> (5 rows)</strong></span></pre><p>Excluding the current row is a pretty <span>common</span><a id="id326015684" class="indexterm"></a> requirement and <span>should</span><a id="id326019619" class="indexterm"></a> therefore not be underestimated. </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec6"></a>Introducing just-in-time compilation</h3></div></div></div><p><span class="strong"><strong>Just-in-time (JIT)</strong></span> compilation is <span>really</span><a id="id326019635" class="indexterm"></a> one of the <span>highlights</span><a id="id326019643" class="indexterm"></a> of PostgreSQL 11. A lot of infrastructure has been added to support even more JIT compilation in the future, and PostgreSQL 11 is the first release that makes full use of this modern technique. Before we dig into details, what is JIT compilation all about? When running a query, a lot of stuff is actually only known at runtime and not at compile time (when PostgreSQL is compiled). Therefore, a traditional compiler is always at a disadvantage because it does not know what will happen at runtime. A JIT compiler already knows a lot more and can react accordingly. </p><p>Starting with PostgreSQL 11, you can make use of JIT compilation, which is especially useful for big queries. We will dig into the finer details in the later chapters of this book.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec7"></a>Enhanced partitioning</h3></div></div></div><p>PostgreSQL 10 introduced the first version of partitioning in PostgreSQL. Of course, we used to have inheritance and all that before. However, PostgreSQL 10 was <span>really</span><a id="id326019660" class="indexterm"></a> the first version that provided a modern version of doing things. PostgreSQL 11 will add some <span>new</span><a id="id326019669" class="indexterm"></a> functionality to this already powerful feature by introducing a couple of new highlights, such as the ability to create a default partition if none of the existing partitions match.</p><p>Here is how it works:</p><pre class="programlisting"><span class="strong"><strong>postgres=# CREATE TABLE default_part PARTITION OF some_table DEFAULT; </strong></span>
<span class="strong"><strong>CREATE TABLE</strong></span></pre><p>In this case, all the rows that simply don't match anywhere will end up in the default partition.</p><p>But there is more. In PostgreSQL, a row could not (easily) be moved from one partition to the other. Suppose you had one partition per country. If a person moved from, say, France to Estonia, you would not do that with a single <code class="literal">UPDATE</code> statement. You had to delete the old row and insert a new one. In PostgreSQL 11, this problem has been solved. Rows can now be moved from one partition to some other place in a totally transparent way.</p><p>PostgreSQL had many more shortcomings. In the old version, all partitions had to be indexed separately. There was no way to create a single index for all partitions. In PostgreSQL 11, an index added to the parent table will automatically make sure that all child tables are indexed too. This is really beneficial as it becomes less likely that indexes will simply be forgotten. Also, in PostgreSQL 11, you can actually add a global unique index. A partitioned table can therefore enforce a unique constraint.</p><p>Up to PostgreSQL 10, we had range partitioning and list partitioning. PostgreSQL 11 adds the ability to do hash partitioning. Here is an example showing how hash partitioning works:</p><pre class="programlisting"><span class="strong"><strong>test=# CREATE TABLE tab(i int, t text) PARTITION BY HASH (i); </strong></span>
<span class="strong"><strong>CREATE TABLE </strong></span>
<span class="strong"><strong>test=# CREATE table tab_1 PARTITION OF tab </strong></span>
<span class="strong"><strong>                  FOR VALUES WITH (MODULUS 4, REMAINDER 0); </strong></span>
<span class="strong"><strong>CREATE TABLE</strong></span></pre><p>But there is not just more functionality. There is also a lot of new stuff to improve performance. Partition pruning is now a lot faster and PostgreSQL has the ability to <span>consider</span><a id="id326019726" class="indexterm"></a> partition-wise joins, as well as partition-wise aggregates, which is exactly what is <span>needed</span><a id="id326019735" class="indexterm"></a> for analytics and data warehousing. </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec8"></a>Adding support for stored procedures</h3></div></div></div><p>PostgreSQL has always <span>supported</span><a id="id326019748" class="indexterm"></a> functions, which were often referred to as stored procedures. However, there is a distinction between a stored procedure <span>and</span><a id="id326020066" class="indexterm"></a> a function. As pointed out previously, up to PostgreSQL 10, we only had functions and no procedures.</p><p>The point is that a function is part of a larger structure, a transaction. A procedure can contain more than just one transaction. Therefore, it cannot be called by a larger transaction but is rather a standalone thing.</p><p>Here is the syntax of <code class="literal">CREATE PROCEDURE</code>:</p><pre class="programlisting"><span class="strong"><strong>test=# \h CREATE PROCEDURE
Command: CREATE PROCEDURE
Description: define a new procedure
Syntax:
CREATE [ OR REPLACE ] PROCEDURE
    name ( [ [ argmode ] [ argname ] 
    argtype [ { DEFAULT | = } default_expr ] [, ...] ] )
  { LANGUAGE lang_name
    | TRANSFORM { FOR TYPE type_name } [, ... ]
    | [ EXTERNAL ] SECURITY INVOKER | [ EXTERNAL ] SECURITY DEFINER
    | SET configuration_parameter { TO value | = value | FROM CURRENT }
    | AS 'definition'
    | AS 'obj_file', 'link_symbol'
} …</strong></span></pre><p>The following procedure shows how two transactions can be executed within the very same procedure:</p><pre class="programlisting"><span class="strong"><strong>test=# CREATE PROCEDURE test_proc()
       LANGUAGE plpgsql
AS $$
  BEGIN
    CREATE TABLE a (aid int);
    CREATE TABLE b (bid int);
    COMMIT;
   CREATE TABLE c (cid int);
    ROLLBACK;
  END;
$$;
CREATE PROCEDURE</strong></span></pre><p>Note <span>that the first two statements</span> have been <span>committed</span><a id="id326020104" class="indexterm"></a> while the <span>second</span><a id="id326020113" class="indexterm"></a> transaction has been aborted. You will see later in this example what the effect of this change is.</p><p>To run the procedure, we can use <code class="literal">CALL</code>:</p><pre class="programlisting"><span class="strong"><strong>test=# CALL test_proc();
CALL</strong></span></pre><p>The first two tables were committed—the third table has not been created because of the rollback inside the procedure:</p><pre class="programlisting"><span class="strong"><strong>test=# \d
List of relations
 Schema | Name | Type  | Owner
--------+------+-------+-------
 public | a    | table | hs
 public | b    | table | hs
(2 rows)</strong></span></pre><p>Procedures are an <span>important</span><a id="id326020146" class="indexterm"></a> step toward a <span>complete</span><a id="id326020154" class="indexterm"></a> and fully featured database system.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec9"></a>Improving ALTER TABLE</h3></div></div></div><p>The <code class="literal">ALTER TABLE</code> command can be <span>used</span><a id="id326020172" class="indexterm"></a> to change the <span>definition</span><a id="id326020181" class="indexterm"></a> of a table. In PostgreSQL 11, the behavior of <code class="literal">ALTER TABLE ... ADD COLUMN</code> has been improved substantially. Let us take a look at the details. The following examples shows how columns can be added to a table and how PostgreSQL will handle those new columns:</p><pre class="programlisting"><span class="strong"><strong>ALTER TABLE x ADD COLUMN y int;</strong></span>
<span class="strong"><strong>ALTER TABLE x ADD COLUMN z int DEFAULT 57;</strong></span></pre><p>The first command in the listing has always been fast, the reason being that in PostgreSQL, the default value of a column is <code class="literal">NULL</code>. So what PostgreSQL does is it adds a column to the system catalog without actually touching storage. The column will be added to the end of the table so if the row is too short on disk, we know that it will be <code class="literal">NULL</code> anyway. In other words, even if you add a column to a 10 TB table, the operation will be really fast because the system does not have to change rows on disk.</p><p>The situation used to be quite different in the second case. <code class="literal">DEFAULT 57</code> actually does add real data to the row and in PostgreSQL 10 and older, this meant that the database had to rewrite the entire table to add this new default value. If you have a small table, it is not a big deal. However, if your table contains billions of rows, you cannot just lock it up and rewrite it—in a professional <span class="strong"><strong>online transaction processing</strong></span> (<span class="strong"><strong>OLTP</strong></span>) system, downtime is out of the question.</p><p>Starting with PostgreSQL 11, it is <span>possible</span><a id="id326081634" class="indexterm"></a> to add <span>immutable</span><a id="id326081640" class="indexterm"></a> default values to a table without rewriting the entire table, which greatly reduces the burden of a changing data structure.</p><p> </p><p> </p></div></div>