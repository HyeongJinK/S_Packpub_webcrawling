<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec82"></a>Checking for slow queries</h2></div></div><hr /></div><p>After inspecting <code class="literal">pg_stat_activity</code>, it makes sense to take a look at slow, time-consuming queries. Basically, there are two ways to approach this problem:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Look for individual slow queries in the log</li><li style="list-style-type: disc">Look for types of queries <span>that</span><a id="id325895963" class="indexterm"></a> take too much time</li></ul></div><p>Finding single, slow queries is the classic approach to performance tuning. By setting the <code class="literal">log_min_duration_statement</code> variable to a desired threshold, PostgreSQL will start to write a log line for each query exceeding this threshold. By default, the slow-query log is off:</p><pre class="programlisting"><span class="strong"><strong>test=# </strong></span><span class="strong"><strong>SHOW log_min_duration_statement;</strong></span>
<span class="strong"><strong> log_min_duration_statement</strong></span>
<span class="strong"><strong>----------------------------</strong></span>
<span class="strong"><strong>                         -1</strong></span>
<span class="strong"><strong>(1 row)</strong></span></pre><p>However, setting this variable to a reasonably good value makes perfect sense. Depending on your workload, the desired time might, of course, vary.</p><p>In many cases, the desired value might differ from database to database. Therefore, it is also possible to use the variable in a more fine-grained way:</p><pre class="programlisting"><span class="strong"><strong>test=# </strong></span><span class="strong"><strong>ALTER DATABASE test </strong></span><span class="strong"><strong>SET log_min_duration_statement TO 10000;</strong></span>
<span class="strong"><strong>ALTER DATABASE</strong></span></pre><p>Setting the parameter for only a certain database makes perfect sense if your databases face different workloads.</p><p>When using the slow-query log, it is important to consider one important factor—many smaller queries might cause more load than a handful of slow-running queries. Of course, it always makes sense to be aware of individual slow queries, but sometimes those queries are not the problem. Consider the following example: on your system, 1 million queries taking 500 milliseconds each are executed, along with some analytical queries running for a couple of milliseconds each. Clearly, the real problem will never show up in the slow-query log while every data export, every index creation, and every bulk load (which cannot be avoided in most cases anyway) will spam the log and point us in the wrong direction.</p><p>My personal recommendation, therefore, is to use a slow-query log, but use it carefully, and with caution. Most importantly, though, be aware of what we are really measuring.</p><p>The better approach, in my opinion, is to work more intensively with the <code class="literal">pg_stat_statements</code> view. It will offer aggregated information and not just information about single queries. The <code class="literal">pg_stat_statements</code> view was discussed earlier in this book. However, the <span>importance</span><a id="id325664453" class="indexterm"></a> of the module cannot be stressed enough.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec128"></a>Inspecting individual queries</h3></div></div></div><p>Sometimes, slow queries are identified, but we still don't have a clue about what is really going on. The next step is, of course, to inspect the execution plan of the query and see what happens. Identifying those key operations in the plan that are responsible for bad runtime is fairly simple. Try and use the following checklist:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Try and see where it is in the plan <span>that</span><a id="id325565401" class="indexterm"></a> time starts to skyrocket</li><li style="list-style-type: disc">Check for missing indexes (one of the main reasons for bad performance)</li><li style="list-style-type: disc">Use the <code class="literal">EXPLAIN</code> clause (buffers <code class="literal">true</code>, analyze <code class="literal">true</code>, and so on) to see if your query uses too many buffers</li><li style="list-style-type: disc">Turn on the <code class="literal">track_io_timing</code> parameter to figure out whether there is an I/O problem or a CPU problem (explicitly check if there is random I/O going on)</li><li style="list-style-type: disc">Look for wrong estimates and try and fix them</li><li style="list-style-type: disc">Look for stored procedures that are executed too frequently</li><li style="list-style-type: disc">Try to figure out whether some of them can be marked as <code class="literal">STABLE</code> or <code class="literal">IMMUTABLE</code>, provided this is possible</li></ul></div><p>Note that <code class="literal">pg_stat_statements</code> does not account for parse time, so if your queries are very long (query string), <code class="literal">pg_stat_statements</code> might be slightly misleading.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec129"></a>Digging deeper with perf</h3></div></div></div><p>In most cases, working through this tiny checklist will help you to track down the majority of problems in a pretty fast and efficient way. However, even the <span>information</span><a id="id325648471" class="indexterm"></a> that's been extracted from the database engine is sometimes not enough.</p><p>The <code class="literal">perf</code> tool is an analysis tool for Linux <span>that</span><a id="id325648485" class="indexterm"></a> allows you to directly see which <code class="literal">C</code> functions cause problems on your system. Usually, <code class="literal">perf</code> is not installed by default, so it is recommended to install it. To use <code class="literal">perf</code> on your server, just log in to a root and run the following:</p><pre class="programlisting"><span class="strong"><strong>perf top</strong></span></pre><p>The screen will refresh itself every couple of seconds and you will have a chance to see what is going on live. The following listing shows you what a standard, read-only benchmark might look as follows:</p><pre class="programlisting"><span class="strong"><strong>Samples: 164K of event 'cycles:ppp', Event count (approx.): 109789128766 </strong></span>
<span class="strong"><strong>Overhead Shared Object     Symbol </strong></span>
<span class="strong"><strong>   3.10% postgres          [.] AllocSetAlloc </strong></span>
<span class="strong"><strong>   1.99% postgres          [.] SearchCatCache </strong></span>
<span class="strong"><strong>   1.51% postgres          [.] base_yyparse </strong></span>
<span class="strong"><strong>   1.42% postgres          [.] hash_search_with_hash_value </strong></span>
<span class="strong"><strong>   1.27% libc-2.22.so      [.] vfprintf </strong></span>
<span class="strong"><strong>   1.13% libc-2.22.so      [.] _int_malloc </strong></span>
<span class="strong"><strong>   0.87% postgres          [.] palloc </strong></span>
<span class="strong"><strong>   0.74% postgres          [.] MemoryContextAllocZeroAligned </strong></span>
<span class="strong"><strong>   0.66% libc-2.22.so      [.] __strcmp_sse2_unaligned </strong></span>
<span class="strong"><strong>   0.66% [kernel]          [k] _raw_spin_lock_irqsave </strong></span>
<span class="strong"><strong>   0.66% postgres          [.] _bt_compare </strong></span>
<span class="strong"><strong>   0.63% [kernel]          [k] __fget_light </strong></span>
<span class="strong"><strong>   0.62% libc-2.22.so      [.] strlen</strong></span></pre><p>You can see that no single function takes too much CPU time in our sample, which tells us that the system is just fine.</p><p>However, this may not always be the case. There is a problem—one that is <span>quite</span><a id="id325896178" class="indexterm"></a> common—called <span class="strong"><strong>spinlock contention</strong></span>. What is this? Spinlocks (<a class="ulink" href="https://en.wikipedia.org/wiki/Spinlock" target="_blank"><span>h</span><span>t</span><span>t</span><span>p</span><span>s</span><span>://</span><span>e</span><span>n</span><span>.</span><span>w</span><span>i</span><span>k</span><span>i</span><span>p</span><span>e</span><span>d</span><span>i</span><span>a</span><span>.</span><span>o</span><span>r</span><span>g</span><span>/</span><span>w</span><span>i</span><span>k</span><span>i</span><span>/</span><span>S</span><span>p</span><span>i</span><span>n</span><span>l</span><span>o</span><span>c</span><span>k</span></a>) are used by the PostgreSQL core to synchronize things <span>such</span><a id="id326472728" class="indexterm"></a> as buffer access. A spinlock is a feature provided by modern CPUs to avoid operating system interaction for small operations (such as incrementing a number). It is a good thing, but in some very special cases, spinlocks can go crazy.</p><p>If you are facing spinlock contention, the symptoms are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Really high CPU load</li><li style="list-style-type: disc">Incredibly low throughput (queries that usually take milliseconds suddenly take seconds)</li><li style="list-style-type: disc">I/O is usually low because the CPU is busy trading locks</li></ul></div><p>In many cases, spinlock contention happens suddenly. Your system is just fine, and all of a sudden, load goes up and throughput drops such as a stone. The <code class="literal">perf top</code> command will reveal that most of this time is spent in a <code class="literal">C</code> function called <code class="literal">s_lock</code>. If this is the case, you should try and do the following:</p><pre class="programlisting"><span class="strong"><strong>huge_pages </strong></span><span class="strong"><strong>= try               # on, off, or try</strong></span></pre><p>Change <code class="literal">huge_pages</code> from <code class="literal">try</code> to <code class="literal">off</code>. It can be a good idea to turn off huge pages altogether on the operating system level. In general, it seems that some kernels are more prone to producing these kinds of problems than others. The Red Hat 2.6.32 series seems to be especially bad (note that I have used the word <span class="emphasis"><em>seems</em></span> here).</p><p>The <code class="literal">perf</code> tool is also <span>interesting</span><a id="id326686777" class="indexterm"></a> if you are using PostGIS. If the top functions in the list are all GIS-related (some underlying library), you know that the <span>problem</span><a id="id326686787" class="indexterm"></a> is most likely not coming from bad PostgreSQL tuning but is simply related to expensive operations that take time to complete.</p></div></div>