<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec42"></a>Understanding execution plans</h2></div></div><hr /></div><p>Now that we've dug into some <span>important</span><a id="id325896177" class="indexterm"></a> optimizations that are implemented in PostgreSQL, let's proceed to take a closer look at execution plans. You have already seen some plans in this book. However, in order to make full use of plans, it is important to develop a systematic approach to reading this information. Reading plans systematically is exactly within the scope of this section.</p><p> </p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec60"></a>Approaching plans systematically</h3></div></div></div><p>The first thing you have to know is that an <code class="literal">EXPLAIN</code> clause can do quite a lot for you and I highly recommend making full use of these features.</p><p>As many readers might already know, an <code class="literal">EXPLAIN ANALYZE</code> clause will <span>execute</span><a id="id325896154" class="indexterm"></a> the query and return the plan, including real runtime information. Here is an example:</p><pre class="programlisting"><span class="strong"><strong>test=# EXPLAIN ANALYZE SELECT * 
</strong></span><span class="strong"><strong>FROM 
(
    SELECT * 
</strong></span><span class="strong"><strong>    FROM b 
</strong></span><span class="strong"><strong>    LIMIT 1000000
</strong></span><span class="strong"><strong>) AS b 
</strong></span><span class="strong"><strong>ORDER BY cos(bid);</strong></span>
<span class="strong"><strong>                            QUERY PLAN </strong></span>
<span class="strong"><strong>---------------------------------------------------------------- </strong></span>
<span class="strong"><strong> Sort (cost=146173.12..148673.12 rows=1000000) </strong></span>
<span class="strong"><strong>         (actual time=837.049..1031.587 rows=1000000) </strong></span>
<span class="strong"><strong>         Sort Key: (cos((b.bid)::double precision)) </strong></span>
<span class="strong"><strong>         Sort Method: external merge Disk: 25408kB </strong></span>
<span class="strong"><strong>   -&gt; Subquery Scan on b </strong></span>
<span class="strong"><strong>         (cost=0.00..29424.78 rows=1000000 width=12) </strong></span>
<span class="strong"><strong>         (actual time=0.011..352.717 rows=1000000) </strong></span>
<span class="strong"><strong>         -&gt; Limit (cost=0.00..14424.78 rows=1000000) </strong></span>
<span class="strong"><strong>               (actual time=0.008..169.784 rows=1000000) </strong></span>
<span class="strong"><strong>               -&gt; Seq Scan on b b_1 (cost=0.00..2884955.84 </strong></span><span class="strong"><strong>rows=199999984 width=4) </strong></span>
<span class="strong"><strong>                     (actual time=0.008..85.710 rows=1000000) </strong></span>
<span class="strong"><strong> Planning time: 0.064 ms </strong></span>
<span class="strong"><strong> Execution time: 1159.919 ms </strong></span>
<span class="strong"><strong>(8 rows)</strong></span></pre><p>The plan looks a bit scary, but don't panic; we will go through it s<span>tep by step</span>. When reading a plan, make sure that you read it from the inside to the outside. In our example, execution starts with a sequential scan on <code class="literal">b</code>. There are actually two blocks of information here: the <span class="strong"><strong>cost block</strong></span> and the <span class="strong"><strong>actual time block</strong></span>. While the cost block contains estimations, the actual time block is hard evidence. It shows the real execution time. In this example, the sequential scan has taken 85.7 milliseconds.</p><p> </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note48"></a>Note</h3><p>Note that the costs shown on your system might not be identical. A small difference in the optimizer statistics can cause differences. The important thing here is really the way the plan has to be read.</p></div><p>The data coming from the index scan is then passed on to the <code class="literal">Limit</code> node, which ensures that there is not too much data. Note that each stage of execution will also show us the number of rows involved. As you can see, PostgreSQL will only fetch 1 million rows from the table in the first place; the <code class="literal">Limit</code> node ensures that this will actually happen. However, there is a price tag at this stage as the runtime has jumped to 169 milliseconds already. Finally, the data is sorted, which takes a lot of time. The most <span>important</span><a id="id325631758" class="indexterm"></a> thing when looking at the plan is to figure out where time is actually lost. The best way to do that is to take a look at the actual time block and try to figure out where time jumps. In this example, the sequential scan takes some time, but it cannot be sped up significantly. Instead, we can see that time skyrockets as sorting starts.</p><p>Of course, the process of sorting can be sped up, but we'll cover more on that later in this chapter.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec47"></a>Making EXPLAIN more verbose</h4></div></div></div><p>In PostgreSQL, the output of an <code class="literal">EXPLAIN</code> clause can be <span>beefed</span><a id="id325631779" class="indexterm"></a> up a little to provide you with more information. To extract as much as possible out of a plan, consider turning the following options on:</p><pre class="programlisting"><span class="strong"><strong>test=# EXPLAIN (analyze, verbose, costs, timing, buffers) 
  SELECT * FROM a ORDER BY random(); 
                          QUERY PLAN 
----------------------------------------------------------------- 
 Sort (cost=834.39..859.39 rows=10000 width=12) 
         (actual time=6.089..7.199 rows=10000 loops=1) 
   Output: aid, (random()) 
   Sort Key: (random()) 
   Sort Method: quicksort Memory: 853kB 
   Buffers: shared hit=45 
   -&gt; Seq Scan on public.a 
         (cost=0.00..170.00 rows=10000 width=12) 
         (actual time=0.012..2.625 rows=10000 loops=1) 
         Output: aid, random() 
         Buffers: shared hit=45 
 Planning time: 0.054 ms 
 Execution time: 7.992 ms 
(10 rows) 
</strong></span></pre><p> </p><p> </p><p> </p><p> </p><p><code class="literal">analyze true</code> will actually execute the query, as shown previously. <code class="literal">verbose true</code> will add some more information to the plan (such as column information and so on). <code class="literal">costs true</code> will show information about costs. <code class="literal">timing true</code> is equally important, as it will provide us with good runtime data so that we can see where in the plan time gets lost. Finally, there is <code class="literal">buffers true</code>, which can be very enlightening. In my example, it reveals that we needed to access 45 buffers to execute the query.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec61"></a>Spotting problems</h3></div></div></div><p>Given all the <span>information</span><a id="id325664429" class="indexterm"></a> shown in Chapter 5, <span class="emphasis"><em>Log Files and System Statistics</em></span>, it is already possible to spot a couple of potential performance problems that are very important in real life.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec48"></a>Spotting changes in runtime</h4></div></div></div><p>When looking at a plan, there are <span>always</span><a id="id325664452" class="indexterm"></a> two questions that you have got to ask yourself:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Is the runtime shown by the <code class="literal">EXPLAIN ANALYZE</code> clause justified for the given query?</li><li style="list-style-type: disc">If the query is slow, where does the runtime jump?</li></ul></div><p>In my case, the sequential scan is rated at 2.625 milliseconds. The sort is done after 7.199 milliseconds, so the sort takes roughly 4.5 milliseconds to complete and is therefore responsible for most of the runtime needed by the query.</p><p>Looking for jumps in the execution time of the query will reveal what is really going on. Depending on which type of operation will burn too much time, you have to act accordingly. Some general advice is not possible here because there are simply too many things that can cause issues.</p><p> </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec49"></a>Inspecting estimates</h4></div></div></div><p>However, there is something that should <span>always</span><a id="id325856136" class="indexterm"></a> be done: making sure that estimates and real numbers are reasonably close together. In some cases, the optimizer will make poor decisions because the estimates are way off for some reason. It can happen that estimates are off because the system statistics are not up to date. Running an <code class="literal">ANALYZE</code> clause is therefore definitely a good thing to start with. However, optimizer stats are mostly taken care of by the auto-vacuum daemon, so it is definitely worth considering other options that are causing bad estimates. Take a look at the following example, which helps us to add some data to a table:</p><pre class="programlisting"><span class="strong"><strong>test=# CREATE </strong></span><span class="strong"><strong>TABLE t_estimate AS 
</strong></span><span class="strong"><strong>       SELECT </strong></span><span class="strong"><strong>* FROM generate_series(1, 10000) AS id;</strong></span>
<span class="strong"><strong>SELECT 10000</strong></span></pre><p>After loading <code class="literal">10000</code> rows, optimizer statistics are created:</p><pre class="programlisting"><span class="strong"><strong>test=# ANALYZE t_estimate;</strong></span>
<span class="strong"><strong>ANALYZE</strong></span></pre><p>Let's take a look at the estimates now:</p><pre class="programlisting"><span class="strong"><strong>test=# EXPLAIN ANALYZE </strong></span><span class="strong"><strong>SELECT * </strong></span><span class="strong"><strong>FROM t_estimate </strong></span><span class="strong"><strong>WHERE cos(id) &lt; 4;</strong></span>
<span class="strong"><strong>                               QUERY PLAN </strong></span>
<span class="strong"><strong>----------------------------------------------------------------- </strong></span>
<span class="strong"><strong> Seq Scan on t_estimate (cost=0.00..220.00 rows=3333 width=4) </strong></span>
<span class="strong"><strong>         (actual time=0.010..4.006 rows=10000 loops=1) </strong></span>
<span class="strong"><strong>   Filter: (cos((id)::double precision) &lt; '4'::double precision) </strong></span>
<span class="strong"><strong> Planning time: 0.064 ms </strong></span>
<span class="strong"><strong> Execution time: 4.701 ms </strong></span>
<span class="strong"><strong>(4 rows)</strong></span></pre><p>In many cases, PostgreSQL might not be able to process the <code class="literal">WHERE</code> clause properly because it only has statistics on columns, not on expressions. What we can see here is a nasty underestimation of the data returned from the <code class="literal">WHERE</code> clause.</p><p>Of course, it can also happen that the <span>amount</span><a id="id325895948" class="indexterm"></a> of data is overestimated:</p><pre class="programlisting"><span class="strong"><strong>test=# EXPLAIN ANALYZE</strong></span>
<span class="strong"><strong>SELECT * 
</strong></span><span class="strong"><strong>FROM t_estimate</strong></span>
<span class="strong"><strong>WHERE cos(id) &gt; 4;</strong></span>
<span class="strong"><strong>              QUERY PLAN </strong></span>
<span class="strong"><strong>----------------------------------------------------------------- </strong></span>
<span class="strong"><strong> Seq Scan on t_estimate (cost=0.00..220.00 rows=3333 width=4) </strong></span>
<span class="strong"><strong>     (actual time=3.802..3.802 rows=0 loops=1) </strong></span>
<span class="strong"><strong>     Filter: (cos((id)::double precision) &gt; '4'::double precision) </strong></span>
<span class="strong"><strong>     Rows Removed by Filter: 10000 </strong></span>
<span class="strong"><strong> Planning time: 0.037 ms </strong></span>
<span class="strong"><strong> Execution time: 3.813 ms </strong></span>
<span class="strong"><strong>(5 rows)</strong></span></pre><p>If something like that happens deep inside the plan, the process might very well create a bad plan. Therefore, making sure that estimates are within a certain range makes perfect sense.</p><p>Fortunately, there is a way to get around this problem:</p><pre class="programlisting"><span class="strong"><strong>test=# CREATE </strong></span><span class="strong"><strong>INDEX idx_cosine </strong></span><span class="strong"><strong>ON t_estimate (cos(id));</strong></span>
<span class="strong"><strong>CREATE INDEX</strong></span></pre><p>Creating an index will make PostgreSQL track statistics of the expression:</p><pre class="programlisting"><span class="strong"><strong>test=# ANALYZE t_estimate;</strong></span>
<span class="strong"><strong>ANALYZE</strong></span></pre><p>Apart from the fact that this plan will ensure significantly better performance, it will also fix statistics, even if the index is not used:</p><pre class="programlisting"><span class="strong"><strong>test=# EXPLAIN ANALYZE SELECT * FROM t_estimate WHERE cos(id) &gt; 4; 
             QUERY PLAN 
----------------------------------------------------------------- 
 Index Scan using idx_cosine on t_estimate 
     (cost=0.29..8.30 rows=1 width=4) 
     (actual time=0.002..0.002 rows=0 loops=1) 
     Index Cond: (cos((id)::double precision) &gt; '4'::double precision) 
 Planning time: 0.095 ms 
 Execution time: 0.011 ms 
(4 rows)</strong></span></pre><p>However, there is more to wrong <span>estimates</span><a id="id326189454" class="indexterm"></a> than meets the eye. One problem that is often underestimated is called a <span class="strong"><strong>cross-column correlation</strong></span>. Consider a simple <span>example</span><a id="id326193289" class="indexterm"></a> involving two columns:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">20% of people like to ski</li><li style="list-style-type: disc">20% of people are from Africa</li></ul></div><p> </p><p>If we want to count the number of skiers in Africa, mathematics says that the result will be <span class="emphasis"><em>0.2 x 0.2 = 4%</em></span> of the overall population. However, there is no snow in Africa and the income in this country is low. Therefore, the real result will surely be lower. The observation Africa and the observation skiing are not statistically independent. In many cases, the fact that PostgreSQL keeps column statistics that do not span more than one column can lead to bad results.</p><p>Of course, the planner does a lot to prevent these things from happening as often as possible. Still, it can be an issue.</p><p>Starting with PostgreSQL 10.0, we have multivariate statistics, which has put an end to cross-column correlation once and for all.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec50"></a>Inspecting buffer usage</h4></div></div></div><p>However, the plan itself is not the <span>only</span><a id="id326193325" class="indexterm"></a> thing that can cause issues. In many cases, dangerous things are hidden on some other level. Memory and caching can lead to undesired behavior, which is often hard to understand for end users who are not trained to see the problem that was described in this section.</p><p>Here is an example that depicts the random insertion of data into the table. The query will generate some randomly ordered data and add it to a new table:</p><pre class="programlisting"><span class="strong"><strong>test=# CREATE </strong></span><span class="strong"><strong>TABLE t_random AS 
</strong></span><span class="strong"><strong>  SELECT * </strong></span><span class="strong"><strong>FROM generate_series(1, 10000000) AS id </strong></span><span class="strong"><strong>ORDER BY random();</strong></span>
<span class="strong"><strong>SELECT 10000000</strong></span>
<span class="strong"><strong>test=# ANALYZE t_random ;</strong></span>
<span class="strong"><strong>ANALYZE</strong></span></pre><p>We have now generated a simple table containing 10 million rows and created the optimizer statistics.</p><p>In the next step, a simple query retrieving only a handful of rows is executed:</p><pre class="programlisting"><span class="strong"><strong>test=# EXPLAIN (analyze </strong></span><span class="strong"><strong>true, buffers true, costs true, timing true)   
       SELECT * </strong></span><span class="strong"><strong>FROM t_random </strong></span><span class="strong"><strong>WHERE id &lt; 1000;</strong></span>
<span class="strong"><strong>                           QUERY PLAN </strong></span>
<span class="strong"><strong>----------------------------------------------------------------- </strong></span>
<span class="strong"><strong> Seq Scan on t_random (cost=0.00..169248.60 rows=1000 width=4) </strong></span>
<span class="strong"><strong>   (actual time=1.068..685.410 rows=999 loops=1) </strong></span>
<span class="strong"><strong>   Filter: (id &lt; 1000) </strong></span>
<span class="strong"><strong>   Rows Removed by Filter: 9999001 </strong></span>
<span class="strong"><strong>   Buffers: shared hit=2112 read=42136 </strong></span></pre><p> </p><p> </p><p> </p><pre class="programlisting"><span class="strong"><strong> Planning time: 0.035 ms </strong></span>
<span class="strong"><strong> Execution time: 685.551 ms </strong></span>
<span class="strong"><strong>(6 rows)</strong></span></pre><p>Before inspecting the data, make sure that you have executed the query twice. Of course, it makes sense to use an index here. However, in this query, PostgreSQL has found 2,112 buffers inside the cache and <code class="literal">421136</code> buffers that had to be taken from the operating system. Now, there are two things that can happen. If you are lucky, the operating system lands a couple of cache hits and the query is fast. If the filesystem cache is not lucky, those blocks have to be taken from disk. This might look obvious; it can however, lead to wild swings in the execution time. A query that runs entirely in the cache can be 100 times faster than a query that has to slowly collect random blocks from disk.</p><p>Let's try to outline this problem by using a <span>simple</span><a id="id326300016" class="indexterm"></a> example. Suppose we have a phone system that stores 10 billion rows (which is not uncommon for large phone carriers). Data flows in at a rapid rate and users want to query this data. If you have 10 billion rows, the data will only partially fit into memory and therefore a lot of stuff will naturally end up coming from the disk.</p><p>Let us run a simple query now to show how PostgreSQL looks up a phone number:</p><pre class="programlisting"><span class="strong"><strong>SELECT </strong></span><span class="strong"><strong>* </strong></span><span class="strong"><strong>FROM data </strong></span><span class="strong"><strong>WHERE phone_number = '+12345678';</strong></span></pre><p>Even if you are on the phone, your data will be spread all over the place. If you end a phone call just to start the next call, thousands of people will do the same, so the odds that two of your calls will end up in the very same 8,000 block is naturally close to zero. Just imagine for the time being that there are 100,000 calls going on at the same time. On disk, data will be randomly distributed. If your phone number shows up often, it means that for each row, at least one block has to be fetched from disk (assuming a very low cache hit rate). Suppose 5,000 rows will be returned. Assuming that you have to go to disk 5,000 times, it leads to something such as <span class="emphasis"><em>5,000 x 5 milliseconds = 25</em></span> seconds of execution time. Note that the execution time of this query might vary between milliseconds and, say, 30 seconds, depending on how much has been cached by the operating system or by PostgreSQL.</p><p>Keep in mind that every server restart will <span>naturally</span><a id="id326300494" class="indexterm"></a> clean out the PostgreSQL and filesystem caches, which can lead to real trouble after a node failure.</p><p> </p><p> </p><p> </p><p> </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec51"></a>Fixing high buffer usage</h4></div></div></div><p>The question that begs an <span>answer</span><a id="id326300848" class="indexterm"></a> is, <span class="emphasis"><em>how can I improve this situation?</em></span> One way to do that is to run a <code class="literal">CLUSTER</code> clause:</p><pre class="programlisting"><span class="strong"><strong>test=# \</strong></span><span class="strong"><strong>h CLUSTER</strong></span>
<span class="strong"><strong>Command:     </strong></span><span class="strong"><strong>CLUSTER</strong></span>
<span class="strong"><strong>Description: cluster </strong></span><span class="strong"><strong>a table according to an index</strong></span>
<span class="strong"><strong>Syntax:</strong></span>
<span class="strong"><strong>CLUSTER [VERBOSE] table_name</strong></span>
<span class="strong"><strong>[ USING index_name ] CLUSTER [VERBOSE]</strong></span></pre><p>The <code class="literal">CLUSTER</code> clause will rewrite the table in the same order as a (<code class="literal">btree</code>) index. If you are running an analytical workload, this can make sense. However, in an OLTP system, the <code class="literal">CLUSTER</code> clause might not be feasible because a table lock is required while the table is rewritten.</p></div></div></div>