<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec67"></a>Questions</h2></div></div><hr /></div><p><span class="strong"><strong>Should everybody create dumps?</strong></span></p><p>If your database is fairly small, a dump certainly makes sense. However, if you database is huge (&gt; XXX GB) a dump might not be feasible anymore and different means can make sense (WAL archiving). You also have to keep in mind that a dump only provides a snapshot of data - it does not provide you with Point-In-Time-Recovery. Therefore the dump is more of an additional tool and not a replacement for WAL-archiving.</p><p><span class="strong"><strong>Why are dumps so small?</strong></span></p><p>A compressed dump is usually around 10 times faster than the PostgreSQL database that you have saved. The reason is that the database has to store the content of an index while the backup only contains definitions. That makes a huge difference in terms of space consumption. On top of that PostgreSQL has to store additional metadata such as tuple headers and so on, which also needs space.</p><p><span class="strong"><strong>Does one have to dump the globals too?</strong></span></p><p>Yes, it is definitely necessary to do that.</p><p><span class="strong"><strong>Is it safe to have a .pgpass file?</strong></span></p><p>Yes. If the permissions have been set properly, a <code class="literal">pgpass</code> file is perfectly safe. Keep in mind: A machine, which has to backup some other database needs all the information to connect to the target system. It makes no difference, in which format data is stored.</p></div>