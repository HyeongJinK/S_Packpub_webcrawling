<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec63"></a>Handling various formats</h2></div></div><hr /></div><p>So far, we have <span>seen</span><a id="id326542151" class="indexterm"></a> that <code class="literal">pg_dump</code> can be used to create text files. The problem here is that a text file can only be replayed completely. If we have saved an entire database, we can only replay the entire thing. In most cases, this is not what we want. Therefore, PostgreSQL has additional formats that offer more functionality.</p><p>At this point, four formats are supported:</p><pre class="programlisting"><span class="strong"><strong>-F, --format=c|d|t|p  output file  format (custom, directory, tar, plain  text  (default))</strong></span></pre><p>We have already seen plain, which is just normal text. On top of that, we can use a custom format. The idea behind a custom format is to have a compressed dump, including a table of contents. Here are two ways to create a custom format dump:</p><pre class="programlisting"><span class="strong"><strong>[hs@linuxpc ~]$ pg_dump -Fc test &gt; /tmp/dump.fc</strong></span><span class="strong"><strong>[hs@linuxpc ~]$ pg_dump -Fc test -f /tmp/dump.fc</strong></span></pre><p>In addition to the table of contents, the compressed dump has one more advantage. It is a lot smaller. The rule of thumb is that a custom format dump is around 90% smaller than the database instance you are about to back up. Of course, this is highly dependent on the number of indexes, but for many database applications, this rough estimation will hold true.</p><p>Once the backup is created, we can inspect the backup file:</p><pre class="programlisting"><span class="strong"><strong>[hs@linuxpc ~]$ pg_restore --list /tmp/dump.fc</strong></span><span class="strong"><strong>;</strong></span><span class="strong"><strong>; Archive created at 2018-11-04 15:44:56 CET</strong></span><span class="strong"><strong>;   dbname: test</strong></span><span class="strong"><strong>;   TOC Entries: 18</strong></span><span class="strong"><strong>;   Compression: -1</strong></span><span class="strong"><strong>;   Dump Version: 1.12-0</strong></span><span class="strong"><strong>;   Format: CUSTOM</strong></span><span class="strong"><strong>;   Integer: 4 bytes</strong></span><span class="strong"><strong>;   Offset: 8 bytes</strong></span><span class="strong"><strong>;   Dumped from database version: 11.0</strong></span><span class="strong"><strong>;   Dumped by pg_dump version: 11.0</strong></span><span class="strong"><strong>;</strong></span><span class="strong"><strong>; Selected TOC Entries:</strong></span><span class="strong"><strong>;</strong></span><span class="strong"><strong>3103;  1262  16384  DATABASE - test  hs</strong></span><span class="strong"><strong>3; 2615  2200  SCHEMA - public hs</strong></span><span class="strong"><strong>3104;  0 0 COMMENT - SCHEMA public hs</strong></span><span class="strong"><strong>1; 3079  13350  EXTENSION - plpgsql</strong></span><span class="strong"><strong>3105;  0 0 COMMENT - EXTENSION plpgsql</strong></span><span class="strong"><strong>187;  1259  16391  TABLE  public t_test hs</strong></span><span class="strong"><strong>...</strong></span></pre><p>Note that <code class="literal">pg_restore --list</code> will return the <span>table</span><a id="id326300494" class="indexterm"></a> of contents of the backup.</p><p>Using a custom format is a good idea as the backup will shrink in size. However, there's more; the <code class="literal">-Fd</code> command will create a backup in the directory format. Instead of a single file, you will now get a directory containing a couple of files:</p><pre class="programlisting"><span class="strong"><strong>[hs@linuxpc ~]$ mkdir /tmp/backup</strong></span><span class="strong"><strong>[hs@linuxpc ~]$ pg_dump -Fd test -f /tmp/backup/</strong></span><span class="strong"><strong>[hs@linuxpc ~]$ cd /tmp/backup/</strong></span><span class="strong"><strong>[hs@linuxpc backup]$ ls -lh total  86M</strong></span><span class="strong"><strong>-rw-rw-r--. 1 hs hs   85M Jan   4 15:54  3095.dat.gz</strong></span><span class="strong"><strong>-rw-rw-r--. 1 hs hs   107 Jan   4 15:54  3096.dat.gz</strong></span><span class="strong"><strong>-rw-rw-r--. 1 hs hs 740K  Jan   4 15:54  3097.dat.gz</strong></span><span class="strong"><strong>-rw-rw-r--. 1 hs hs   39 Jan   4 15:54  3098.dat.gz</strong></span><span class="strong"><strong>-rw-rw-r--. 1 hs hs 4.3K  Jan   4 15:54  toc.dat</strong></span></pre><p>One advantage of the directory format is that we can use more than one core to perform the backup. In the case of a plain or custom format, only one process will be used by <code class="literal">pg_dump</code>. The directory format changes that rule. The following example shows <span>how</span><a id="id325565433" class="indexterm"></a> we can tell <code class="literal">pg_dump</code> to use four cores (jobs):</p><pre class="programlisting"><span class="strong"><strong>[hs@linuxpc backup]$ rm -rf *</strong></span><span class="strong"><strong>[hs@linuxpc backup]$ pg_dump -Fd test -f /tmp/backup/ -j 4</strong></span></pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note71"></a>Note</h3><p>The more objects in our database, the more of a chance there is for a potential speedup.</p></div></div>