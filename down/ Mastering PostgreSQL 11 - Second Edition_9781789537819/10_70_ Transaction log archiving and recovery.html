<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec69"></a>Transaction log archiving and recovery</h2></div></div><hr /></div><p>After our brief introduction to the <span>transaction</span><a id="id325870747" class="indexterm"></a> log in general, it is time to focus on the process of transaction log archiving. As we have already seen, the <span>transaction</span><a id="id325870730" class="indexterm"></a> log contains a sequence of binary changes that are made to the storage system. So, why not use it to replicate database instances and do a lot of other cool stuff such as archiving and a lot more?</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec99"></a>Configuring for archiving</h3></div></div></div><p>The first thing we want to do in this chapter is create a <span>configuration</span><a id="id325869765" class="indexterm"></a> to perform standard <span class="strong"><strong>Point-In-Time Recovery</strong></span> (<span class="strong"><strong>PITR</strong></span>). There are a <span>couple</span><a id="id325869750" class="indexterm"></a> of advantages of using PITR over ordinary dumps:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">We will lose less data because we can restore the data to a certain point in time and not just to the fixed backup point.</li><li style="list-style-type: disc">Restoring will be faster because indexes don't have to be created from scratch. They are just copied over and are ready to use.</li></ul></div><p>Configuring for PITR is easy. Just a handful of changes have to be made in the <code class="literal">postgresql.conf</code> file:</p><pre class="programlisting"><span class="strong"><strong>wal_level </strong></span><span class="strong"><strong>= replica    </strong></span><span class="strong"><strong># used to be "hot_standby" in older versions 
max_wal_senders = 10   </strong></span><span class="strong"><strong># at least 2, better at least 2</strong></span></pre><p>The <code class="literal">wal_level</code> variable says that the server is supposed to produce enough transaction logs to allow for PITR. If the <code class="literal">wal_level</code> variable is set to <code class="literal">minimal</code> (which is the default value up to PostgreSQL 9.6), the transaction log will only contain enough information to recover a single node setup—it is not rich enough to handle replication. In PostgreSQL 10.0, the default value is already correct and there is no longer a need to change most settings.</p><p>The <code class="literal">max_wal_senders</code> variable will allow us to stream <code class="literal">WAL</code> from the server. It will allow us to use <code class="literal">pg_basebackup</code> to create an initial backup instead of traditional file-based copying. The advantage here is that <code class="literal">pg_basebackup</code> is a lot easier to use. Again, the default value in 10.0 has been changed in a way so that for 90% of all setups, no changes are needed.</p><p>The idea behind <code class="literal">WAL</code> streaming is that the transaction log that's created is copied to a safe place for storage. Basically, there are two means of transporting the <code class="literal">WAL</code>:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Using <code class="literal">pg_receivewal</code> (up to 9.6, this is known as <code class="literal">pg_receivexlog</code>)</li><li style="list-style-type: disc">Using the filesystem as a means to archive</li></ul></div><p>In this section, we will look at how to set up the second option. During normal operations, PostgreSQL keeps writing to those <code class="literal">WAL</code> files. When <code class="literal">archive_mode = on</code> in the <code class="literal">postgresql.conf</code> file, PostgreSQL will call the <code class="literal">archive_command</code> variable for every single file.</p><p>A configuration might look as follows. First, a directory storing those transaction log files can be created:</p><pre class="programlisting"><span class="strong"><strong>mkdir /archive</strong></span>
<span class="strong"><strong>chown postgres.postgres archive</strong></span></pre><p>The following entries can be changed in the <code class="literal">postgresql.conf</code> file:</p><pre class="programlisting"><span class="strong"><strong>archive_mode </strong></span><span class="strong"><strong>= on</strong></span>
<span class="strong"><strong>archive_command </strong></span><span class="strong"><strong>= 'cp %p /archive/%f'</strong></span></pre><p>A restart will enable archiving, but let's configure the <code class="literal">pg_hba.conf</code> file first to reduce downtime to an absolute minimum.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note77"></a>Note</h3><p>Note that we can put any command into the <code class="literal">archive_command</code> variable.</p></div><p>Many people use <code class="literal">rsync</code>, <code class="literal">scp</code>, and others to <span>transport</span><a id="id325638510" class="indexterm"></a> their <code class="literal">WAL</code> files to a safe location. If our script returns <code class="literal">0</code>, PostgreSQL will assume that the file has been archived. If anything else is returned, PostgreSQL will try to archive the file again. This is necessary because the database engine has to ensure that no files are lost. To perform the recovery process, we have to have every file available; not a single file is allowed to go missing.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec100"></a>Configuring the pg_hba.conf file</h3></div></div></div><p>Now that the <code class="literal">postgresql.conf</code> file has been configured successfully, it is necessary to configure the <code class="literal">pg_hba.conf</code> file for streaming. Note that this is only necessary if we are <span>planning</span><a id="id325664412" class="indexterm"></a> to use <code class="literal">pg_basebackup</code>, which is the state-of-the-art tool for creating base backups.</p><p>Basically, the options we have in the <code class="literal">pg_hba.conf</code> file are the same ones that we already saw in Chapter 8, <span class="emphasis"><em>Managing PostgreSQL Security</em></span>. There is just one major issue to keep in m<span>in</span>d:</p><pre class="programlisting"><span class="strong"><strong># Allow replication connections from localhost, by a user with the</strong></span>
<span class="strong"><strong># replication privilege.
local   replication   postgres                  trust
host    replication   postgres   127.0.0.1/32   trust
host    replication   postgres   ::1/128        trust
</strong></span></pre><p>We can define standard <code class="literal">pg_hba.conf</code> file rules. The important thing is that the second column says <code class="literal">replication</code>. Normal rules are not enough—it is really important to add explicit replication permissions. Also keep in mind that we don't have to do this as a superuser. We can create a specific user who is only allowed to perform login and replication.</p><p>Again, PostgreSQL 10 and later versions are already configured in the way we have outlined in this section. Local replication works when out-of-the-box—remote IPs have to be added to <code class="literal">pg_hba.conf</code>.</p><p>Now that the <code class="literal">pg_hba.conf</code> file has been configured correctly, PostgreSQL can be restarted.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec101"></a>Creating base backups</h3></div></div></div><p>After teaching PostgreSQL to archive those <code class="literal">WAL</code> files, it is time to <span>create</span><a id="id325856132" class="indexterm"></a> a first backup. The idea is to have a backup and to replay <code class="literal">WAL</code> files based on that <span>backup</span><a id="id325856186" class="indexterm"></a> to reach any point in time.</p><p>To create an initial backup, we can turn to <code class="literal">pg_basebackup</code>, which is a command-line tool used to perform backups. Let's call <code class="literal">pg_basebackup</code> and see how it works:</p><pre class="programlisting"><span class="strong"><strong>pg_basebackup -D /some_target_dir </strong></span>
<span class="strong"><strong>         -h localhost </strong></span>
<span class="strong"><strong>         --checkpoint=fast </strong></span>
<span class="strong"><strong>         --wal-method=stream </strong></span></pre><p>As we can see, we will use four parameters here:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">-D</code>: Where do we we want the base backup to live? PostgreSQL requires an empty directory. At the end of the backup, we will see a copy of the server's data directory (destination).</li><li style="list-style-type: disc"><code class="literal">-h</code>: Indicates the IP address or the name of the master (source). This is the server you want to back up.
</li><li style="list-style-type: disc"><code class="literal">--checkpoint=fast</code>: Usually, <code class="literal">pg_basebackup</code> waits for the master to checkpoint. The reason for this is that the replay process has to start somewhere. A checkpoint ensures that data has been written up to a certain point and so PostgreSQL can safely jump in there and start the replay process. Basically, it can also be done without the <code class="literal">--checkpoint=fast</code> parameter. However, it might take a while before <code class="literal">pg_basebackup</code> starts to copy data in this case. Checkpoints can be up to one hour apart, which can delay our backups unnecessarily.</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">--wal-method=stream</code>: By default, <code class="literal">pg_basebackup</code> connects to the master server and starts copying files over. Now, keep in mind that those files are modified while they are copied. The data reaching the backup is therefore inconsistent. This inconsistency can be repaired during the recovery process using the <code class="literal">WAL</code>. The backup itself, however, is not consistent. By adding the <code class="literal">--wal- method=stream</code> parameter, it is possible to create a self-contained backup; it can be started directly without replaying the transaction log. This is a nice method if we just want to clone an instance and not use PITR. Fortunately, <code class="literal">-wal-method=stream</code> is actually already the default in PostgreSQL 10.0. However, in 9.6 or earlier, it is <span>recommended</span><a id="id326647961" class="indexterm"></a> to use the predecessor, named <code class="literal">-xlog-method=stream</code>.</li></ul></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec81"></a>Reducing the bandwidth of a backup</h4></div></div></div><p>When <code class="literal">pg_basebackup</code> starts, it tries to finish its work as quickly as possible. If we have a good network connection, <code class="literal">pg_basebackup</code> is <span>definitely</span><a id="id326647992" class="indexterm"></a> able to fetch hundreds of megabytes a second from the remote server. If our server has a weak I/O system, it could mean that <code class="literal">pg_basebackup</code> could suck up all the resources easily, and end users might experience bad performance because their I/O requests are simply too slow.</p><p>To control the maximum transfer rate, <code class="literal">pg_basebackup</code> offers the following:</p><pre class="programlisting"><span class="strong"><strong>-r, --max-rate=RATE 
    maximum transfer rate to transfer data directory 
</strong></span><span class="strong"><strong>(in kB/s, or use suffix "k" or "M")</strong></span></pre><p>When we create a base backup, make sure that the disk system on the master can actually stand the load. Adjusting our transfer rate can therefore make a lot of sense.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec82"></a>Mapping tablespaces</h4></div></div></div><p>Usually, <code class="literal">pg_basebackup</code> can be called directly if we are <span>using</span><a id="id325648488" class="indexterm"></a> an identical filesystem layout on the target system. If this is not the case, <code class="literal">pg_basebackup</code> allows you to map the master's filesystem layout to the desired layout:</p><pre class="programlisting"><span class="strong"><strong>-T, --tablespace-mapping=OLDDIR=NEWDIR</strong></span>
<span class="strong"><strong>          relocate tablespace </strong></span><span class="strong"><strong>in OLDDIR to NEWDIR</strong></span></pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip78"></a>Note</h3><p>If your system is small, it could be a good idea to keep everything in one tablespace.</p></div><p>This holds true if I/O is not the problem (maybe because you are only managing a few gigabytes of data).</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec83"></a>Using different formats</h4></div></div></div><p><code class="literal">pg_basebackup</code> can create <span>various</span><a id="id325863127" class="indexterm"></a> formats. By default, it will put data in an empty directory. Essentially, it will connect to the source server and create a <code class="literal">.tar</code> over a network connection and put the data into the desired directory.</p><p>The trouble with this approach is that <code class="literal">pg_basebackup</code> will create many files, which is not suitable if we want to move the backup to an external backup solution such as Tivoli storage manager or some other solution. The <span>following listing shows the valid output formats supported by pg_basebackup</span>:</p><pre class="programlisting"><span class="strong"><strong>-F, --format=p|t             output format (plain (default), tar)</strong></span></pre><p>To create a single file, we can use the <code class="literal">-F=t</code> option. By default, it will create a file called <code class="literal">base.tar</code>, which can then be managed more easily. The downside, of course, is that we have to inflate the file again before performing PITR.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec84"></a>Testing transaction log archiving</h4></div></div></div><p>Before we dive into the actual <span>replay</span><a id="id325863172" class="indexterm"></a> process, it makes sense to actually check archiving to make sure that it is working perfectly and as expected by using a simple "ls" as shown in the next listing:</p><pre class="programlisting"><span class="strong"><strong>[hs@zenbook archive]$ ls -l </strong></span>
<span class="strong"><strong>total 212996 </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 16777216 Jan 30 09:04 000000010000000000000001 </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 16777216 Jan 30 09:04 000000010000000000000002 </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 302 Jan 30 09:04 000000010000000000000002.00000028.backup </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 16777216 Jan 30 09:20 000000010000000000000003 </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 16777216 Jan 30 09:20 000000010000000000000004 </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 16777216 Jan 30 09:20 000000010000000000000005 </strong></span>
<span class="strong"><strong>-rw------- 1 hs hs 16777216 Jan 30 09:20 000000010000000000000006 </strong></span>
<span class="strong"><strong>...</strong></span></pre><p>As soon as there is serious activity in the database, <code class="literal">WAL</code> files should be sent to the archive.</p><p>In addition to just checking for files, the following view can be useful:</p><pre class="programlisting"><span class="strong"><strong>test=# \d pg_stat_archiver</strong></span>
<span class="strong"><strong>              View "pg_catalog.pg_stat_archiver"</strong></span>
<span class="strong"><strong> Column             </strong></span><span class="strong"><strong>|         Type             | Modifiers</strong></span>
<span class="strong"><strong>--------------------+--------------------------+-----------</strong></span>
<span class="strong"><strong> archived_count     | bigint                   | 
 last_archived_wal  | text                     |
 last_archived_time | timestamp with time zone |     
 failed_count       | bigint                   |
 last_failed_wal    | text                     | 
 last_failed_time   | timestamp with time zone |</strong></span>
<span class="strong"><strong> stats_reset        </strong></span><span class="strong"><strong>| timestamp with time zone |</strong></span></pre><p>The <code class="literal">pg_stat_archiver</code> system view is very useful for figuring out if and when archiving has stalled for whatever reason. It will tell us about the number of files already archived (<code class="literal">archived_count</code>). We can also see which file was the last one and when the event happened. Finally, the <code class="literal">pg_stat_archiver</code> system view can tell us when archiving has gone wrong, which is vital information. Unfortunately, the error code or the error message is not shown in the table, but since <code class="literal">archive_command</code> can be an arbitrary command, it is easy to log.</p><p>There is one more thing to see in the archive. As we described previously, it is important to see that those files are actually archived. But there's more. When the <code class="literal">pg_basebackup</code> command-line tool is called, we will see a <code class="literal">.backup</code> file in the stream of <code class="literal">WAL</code> files. It is small and contains only some information about the base backup itself—it is purely informative and is not needed by the replay process. However, it gives us some vital clues. When we start to replay the transaction log later on, we can delete all <code class="literal">WAL</code> files that are older than the <code class="literal">.backup</code> file. In this case, our backup file is called <code class="literal">000000010000000000000002.00000028.backup</code>. This means that the replay process starts somewhere within file <code class="literal">...0002</code> (at position <code class="literal">...28</code>). It also means that we can delete all files older than <code class="literal">...0002</code>. Older <code class="literal">WAL</code> files won't be needed for recovery anymore. Keep in mind that we can keep more than just one backup around, so I am only referring to the <span>current</span><a id="id325887860" class="indexterm"></a> backup.</p><p> </p><p>Now that archiving works, we can turn our attention to the replay process.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec102"></a>Replaying the transaction log</h3></div></div></div><p>Let's sum up the process so far. We have adjusted the <code class="literal">postgresql.conf</code> file (<code class="literal">wal_level</code>, <code class="literal">max_wal_senders</code>, <code class="literal">archive_mode</code>, and <code class="literal">archive_command</code>) and we <span>have</span><a id="id325895953" class="indexterm"></a> allowed for the <code class="literal">pg_basebackup</code> command in the <code class="literal">pg_hba.conf</code> file. Then, the database was restarted and a base backup was successfully produced.</p><p>Keep in mind that base backups can only happen while the database is fully operational—only a brief restart to change the <code class="literal">max_wal_sender</code> and <code class="literal">wal_level</code> variables is needed. </p><p>Now that the system is working properly, we might face a crash that we will want to recover from. Therefore, we can perform PITR to restore as much data as possible. The first thing we've got to do is take the base backup and put it at the desired location.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip79"></a>Note</h3><p>It can be a good idea to save the old database cluster. Even if it is broken, our PostgreSQL support company might need it to track down the reason for the crash. You can still delete it later on, once you've got everything up and running again.</p></div><p>Given the preceding filesystem layout, we might want to do something as follows:</p><pre class="programlisting"><span class="strong"><strong>cd /some_target_dir cp -Rv * /data</strong></span></pre><p>We're assuming that the new database server will be located in the <code class="literal">/data</code> directory. Make sure that the directory is empty before you copy the base backup over.</p><p>In the next step, a file called <code class="literal">recovery.conf</code> can be created. It will contain all the information concerning the replay process such as the position of the <code class="literal">WAL</code> archive, the time we want to reach, and so on.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip80"></a>Note</h3><p>In PostgreSQL 10.0, the <code class="literal">recovery.conf</code> file will most likely not exist anymore. Settings are expected to be moved to the <code class="literal">postgresql.conf</code> file. At the time of writing this book, it is not totally clear what will happen precisely.</p></div><p>Here is a sample <code class="literal">recovery.conf</code> file:</p><pre class="programlisting"><span class="strong"><strong>restore_command = 'cp /archive/%f %p' 
recovery_target_time = '2019-04-05 15:43:12'</strong></span></pre><p>After putting the <code class="literal">recovery.conf</code> file into the <code class="literal">$PGDATA</code> directory, we can <span>simply</span><a id="id325896177" class="indexterm"></a> start up our server. The output might look as follows:</p><pre class="programlisting"><span class="strong"><strong>server starting </strong></span>
<span class="strong"><strong>LOG: database system was interrupted; last known up </strong></span>
<span class="strong"><strong>   at 2017-01-30 09:04:07 CET </strong></span>
<span class="strong"><strong>LOG: starting point-in-time recovery to 2019-04-05 15:43:12+02 </strong></span>
<span class="strong"><strong>LOG: restored log file "000000010000000000000002" from archive </strong></span>
<span class="strong"><strong>LOG: redo starts at 0/2000028 </strong></span>
<span class="strong"><strong>LOG: consistent recovery state reached at 0/20000F8 </strong></span>
<span class="strong"><strong>LOG: restored log file "000000010000000000000003" from archive </strong></span>
<span class="strong"><strong>LOG: restored log file "000000010000000000000004" from archive </strong></span>
<span class="strong"><strong>LOG: restored log file "000000010000000000000005" from archive </strong></span>
<span class="strong"><strong>... </strong></span>
<span class="strong"><strong>LOG: restored log file "00000001000000000000000E" from archive </strong></span>
<span class="strong"><strong>cp: cannot stat '/archive/00000001000000000000000F': </strong></span>
<span class="strong"><strong>   No such file or directory </strong></span>
<span class="strong"><strong>LOG: redo done at 0/E7BF710 </strong></span>
<span class="strong"><strong>LOG: last completed transaction was at log time </strong></span>
<span class="strong"><strong>   2017-01-30 09:20:47.249497+01 </strong></span>
<span class="strong"><strong>LOG: restored log file "00000001000000000000000E" from archive </strong></span>
<span class="strong"><strong>cp: cannot stat '/archive/00000002.history': No such file or directory </strong></span>
<span class="strong"><strong>LOG: selected new timeline ID: 2 </strong></span>
<span class="strong"><strong>cp: cannot stat '/archive/00000001.history': No such file or directory </strong></span>
<span class="strong"><strong>LOG: archive recovery complete </strong></span>
<span class="strong"><strong>LOG: MultiXact member wraparound protections are now enabled </strong></span>
<span class="strong"><strong>LOG: database system is ready to accept connections </strong></span>
<span class="strong"><strong>LOG: autovacuum launcher started</strong></span></pre><p>When the server is started, there are a couple of messages to look for to ensure that our recovery works perfectly: the first one is <code class="literal">consistent recovery state reached</code>. This message means that PostgreSQL could replay enough of the transaction log to bring the database back to a state that makes it usable.</p><p>Then, PostgreSQL will copy one file after the other and replay them. However, remember that we have told the <code class="literal">recovery.conf</code> file to bring us all the way up to 2019. This text was written in 2017, so there is clearly not enough <code class="literal">WAL</code> to reach 2019. Therefore, PostgreSQL will error out and tell us about the last completed transaction.</p><p>Of course, this is just a showcase, and in real-world examples, we will most likely use a date in the past, which we can use to safely recover. However, I wanted to show you that it is perfectly feasible to use a date in the future—just be prepared to accept the fact that <span>errors</span><a id="id325958128" class="indexterm"></a> will happen.</p><p>After the recovery has finished, the <code class="literal">recovery.conf</code> file will be renamed <code class="literal">recovery.done</code> so that we can see what we have done during recovery. All of the processes of our database server will be up and running and we will have a ready-to-use database instance.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl3sec85"></a>Finding the right timestamp</h4></div></div></div><p>So far, we have progressed under the <span>assumption</span><a id="id325981670" class="indexterm"></a> that we know the timestamp we want to recover, or that we simply want to replay the whole transaction log to reduce data loss. However, what if we don't want to replay everything? What if we don't know which point in time to recover to? In everyday life, this is actually a very common scenario. One of our developers loses some data in the morning and we are supposed to make things fine again. The trouble is this: at what time in the morning? Once the recovery has ended, it cannot be restarted easily. Once recovery is completed, the system will be promoted, and once it has been promoted, we cannot continue to replay <code class="literal">WAL</code>.</p><p>However, what we can do is pause recovery without promotion, check what is inside the database, and continue.</p><p>Doing that is easy. The first thing we have to make sure of is that the <code class="literal">hot_standby</code> variable is set to <code class="literal">on</code> in the <code class="literal">postgresql.conf</code> file. This will make sure that the database is readable while it is still in recovery mode. Then, we have to adapt the <code class="literal">recovery.conf</code> file before starting the replay process:</p><pre class="programlisting"><span class="strong"><strong>recovery_target_action = 'pause'</strong></span></pre><p>There are various <code class="literal">recovery_target_action</code> settings. If we use pause, PostgreSQL will pause at the desired time and let us check what has already been replayed. We can adjust the time we want, restart, and try again. Alternatively, we can set the value to promote or shutdown.</p><p>There is a second way to pause transaction log replay. Basically, it can also be used when performing PITR. However, in most cases, it is used with streaming replication. Here is what can be done during <code class="literal">WAL</code> replay:</p><pre class="programlisting"><span class="strong"><strong>postgres=# \x</strong></span>
<span class="strong"><strong>Expanded display is on. </strong></span>
<span class="strong"><strong>postgres=# \df *pause* 
List of functions</strong></span>
<span class="strong"><strong>-[ RECORD 1 ]-------+------------------------- 
Schema              | pg_catalog</strong></span>
<span class="strong"><strong>Name                | pg_is_wal_replay_paused</strong></span>
<span class="strong"><strong>Result </strong></span><span class="strong"><strong>data type    | boolean</strong></span>
<span class="strong"><strong>Argument </strong></span><span class="strong"><strong>data types |</strong></span>
<span class="strong"><strong>Type                | normal</strong></span>
<span class="strong"><strong>-[ RECORD 2 ]-------+------------------------- 
Schema              | pg_catalog</strong></span>
<span class="strong"><strong>Name                | pg_wal_replay_pause</strong></span>
<span class="strong"><strong>Result </strong></span><span class="strong"><strong>data type    | void</strong></span>
<span class="strong"><strong>Argument </strong></span><span class="strong"><strong>data types |</strong></span>
<span class="strong"><strong>Type                | normal</strong></span>

<span class="strong"><strong>postgres=# \</strong></span><span class="strong"><strong>df *resume* 
List of functions</strong></span>
<span class="strong"><strong>-[ RECORD 1 ]-------+---------------------- 
Schema              | pg_catalog</strong></span>
<span class="strong"><strong>Name                | pg_wal_replay_resume</strong></span>
<span class="strong"><strong>Result </strong></span><span class="strong"><strong>data type    | void</strong></span>
<span class="strong"><strong>Argument </strong></span><span class="strong"><strong>data types |</strong></span>
<span class="strong"><strong>Type                | normal</strong></span></pre><p>We can call the <code class="literal">SELECT pg_wal_replay_pause();</code> command to halt <code class="literal">WAL</code> replay <span>until</span><a id="id325998866" class="indexterm"></a> we call the <code class="literal">SELECT pg_wal_replay_resume();</code> command.</p><p>The idea is to figure out how much <code class="literal">WAL</code> has already been replayed and to continue as necessary. However, keep this in mind: once a server has been promoted, we cannot just continue to replay <code class="literal">WAL</code> without further precautions.</p><p>As we have already seen, it can be pretty tricky to figure out how far we need to recover. Therefore, PostgreSQL provides us with some help. Consider the following real-world example: at midnight, we are running a nightly process that ends at some point that is usually not known. The goal is to recover exactly to the end of the nightly process. The trouble is this: how do we know when the process has ended? In most cases, this is hard to figure out. So, why not add a marker to the transaction log, as follows:</p><pre class="programlisting"><span class="strong"><strong>postgres=# SELECT pg_create_restore_point('my_daily_process_ended');</strong></span>
<span class="strong"><strong> pg_create_restore_point</strong></span>
<span class="strong"><strong>-------------------------</strong></span>
<span class="strong"><strong> 1F/E574A7B8</strong></span>
<span class="strong"><strong>(1 row)</strong></span></pre><p>If our process calls this SQL statement as soon as it ends, it will be possible to use this label in the transaction log to recover exactly to this point in time by adding the following directive to the <code class="literal">recovery.conf</code> file:</p><pre class="programlisting"><span class="strong"><strong>recovery_target_name = 'my_daily_process_ended'</strong></span></pre><p>Using this setting instead of <code class="literal">recovery_target_time</code>, the replay process will us beamexactly to the end of the nightly process.</p><p>Of course, we can also replay up to a certain transaction ID. However, in real life, this has proven to be difficult as the exact transaction ID is rarely ever <span>known</span><a id="id326000400" class="indexterm"></a> to the administrator, and therefore, there is not much practical value in this.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl2sec103"></a>Cleaning up the transaction log archive</h3></div></div></div><p>So far, data is being written to the <span>archive</span><a id="id326000414" class="indexterm"></a> all of the time and no attention has been paid to cleaning out the archive again to free up space in the filesystem. PostgreSQL cannot do this job for us because it has no idea whether we want to use the archive again. Therefore, we are in charge of cleaning up the transaction log. Of course, we can also use a backup tool—however, it is important to know that PostgreSQL has no chance of doing the cleanup for us.</p><p>Suppose we want to clean up an old transaction log that is not needed anymore. Maybe we want to keep several base backups around and clean out all transaction logs that won't be needed anymore to restore one of those backups.</p><p>In this case, the <code class="literal">pg_archivecleanup</code> command-line tool is exactly what we need. We can simply pass the archive directory and the name of the backup file to the <code class="literal">pg_archivecleanup</code> command, and it will make sure that files are removed from disk. Using this tool makes life easier for us because we don't <span>have</span><a id="id326008185" class="indexterm"></a> to figure out which transaction log files to keep on our own. Here is how it works:</p><pre class="programlisting"><span class="strong"><strong>[hs@asus ~]$ pg_archivecleanup --help</strong></span>
<span class="strong"><strong>pg_archivecleanup removes older WAL files from PostgreSQL archives.</strong></span>

<span class="strong"><strong>Usage:</strong></span>
<span class="strong"><strong>  pg_archivecleanup [OPTION]... ARCHIVELOCATION OLDESTKEPTWALFILE</strong></span>

<span class="strong"><strong>Options:</strong></span>
<span class="strong"><strong>  -d generate debug output (verbose mode)</strong></span>
<span class="strong"><strong>  -n dry run, show the names of the files that would be removed</strong></span>
<span class="strong"><strong>  -V, --version output version information, then exit</strong></span>
<span class="strong"><strong>  -x EXT clean up files if they have this extension</strong></span>
<span class="strong"><strong>  -?, --help show this help, then exit</strong></span>

<span class="strong"><strong>For use as archive_cleanup_command in recovery.conf when standby_mode = on:</strong></span>
<span class="strong"><strong>  archive_cleanup_command = 'pg_archivecleanup [OPTION]... ARCHIVELOCATION %r'</strong></span>
<span class="strong"><strong>e.g.</strong></span>
<span class="strong"><strong>  archive_cleanup_command = 'pg_archivecleanup /mnt/server/archiverdir %r'</strong></span>

<span class="strong"><strong>Or for use as a standalone archive cleaner:</strong></span>
<span class="strong"><strong>e.g.</strong></span>
<span class="strong"><strong>  pg_archivecleanup /mnt/server/archiverdir 000000010000000000000010.00000020.backup</strong></span></pre><p>The tool can be <span>used</span><a id="id326008681" class="indexterm"></a> easily, and is available on all platforms.</p></div></div>