<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec35"></a>Fault tolerance</h2></div></div><hr /></div><p>To gracefully handle failures, Mesos <span>implements</span><a id="id325092441" class="indexterm"></a> two features, both enabled by default, known as <span class="strong"><strong>check pointing</strong></span> and <span class="strong"><strong>slave recovery</strong></span>. Check pointing is a feature enabled in both the framework and on the slave, which <span>allows</span><a id="id325245069" class="indexterm"></a> certain information <span>about</span><a id="id325245086" class="indexterm"></a> the state of the cluster to be persistent periodically to the disk. The state of the cluster is written to the disk on the Mesos slave server. The check-pointed data includes information on the task, such as executors and status updates. The second one is slave recovery. Slave recovery allows the Mesos slave daemon to read the state from the disk, and reconnect to running executors and tasks should the Mesos slave daemon fail or be restarted. If the Mesos slave daemon fails or is restarted, slave recovery helps to read the state from the disk and reconnect to the running executors and tasks.</p><p>So, by just refreshing the Mesos cluster, we can see that both <code class="literal">master2</code> and <code class="literal">master1</code> are available for us, and that <code class="literal">master3</code> is down. <code class="literal">mesos-master2</code> is the leader. During the <span class="emphasis"><em>Resources and Attributes</em></span> section, we ran nginx instances. <code class="literal">mesos-slave1</code> has two nginx instances, <code class="literal">mesos-slave3</code> has four, and <code class="literal">mesos-slave2</code> has three. We will stop one of the Mesos slaves and see what happens. Let's navigate to Marathon on <code class="literal">slave1</code>. For now, we can see that the URL is accessible:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/37a9281a-12f9-4494-9ae1-78d92fcdd7d6.png" /></div><p>This is the landing page for our nginx server. So, what we are going to do here is stop the Mesos slave and see if we are still able to access the landing page for both instances. Go to <code class="literal">slave1</code> and run the following command:</p><pre class="programlisting">sudo service mesos-slave</pre><p>Then stop status, and it will be stopped. Let's move to our console. We can see that <code class="literal">mesos-slave1</code> has two nginx servers running. Refresh this. Let's check the agents as well. We can still see the agent. In a few minutes, the agent will be gone, because as soon as the clusters find out that the slave is away, cluster will move the slave agent, and the resource count will also go down. Now, when we click on <strong class="userinput"><code>Agents</code></strong>, we will see only <code class="literal">meso-slave2</code> and <code class="literal">slave3</code>. Check the resources; we will see only 1 for CPU, whereas previously it was 1.8 CPU, and that the task is Running. It will not show the <span>nginx</span><a id="id325485800" class="indexterm"></a> instance, which is running on the <code class="literal">meso-slave1</code> server.</p><p>So, let's quickly refresh and see if our application is up and running. If the slave is down, we can still access our application. So, let's quickly restart the slave now. After this, with the slave running again, go to your console, refresh it, and we will see that our nginx task is back. As soon as we restarted our Mesos slave, it got the information of Task Name and again made the resources available. The CPU allocation rises to 1.8. This is how fault tolerance works for the Mesos slave, with the help of checkpointing and slave recovery. Let's quickly look at how Mesos handles failures. A number of events typically cause downtime and outages for infrastructure, including network partitions, machine failures, power outages, and so on. We will explore fault tolerance and high availability in Mesos within the context of three potential failure scenarios. The first one is machine failure, where the underlying physical or virtual host fails. In service process failure, the Mesos master or Mesos slave daemon fails. Third is upgrades. If we want to upgrade from one version to another, the Mesos master or Mesos slave daemon must be restarted. Fortunately, Mesos and the Mesos frameworks are capable of handling each of these failure modes.</p><p>We saw, with the example of the Mesos master, how high availability for the Mesos cluster can be achieved using ZooKeeper. Now, we will see what happens to the task if the Mesos slave server goes down.</p><p>So, let's quickly do an exercise on the Mesos slave. If our Mesos slave goes down, how will the task run? Let's learn how Mesos handles these failures. Currently, we have one nginx instance running, which is on <code class="literal">slave3</code>, so let's stop this <code class="literal">mesos-slave3</code> process. To do this, go into the slave 3 server and enter the following command:</p><pre class="programlisting">sudo service mesos-slave stop</pre><p>Check the status to make sure that we have stopped the service. Quickly go back to the console. As we already know, once you stop the slave process, our instance will keep on running. This is our slave service, which is on <code class="literal">slave3</code>. It'll just take some time to reload, so hang on a little while. Soon, you will see <code class="literal">slave3</code> disappear, but our process will still be running. Here, we can see that the process has gone to <code class="literal">mesos-slave2</code>. </p><p>As we saw, we have stopped <code class="literal">mesos-slave3</code>-automatically; this was detected and the service went to another server. Let's quickly check that it's still working. Let's stop the <code class="literal">mesos-slave2</code> as well now. After this, we can go to our console and check this. This confirms that one more instance was started on <code class="literal">slave1</code>. This <span>shows</span><a id="id325485923" class="indexterm"></a> that as soon as we stop one of the slaves, cluster moves the all of the tasks to another server.</p><p> </p><p>Here, we learned how to install Mesos and its supporting tools and how to install the Mesos master and slaves. We also installed Marathon and Docker.</p></div>