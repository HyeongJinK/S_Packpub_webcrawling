<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec39"></a>Setting up Marathon-lb</h2></div></div><hr /></div><p>First, we should understand <span>why</span><a id="id325245756" class="indexterm"></a> we need Marathon-lb set up. We already deployed a WordPress container in the previous section. So, you have one instance, you know the server name and the port, and, when you click on the link, it will bring up the output page—the WordPress landing page. If you are working on only one instance, then you don't have to use Marathon-lb; you can just have your public IP map to another DNS name and you can access that. In our case, our server is <code class="literal">mesos-master2</code>, so what we can do is we can just access the <code class="literal">mesos-master2</code> server on a specific port and then it will get access. You can just configure a load balancer and point to this server on this port and your work is done. In that scenario, you don't need a Marathon-lb setup; you can directly point your AWS Load Balancer to this instance on this specific port and your work is done, but if you're planning to scale your server, you will need Marathon-lb.</p><p>Let's scale our application to three instances. If you don't have Marathon-lb then, each time you scale the application, you need to point to another server as well in your load balancer, which is a manual step and time consuming. Currently, we have just added two more instances, but in the real world you might need more than three instances for your application, and you want it to be automatically managed. As soon as the new service comes in, your server or your load balancer should know the server name and the IP address or the server name and port number, and it should get automatically load balanced to that server as well. As soon as your new service arises, it will validate the new service and it will add it in your configuration so your customers can access that server as well. So, the new server is ready to get served, and that's where Marathon-lb comes in very handy to manage your application.</p><p> </p><p>We will see how we will set up the Marathon-lb and then we will see how we can configure HAProxy inside your application. We will use a Docker container for the Marathon-lb set up. We will set up two Docker containers on <code class="literal">marathon1</code> and <code class="literal">marathon2,</code> so it's resilient and highly available for us. If either one goes down, the other one will be available to serve the request. Let's run the Docker container. Here is the command to run your Marathon-lb inside the Docker container:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker run -d -p 9090:9090 --add-host="mesos-slavel:10.0.1.85" -    -add-host="mesos-slave2:10.0.1.174"</strong></span></pre><p>The detached mode is<code class="literal">docker run -d</code>, and <code class="literal">9090</code> is the port where HAProxy will bind. So, you can see these ports; we have told HAProxy to use the <code class="literal">9090</code> port. For access, we will bind the <code class="literal">9090</code> container port to the <code class="literal">9090</code> host port, and then we have used a <code class="literal">--add-host</code> flag. So, this is our Mesos master and slave server. The information will get added in the host file so, in the cluster configuration, HAProxy will know the IP of the server. By using the <code class="literal">--add-host</code> flag, it will add the name and IP to the host file inside your container. Then we will use the <code class="literal">-e PORTS=9090</code> environment, which will inform HAProxy to use the <code class="literal">9090</code> port. We will download this image from Docker Marathon-lb, and then we will give the <code class="literal">--marathon</code> command. This is again an environment variable to inform HAProxy to use the Marathon UI on this port to fetch the application details. We will be using <code class="literal">sse</code> mode. In <code class="literal">sse</code> mode, scripts connect to the Marathon events and point to get notified about state changes. So, that's where, when you deploy the new application, it quickly checks the service detail and makes the changes accordingly, so the new services are ready to be served. Let's press <span class="emphasis"><em>Enter</em></span>:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/171a6ca3-5423-4085-be47-ad58f9240b2a.png" /></div><p>The image has been downloaded and it is in the running state now. To validate that, run the following command:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker ps -a</strong></span></pre><p> </p><p> </p><p>So, you can see the container ID, image, and <span>command</span><a id="id325482955" class="indexterm"></a> ran inside the container, and you can see the <code class="literal">9090</code> port is mapped. We will do the same thing in the <code class="literal">marathon2</code> server.</p><p>Let's access the HAProxy on the <code class="literal">9090</code> port:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/da016fd8-557e-4b9f-8477-3d701a021f7e.png" /></div><p>So, this is our <code class="literal">marathon1</code> server on the <code class="literal">9090</code> port. As you can see, it has started checking the events, and it has started checking the services that are running inside the cluster. So, right now, you know we have scaled the services; it grabbed that information and it is showing it in the preceding output.</p><p>So, that's how Marathon-lb works. Now we'll scale one more server and scale it to four, so we have four instances of WordPress. First, let's refresh <code class="literal">marathon1</code>. As soon as you have refreshed, you will see the four instances running, so you don't have to worry about adding the configuration manually. So, Marathon-lb using HAProxy detects the new services and makes the changes so your new service is available and ready to get served.</p><p> </p><p>Let's delete this application and see what state we see in the HAProxy console. Go to <strong class="userinput"><code>Application</code></strong> and click <strong class="userinput"><code>Destroy</code></strong>. Refresh, and then you will see Marathon-lb has detected there are no services running, so all the settings are gone now. So, let's deploy the WordPress application again. We already have our database instance running, so when we deploy our application, it will connect to our database as well. Go to RDS instances and our database instance is available. Let's go to the Marathon console, and again create an application called <code class="literal">wordpress</code>—what we have already created in the previous section. Let's validate it by clicking on the ID:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/9cda0753-aa7f-4a4d-943d-597b6c79d988.png" /></div><p>So, you can see the WordPress landing page. If you refresh our HAProxy page, you don't see any information, so you need to understand why this information is not there. We need to define a HAProxy group. So, while starting our instance, we have defined <code class="literal">--group external</code>. We have defined this while running our Marathon-lb container. We need to define this group in the application. While <span>deploying</span><a id="id325485831" class="indexterm"></a> the application, we need to include a special label with a key HAProxy group, and we have not defined that in our deployment. So, go to <strong class="userinput"><code>Edit</code></strong> and change its labels:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/bfe100a7-79ee-435d-b783-76e8b561dc12.png" /></div><p>So, this is how, after defining an HAProxy group, Marathon-lb knows which services needs to be exposed:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/692c528b-0e34-43c8-a0cb-a421267993da.png" /></div><p> </p><p>The WordPress container is exposed on port <code class="literal">10000</code>; HAProxy automatically assigned this port, but there is a way you can control this port as well. Go to the Marathon console, click on <strong class="userinput"><code>wordpress</code></strong>, and go <strong class="userinput"><code>Configuration</code></strong>. You can change the port as per your requirement. So, let's change it; go to <strong class="userinput"><code>JSON Mode</code></strong> and change <code class="literal">servicePort</code> to <code class="literal">10001</code>:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/75997e14-b4b5-4a43-865b-be442ae16912.png" /></div><p>Refresh the HAProxy page and you can see the port has changed:</p><p>So, this port is useful when you run the Marathon-lb container. You need to bind this port to your localhost in the Marathon-lb server. So, as of now, we can directly access the WordPress container using the server name and port, which is defined in our cluster configuration, which you can access to see your page, but our main focus is how we will access all four instances after scaling.</p><p> </p><p>You can't add them each one by one, so you need to have Marathon-lb set up. So, let's quickly set up the configuration for Marathon-lb. We need to bind the <code class="literal">10001</code> port to our local server in the same way we did when we bound the HAProxy <code class="literal">9090</code> port to our local server. According to our requirement, you can use whichever port you like, and then you can change the service port in your <span>Marathon</span><a id="id325490076" class="indexterm"></a> UI. We've seen how we changed from <code class="literal">10000</code> to <code class="literal">10001</code>. First, we will stop the services in <code class="literal">marathon1</code> by running the following command:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker ps -a</strong></span>
<span class="strong"><strong>$ sudo docker stop d6f95d09d2de</strong></span></pre><p>We will do the same thing on <code class="literal">marathon2</code> server and we will remove this container because we need to run a new container with our port definitions:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker ps -a</strong></span>
<span class="strong"><strong>$ sudo docker stop 5f726bb00028</strong></span>
<span class="strong"><strong>$ sudo docker rm 5f726bb00028</strong></span></pre><p>So, now we will run the new container:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker run -d -p 9090:9090 -p 8081:10001 --add-host="mesos-slave:10.0.1.85"</strong></span>
<span class="strong"><strong>...</strong></span></pre><p>We are putting one more port mapping, which is <code class="literal">-p</code>, then the local port you are looking for— <code class="literal">8081</code>—and then <code class="literal">10001</code>. So, you can change the port according to your requirements. If you want to change it to <code class="literal">2</code>, you can do this and then go there in the application configuration and change the service port. So, as of now we'll keep this as <code class="literal">1</code>. Let's validate our server:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker ps -a</strong></span></pre><p> </p><p> </p><p>So, you can see our container is running and it has mapped to our localhost on port <code class="literal">8081</code>. Now, we will access the WordPress container via our Marathon-lb. So, let's refresh HAProxy page; as of now, we only have one instance running. Enter <code class="literal">marathon1:8081</code>. So, you can <span>see</span><a id="id325493453" class="indexterm"></a> we can now access on <code class="literal">marathon1:8081</code> via Marathon-lb:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/cc9599ac-6208-48df-9ffb-f8d0766cdb70.png" /></div><p> </p><p>So, we have successfully done our configuration. Let's scale the application, and make it 3, and you will see our two other instances have been started on another server, which are <code class="literal">mesos-slave3</code> and <code class="literal">mesos-master2</code>. We can access it by clicking on the IDs. So, let's go via Marathon-lb server and <code class="literal">marathon1:8081</code>, and you will still have access, so it will load balance on all the three servers. Let's check our HAProxy; you can see the three servers are listed here:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/be4dbb85-b090-410e-9c6a-e6d7e0c17810.png" /></div><p>So, now it will send a request to all three servers; this is how you can scale your application as per the load. If you can see, on a specific day, that there is a used load or there is any scale going on, you can quickly scale in the application according to your requirements. Now we'll do the same stuff on the <code class="literal">marathon2</code> server, and you will see you can access the WordPress via <code class="literal">marathon2</code>.</p><p>Now, we will have a Marathon-lb high availability setup. We will use AWS Load Balancer and, as we have done for Mesos and Marathon, we will do the same for Marathon-lb. We will have a load balancer that will point to Marathon-lb on port <code class="literal">8081</code>. So, now you will load balance <code class="literal">marathon1</code> and <code class="literal">marathon2</code> on port <code class="literal">8081,</code> which is our Marathon-lb via AWS Load Balancer.</p><p>So, go to RDS, then go to EC2 instances. Click <strong class="userinput"><code>Load Balancers</code></strong>, then <strong class="userinput"><code>Create Load Balancer</code></strong>. You will have <strong class="userinput"><code>Application Load Balancer</code></strong>. For the <strong class="userinput"><code>Configure Load Balancer</code></strong> step, provide the name, <code class="literal">wordpress-lb</code>. We need <strong class="userinput"><code>internet-facing</code></strong>, which will load balance on port <code class="literal">80</code>, and our <strong class="userinput"><code>VPC</code></strong> is <strong class="userinput"><code>Mesos</code></strong>. Click both zones and click <strong class="userinput"><code>Next</code></strong>. In the <strong class="userinput"><code>Configure Security Groups</code></strong> step, create a new security group and name it <code class="literal">wordpress-lb</code>. The description will be <code class="literal">wordpress load balancer</code>. Then click <strong class="userinput"><code>Next</code></strong>.</p><p>Here, we will <strong class="userinput"><code>Configure Routing</code></strong>, so we will define <strong class="userinput"><code>New target group</code></strong> in <strong class="userinput"><code>Target group</code></strong>; we will define our servers, which are <code class="literal">marathon1</code> and <code class="literal">marathon2</code>. We'll first name the target group <code class="literal">wordpress-lb</code>: the port that we want is <code class="literal">8081</code>, and the target type is <code class="literal">instance</code>. Then we will click <strong class="userinput"><code>Next</code></strong>. In the <strong class="userinput"><code>Register Targets</code></strong> step, you need to add <code class="literal">marathon2</code> and <code class="literal">marathon1</code> as a target, click <strong class="userinput"><code>Add to registered</code></strong>, and click <strong class="userinput"><code>Next</code></strong>.</p><p>Let's quickly check the <strong class="userinput"><code>Health checks</code></strong>; under the <strong class="userinput"><code>Configuring Routing</code></strong> step, add <code class="literal">301</code> and <code class="literal">302</code> to <strong class="userinput"><code>Success code</code></strong>, click <strong class="userinput"><code>Next</code></strong>, and then you can click <strong class="userinput"><code>Create</code></strong>. So, it will successfully create a load balancer. So, we can see the state is active—that means our load balancer is up and running. Copy the <strong class="userinput"><code>DNS name</code></strong> URL:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/716bb35f-09fd-4bf2-a4d9-e77ae38cd2ee.png" /></div><p>Paste it in the browser. So, you can see the same landing page appears here:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/f7998148-aaf6-43bf-9a08-5484dab56618.png" /></div><p> </p><p>It means our load balancer is forwarding the request to our Marathon-lb, which is inside the Docker container on the <code class="literal">marathon1</code> and <code class="literal">marathon2</code> servers. So, let's <span>quickly</span><a id="id325093089" class="indexterm"></a> see the configuration. Go to <strong class="userinput"><code>Target Groups</code></strong>, and click <code class="literal">wordpress-lb</code>. The most important part is we need to see whether our target is healthy or not:</p><div class="mediaobject"><img src="/graphics/9781789137385/graphics/7584483a-932a-4197-812e-62d66a31138c.png" /></div><p>Now we will stop one server, <code class="literal">marathon2</code>, and see what happens:</p><pre class="programlisting"><span class="strong"><strong>$ sudo docker ps -a</strong></span>
<span class="strong"><strong>$ sudo docker stop 7e660e167778</strong></span>
<span class="strong"><strong>$ sudo docker ps -a</strong></span></pre><p>Let's validate on the browser. If you refresh it, you will get <strong class="userinput"><code>502 Bad Gateway</code></strong>. We need to wait till that instance gets unhealthy, and then our AWS will remove it from the target group. You will see now one of the instances is unhealthy, so if you again refresh the browser, you will see the request will go to another server. Go to <strong class="userinput"><code>Load Balancers</code></strong>, then go to <strong class="userinput"><code>Target Groups</code></strong>. In <strong class="userinput"><code>Target Groups</code></strong>, click <code class="literal">wordpress-lb</code> and <strong class="userinput"><code>Health Checks</code></strong>. In this health check, click <strong class="userinput"><code>Edit</code></strong>, and then you can minimize the values, such as making the <strong class="userinput"><code>Healthy</code></strong><strong class="userinput"><code>threshold</code></strong> <code class="literal">2</code>, then you can keep the <strong class="userinput"><code>Unhealthy threshold</code></strong> as is, but you can make changes in <strong class="userinput"><code>Interval</code></strong> by adding <code class="literal">10</code>, so it will quickly check the service and it will mark it as unhealthy, and it will only show which instances are available. So, that's how you can make changes to quickly bring up the services if one of the instances is down.</p><p> </p><p> </p><p>Let's stop both instances. Go in <code class="literal">marathon1</code> and stop this as well using <code class="literal">sudo docker stop, container ID</code>. Now go to the EC2 console, check the <strong class="userinput"><code>Targets—</code></strong>both are unhealthy, so go to browser. So, again, we will get <strong class="userinput"><code>502 Bad Gateway</code></strong> because both instances are in an unhealthy state. Let's start one of the Marathon-lb containers again using <code class="literal">sudo docker ps -a</code>. So, it's up and running. Go to EC2 and <span>refresh</span><a id="id325093201" class="indexterm"></a> this. You can see one of the instances that we started is in a healthy state. Again, go to the browser and refresh, and then you will get the page.</p><p>I'm sure Marathon-lb will be useful in your environment.</p></div>