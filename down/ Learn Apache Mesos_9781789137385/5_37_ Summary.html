<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec40"></a>Summary</h2></div></div><hr /></div><p>We learned how to configure AWS Load Balancer for the Marathon and Mesos master console. AWS Load Balancer helped us to route requests for both the Marathon and all three Mesos master servers. This helped us to ease the management for Mesos and Marathon services. Then, we enabled the containerizer in all of the Mesos slave servers, and we added a Marathon user on all of the slave servers. Both settings are necessary for the deployment of our application on all slaves servers.</p><p>Then, we deployed a sample nginx server using the Marathon framework and we saw how you can scale multiple instances very quickly and easily. Then, we took a real-world example where we created an RDS MySQL database for WordPress in AWS, then we deployed a WordPress container in a Mesos cluster and connected a WordPress container to the database.</p><p>Then we deployed Marathon-lb, which is based on HAProxy. Marathon-lb is a service discovery tool that is useful when your new service is deployed on your Mesos cluster. It quickly detects that and adds those configurations in the Mesos-lb configuration, and makes the services available for customers; it does everything automatically, and there's no need for manual intervention there. So, once you scale your services, the Marathon-lb HAProxy will detect that and add those configurations and make those services available for your customers. We deployed two Marathon-lb servers, which were load balanced using AWS Load Balancer, so we achieved high availability and resilience there as well. In the next chapter, we will learn about persistent volumes and how to use it in Docker.</p></div>