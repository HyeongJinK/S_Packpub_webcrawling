<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec58"></a>Creating tasks in Celery</h2></div></div><hr /></div><p>As stated before, Celery tasks are just user-defined functions that perform some operations. But before any tasks can be written, our Celery object needs to be created. This is the object that the <span>Celery</span><a id="id324991592" class="indexterm"></a> server will import to handle running and scheduling all of the tasks.</p><p>At a bare minimum, Celery needs one configuration <span>variable</span><a id="id325371880" class="indexterm"></a> to run, and that is the connection to the message broker. The connection is defined the same as the SQLAlchemy connection; that is, as a URL. The backend, which stores our tasks' results, is also defined as a URL, as shown in the following code:</p><pre class="programlisting">class DevConfig(Config): 
    DEBUG = True 
    SQLALCHEMY_DATABASE_URI = 'sqlite:///../database.db' 
    CELERY_BROKER_URL = "amqp://rabbitmq:rabbitmq@localhost//" 
    CELERY_RESULT_BACKEND = "amqp://rabbitmq:rabitmq@localhost//" </pre><p>In the <code class="literal">__init__.py</code> file, the <code class="literal">Celery</code> class from <code class="literal">Flask-Celery-Helper</code> will be initialized:</p><pre class="programlisting">from flask_celery import Celery
... 
celery = Celery()
...
def create_app(object_name):
...
    celery.init_app(app)
...</pre><p> </p><p>So, in order for our Celery process to work with the database and any other Flask extensions, it needs to work within our application context. In order to do so, Celery will need to create a new instance of our application for each process. Like most Celery apps, we need a Celery factory to create an application instance and register our Celery instance on it. In a new file, named <code class="literal">celery_runner.py</code>, in the top-level directory—the same location where <code class="literal">manage.py</code> resides—we have the following:</p><pre class="programlisting">import os
from webapp import create_app
from celery import Celery


def make_celery(app):
    celery = Celery(
        app.import_name,
broker=app.config['CELERY_BROKER_URL'],
backend=app.config['CELERY_RESULT_BACKEND']
    )
    celery.conf.update(app.config)
    TaskBase = celery.Task

class ContextTask(TaskBase):
        abstract = True

def __call__(self, *args, **kwargs):
with app.app_context():
return TaskBase.__call__(self, *args, **kwargs)

    celery.Task = ContextTask
return celery

env = os.environ.get('WEBAPP_ENV', 'dev')
flask_app = create_app('config.%sConfig' % env.capitalize())

celery = make_celery(flask_app)</pre><p>The <code class="literal">make_celery</code> function wraps every call to each Celery task in a Python <code class="literal">with</code> block. This makes sure that every call to any Flask extension will work as it is working with our app. Also, make sure not to name the Flask app instance <code class="literal">app</code>, as Celery tries to import any object named <code class="literal">app</code> or <code class="literal">celery</code> as the Celery application instance. So naming your Flask object <code class="literal">app</code> will cause Celery to try to use it as a Celery object.</p><p> </p><p>Now we can write our first task. It will be a simple task to start with; one that just returns any string passed to it. We have a new file in the blog module directory, named <code class="literal">tasks.py</code>. In this file, find the following:</p><pre class="programlisting">from .. import celery

@celery.task() 
def log(msg): 
    return msg</pre><p>Now, the final piece of the puzzle is to run the Celery process, which is called a <span class="strong"><strong>worker</strong></span>, in a new Terminal window. Again, this is the process that will be listening to our message broker for <span>commands</span><a id="id325378669" class="indexterm"></a> to start new tasks:</p><pre class="programlisting"><span class="strong"><strong>$ celery worker -A celery_runner --loglevel=info</strong></span></pre><p>The <code class="literal">loglevel</code> flag is there, so you will see the confirmation that a task was received, and its output was available, in the Terminal window.</p><p>Now, we can send commands to our Celery worker. Open a Flask shell session, as follows:</p><pre class="programlisting"><span class="strong"><strong>$ export FLASK_APP=main.py
</strong></span><span class="strong"><strong>$ flask shell</strong></span>
<span class="strong"><strong>&gt;&gt;&gt; from webapp.blog.tasks import log</strong></span><span class="strong"><strong>&gt;&gt;&gt; log("Message")</strong></span>
Message
<span class="strong"><strong>&gt;&gt;&gt; result = log.delay("Message")</strong></span></pre><p>The function can be called as if it were any other function, and doing so will execute the function in the current process. However, calling the <code class="literal">delay</code> method on the task will send a message to the worker process to execute the function with the given arguments.</p><p>In the Terminal window that is running the Celery worker, you should see something like the following:</p><pre class="programlisting"><span class="strong"><strong>Task webapp.blog.tasks.log succeeded in 0.0005873600021s: 'Message'</strong></span></pre><p>As with any asynchronous task, the <code class="literal">ready</code> method can be used to tell if the task has successfully been completed. If <code class="literal">True</code>, the <code class="literal">get</code> method can be used to retrieve the result of the tasks as follows:</p><pre class="programlisting"><span class="strong"><strong>&gt;&gt;&gt; result.ready()
</strong></span>True<span class="strong"><strong>
&gt;&gt;&gt; result.get()
</strong></span>"Message"</pre><p> </p><p> </p><p>The <code class="literal">get</code> method causes the current process to wait until the <code class="literal">ready</code> function returns <code class="literal">True</code> to retrieve the result. So, calling <code class="literal">get</code> immediately after calling the task essentially makes the task synchronous. Because of this, it's rather rare for tasks to actually return a value to the producer. The vast majority of tasks perform some operation and then exit.</p><p>When a task is run on the Celery worker, the state of the task can be accessed via the <code class="literal">state</code> attribute. This allows for a more fine-grained understanding of what the task is currently doing in the worker process. The available states are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">FAILURE</code>: The task failed, and all of the retries failed as well.</li><li style="list-style-type: disc"><code class="literal">PENDING</code>: The task has not yet been received by the worker.</li><li style="list-style-type: disc"><code class="literal">RECEIVED</code>: The task has been received by the worker, but is not yet processing.</li><li style="list-style-type: disc"><code class="literal">RETRY</code>: The task failed and is waiting to be retried.</li><li style="list-style-type: disc"><code class="literal">REVOKED</code>: The task was stopped.</li><li style="list-style-type: disc"><code class="literal">STARTED</code>: The worker has started processing the task.</li><li style="list-style-type: disc"><code class="literal">SUCCESS</code>: The task was completed successfully.</li></ul></div><p>In Celery, if a task fails, then the task can recall itself with the <code class="literal">retry</code> method, as follows:</p><pre class="programlisting">@celery.task(bind=True) 
def task(self, param): 
  try: 
    some_code 
  except Exception, e: 
    self.retry(exc=e) </pre><p>The <code class="literal">bind</code> parameter in the decorator function tells <span>Celery</span><a id="id325563662" class="indexterm"></a> to pass a reference to the task object as the first parameter in the function. Using the <code class="literal">self</code> parameter, the <code class="literal">retry</code> method can be called, which will <span>rerun</span><a id="id325564225" class="indexterm"></a> the task with the same parameters. There are several other parameters that can be passed to the function decorator to change the behavior of the task:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">max_retries</code>: This is the maximum number of times the task can be retried before it is declared as failed.</li><li style="list-style-type: disc"><code class="literal">default_retry_delay</code>: This is the time in seconds to wait before running the task again. It's a good idea to keep this at around a minute or so if you expect that the conditions that led to the task failing are transitory; for example, network errors.
</li><li style="list-style-type: disc"><code class="literal">rate_limit</code>: This specifies the total number of unique calls to this task that are allowed to run in a given interval. If the value is an integer, then it represents the total number of calls that this task that is allowed to run per second. The value can also be a string in the form of <span class="emphasis"><em>x/m</em></span>,<span class="emphasis"><em> </em></span>for <span class="emphasis"><em>x</em></span> number of tasks per minute, or <span class="emphasis"><em>x/h</em></span>, for <span class="emphasis"><em>x</em></span> number of tasks per hour. For example, passing in <span class="emphasis"><em>5/m</em></span> will only allow this task to be called five times a minute.</li><li style="list-style-type: disc"><code class="literal">time_limit</code>: If this is specified, then the task will be killed if it runs longer than the specified number of seconds.</li><li style="list-style-type: disc"><code class="literal">ignore_result</code>: If the task's return value isn't used, then don't send it back.</li></ul></div><p>It's a good idea to specify all of these for each task to avoid any chance that a task will not be run.</p></div>