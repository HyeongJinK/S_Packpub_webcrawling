<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec33"></a>An introduction to algorithms</h2></div></div><hr /></div><p>The theoretical foundation of algorithms, in the form of the Turing machine, was established several <span>decades</span><a id="id326643182" class="indexterm"></a> before digital logic circuits could actually implement such a machine. The Turing machine is essentially a mathematical model that, using a predefined set of rules, translates a set of inputs into a set of outputs. The first implementations of Turing machines were mechanical and the next generation may likely see digital logic circuits replaced by quantum circuits or something similar. Regardless of the platform, algorithms play a central predominant role.</p><p>Another aspect is the effect algorithms have on technological innovation. As an obvious example, consider the page rank search algorithm, a variation of which the Google Search engine is based on. Using this and similar algorithms allows researchers, scientists, technicians, and others to quickly search through vast amounts of information extremely quickly. This has a massive effect on the rate at which new research can be carried out, new discoveries made, and new innovative technologies developed. An algorithm is a sequential set of instructions to execute a particular task. They are very important, as we can break a complex problem into a smaller one to prepare simple steps to execute a big problem—that is the most important part of algorithms. A good algorithm is key for an efficient program to solve a specific problem. The study of algorithms is also important because it trains us to think very specifically about certain problems. It can help to increase our problem-solving abilities by isolating the components of a problem and defining relationships between these components. In summary, there are some important reasons for studying algorithms:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">They are essential for computer science and <span class="emphasis"><em>intelligent</em></span> systems</li><li style="list-style-type: disc">They are important in many other domains (computational biology, economics, ecology, communications, ecology, physics, and so on)</li><li style="list-style-type: disc">They play a role in technology innovation</li><li style="list-style-type: disc">They improve problem-solving and analytical thinking</li></ul></div><p> </p><p> </p><p>There are mainly two important aspects to solve a given problem. Firstly, we need an efficient mechanism to store, manage, and retrieve the data, which is important to solve a problem (this comes under data structures); secondly, we require an efficient algorithm which is a finite set of instructions to solve that problem. Thus, the study of data structures and algorithms is key to solving any problem using computer programs. An efficient algorithm should have the following characteristics:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">It should be as specific as possible</li><li style="list-style-type: disc">It should have each instruction properly defined</li><li style="list-style-type: disc">There should not be any ambiguous instruction</li><li style="list-style-type: disc">All the instructions of the algorithm should be executable in a finite amount of time and in a finite number of steps</li><li style="list-style-type: disc">It should have clear input and output to solve the problem</li><li style="list-style-type: disc">Each instruction of the algorithm should be important in solving the given problem</li></ul></div><p>Algorithms, in their simplest form, are just a <span>sequence</span><a id="id326377843" class="indexterm"></a> of actions—a list of instructions. It may just be a linear construct of the form do <span class="emphasis"><em>x</em></span>, then do <span class="emphasis"><em>y</em></span>, then do <span class="emphasis"><em>z</em></span>, then finish. However, to make things more useful we add clauses to the effect of do <span class="emphasis"><em>x</em></span> then do <span class="emphasis"><em>y</em></span>; in Python, these are if-else statements. Here, the future course of action is dependent on some conditions; say the state of a data structure. To this, we also add the operation, iteration, the while, and the for statements. Expanding our algorithmic literacy further, we add recursion. Recursion can often achieve the same results as iteration, however, they are fundamentally different. A recursive function calls itself, applying the same function to progressively smaller inputs. The input of any recursive step is the output of the previous recursive step.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec17"></a>Algorithm design paradigms</h3></div></div></div><p>In general, we can discern three <span>broad</span><a id="id325837792" class="indexterm"></a> approaches to algorithm design. They are:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Divide and conquer</li><li style="list-style-type: disc">Greedy algorithms</li><li style="list-style-type: disc">Dynamic programming</li></ul></div><p>As the name suggests, the divide and conquer paradigm involves breaking a problem into smaller simple sub-problems, and then solving these sub-problems, and finally, combining the results to obtain a global optimal solution. This is a very common and natural problem-solving technique, and is, arguably, the most commonly used approach to algorithm design. For example, merge sort is an algorithm to sort a list of n natural numbers increasingly.</p><p> </p><p> </p><p> </p><p> </p><p>In this algorithm, we divide the list iteratively in equal parts until each sub-list contains one element, and then we combine these sub-lists to create a new list in a sorted order. We will be discussing merge sort in more detail later in this section/chapter.</p><p>Some examples of divide and conquer <span>algorithm</span><a id="id325837829" class="indexterm"></a> paradigms are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Binary search</li><li style="list-style-type: disc">Merge sort</li><li style="list-style-type: disc">Quick sort</li><li style="list-style-type: disc">Karatsuba algorithm for fast multiplication</li><li style="list-style-type: disc">Strassen's matrix multiplication</li><li style="list-style-type: disc">Closest pair of points</li></ul></div><p>Greedy algorithms often <span>involve</span><a id="id325851483" class="indexterm"></a> optimization and combinatorial problems. In greedy algorithms, the objective is to obtain the best optimum solution from many possible solutions in each step, and we try to get the local optimum solution which may eventually lead us to obtain the overall optimum solution. Generally, greedy algorithms are used for optimization problems. Here are many popular standard problems where we can use greedy algorithms to obtain the optimum solution:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Kruskal's minimum spanning tree</li><li style="list-style-type: disc">Dijkstra's shortest path</li><li style="list-style-type: disc">Knapsack problem</li><li style="list-style-type: disc">Prim's minimal spanning tree algorithm</li><li style="list-style-type: disc">Travelling salesman problem</li></ul></div><p>Greedy algorithms often involve optimization and combinatorial problems; the classic example is to apply the greedy algorithm to the traveling salesperson problem, where a greedy approach always chooses the closest destination first. This shortest-path strategy involves finding the best solution to a local problem in the hope that this will lead to a global solution.</p><p>Another classic example is to apply the greedy algorithm   to the traveling salesperson problem; it is an NP-hard problem. In this problem, a greedy approach always chooses the closest unvisited city first from the current city; in this way, we are not sure that we get the best solution, but we surely get an optimal solution. This shortest-path strategy involves finding the best solution to a local problem in the hope that this will lead to a global solution.</p><p> </p><p> </p><p>The <span>dynamic</span><a id="id325855479" class="indexterm"></a> programming approach is useful when our sub-problems overlap. This is different from divide and conquer. Rather than breaking our problem into independent sub-problems, with dynamic programming, intermediate results are cached and can be used in subsequent operations. Like divide and conquer, it uses recursion; however, dynamic programming allows us to compare results at different stages. This can have a performance advantage over the divide and conquer for some problems because it is often quicker to retrieve a previously calculated result from memory rather than having to recalculate it. Dynamic programming also uses recursion to solve the problems. For example, the matrix chain multiplication problem can be solved using dynamic programming. The matrix chain multiplication problem determines the best effective way to multiply the matrices when a sequence of matrices is given, it finds the order of multiplication that requires the minimum number of operations.</p><p>For example, let's look at three matrices—<span class="emphasis"><em>P</em></span>, <span class="emphasis"><em>Q</em></span>, and <span class="emphasis"><em>R</em></span>. To compute the multiplication of these three matrices, we have many possible choices (because the matrix multiplication is associative), such as <span class="emphasis"><em>(PQ)R = P(QR)</em></span>. So, if the sizes of these matrices are—<span class="emphasis"><em>P</em></span> is a 20 × 30, <span class="emphasis"><em>Q</em></span> is 30 × 45, <span class="emphasis"><em>R</em></span> is 45 x 50, then, the number of multiplications for <span class="emphasis"><em>(PQ)R</em></span> and <span class="emphasis"><em>P(QR)</em></span> will be:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"> <span class="emphasis"><em>(PQ)R</em></span> = 20 x 30 x 45 + 20 x 45 x 50 = 72,000</li><li style="list-style-type: disc"> <span class="emphasis"><em>P(QR)</em></span> =  20 x 30 x 50 + 30 x 45 x 50 = 97,500</li></ul></div><p>It can be observed from this example that if we multiply using the first option, then we would need 72,000 multiplications, which is less when compared to the second option/ This is shown in the following code:</p><pre class="programlisting">def MatrixChain(mat, i, j):   
    if i == j:   
        return 0   
    minimum_computations = sys.maxsize  
    for k in range(i, j): 
        count = (MatrixChain(mat, i, k) + MatrixChain(mat, k+1, j)+ mat[i-1] * mat[k] * mat[j])   
        if count &lt; minimum_computations:  
              minimum_computations= count;    
        return minimum_computations;  

matrix_sizes = [20, 30, 45, 50];  
print("Minimum multiplications are", MatrixChain(matrix_sizes , 1, len(matrix_sizes)-1));

#prints 72000</pre><p> </p><p> </p><p> </p><p> </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip4"></a>Note</h3><p><a class="link" href="#" linkend="ch13">Chapter 13</a>, <span class="emphasis"><em>Design Techniques and Strategies</em></span>, presents a more detailed discussion on the algorithm design strategy.</p></div></div></div>