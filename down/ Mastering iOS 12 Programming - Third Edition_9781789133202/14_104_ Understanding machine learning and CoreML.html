<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch14lvl1sec99"></a>Understanding machine learning and CoreML</h2></div></div><hr /></div><p>Machine learning and CoreML go <span>hand</span><a id="id325333116" class="indexterm"></a> in hand, but they're not quite the same. Machine learning is all about teaching a machine how it can recognize, analyze, or apply certain things. The result of all this teaching is a trained model that can be used by <span>CoreML</span><a id="id325607243" class="indexterm"></a> to analyze specific inputs and produce an output based on the rules that were established during the training phase.</p><p>Before you learn about CoreML, it's good to obtain some knowledge about machine learning to make sure you're familiar with some of the terms that are used, and so you know what machine learning is.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch14lvl2sec77"></a>Understanding what machine learning is</h3></div></div></div><p>A lot of developers will hear about <span>machine</span><a id="id325609925" class="indexterm"></a> learning, deep learning, or neural networks at some point in their career. You may have already heard about these topics. If you have, you know that machine learning is a complex field that requires particular domain knowledge. However, machine learning is becoming more prominent and popular by the day, and it is used to improve many different types of applications.</p><p>For instance, machine learning can be used to predict what type of content a particular user might like to see in a music app, based on music that they already have in their library, or to automatically tag faces in photos to connect them to people in the user's contact list. It can even be used to predict costs for specific products or services based on past data. While this might sound like magic, the flow for creating machine learning experiences like these can be split roughly into two phases:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Training a model</li><li>Using inference to obtain a result from the model</li></ol></div><p>Large amounts of high-quality data must be collected to perform the first step. If you're going to train a model that should recognize cats, you will need large amounts of pictures of cats. You must also collect images that do not contain cats. Each image must then be appropriately tagged to indicate whether the image includes a cat or not.</p><p> </p><p>If your dataset only contains images of cats that face towards the camera, the chances are that your model will not be able to recognize cats from a sideways point of view. If your dataset does contain cats from many different sides, but you only collected images for a single breed or with a solid white background, your model might still have a tough time recognizing all cats. Obtaining quality training data is not easy, yet it's essential.</p><p>During the training phase of a model, it is imperative that you provide a set of inputs that are of the highest quality possible. The smallest mistake could render your entire dataset worthless. It's in part due to the process of collecting data that training a model is a tedious task. One more reason is that training a model typically takes a lot of time. Certain complex models could take a couple of hours to crunch all the data and train themselves.</p><p>A trained model comes in several types. Each type of <span>model</span><a id="id325611493" class="indexterm"></a> is suitable for a different kind of task. For instance, if you are working on a model that can classify certain email messages as spam, your <span>model</span><a id="id325611538" class="indexterm"></a> might be a so-called <span class="strong"><strong>support vector machine</strong></span>. If you're training a model that recognizes <span>cats</span><a id="id325611548" class="indexterm"></a> in pictures, you are likely training a <span class="strong"><strong>neural network</strong></span>.</p><p>Each model comes with its own pros and cons, and each model is created and used differently. Understanding all these different models, their implications, and how to train them is extremely hard, and you could likely write a book on each kind of model.</p><p>In part, this is why CoreML is so great. CoreML enables you to make use of pre-trained models in your own apps. On top of this, CoreML standardizes the interface that you use in your own code. This means that you can use complex models without even realizing it. Let's learn more about CoreML, shall we?</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch14lvl2sec78"></a>Understanding CoreML</h3></div></div></div><p>Due to the complex nature of machine learning and using trained models, Apple has built CoreML to make incorporating a trained <span>model</span><a id="id325615281" class="indexterm"></a> as simple as possible. On top of this, another goal was to ensure that whenever you implement machine learning using CoreML, your implementation is as fast and energy efficient as possible. Since Apple has been enhancing iOS with machine learning for a couple of years now, they have loads of experience of implementing complex models in apps.</p><p> </p><p>If you have ever researched machine learning, you might have come across cloud-based solutions. Typically, you send a bunch of data to such a cloud-based solution, and the result is passed back as a response to your request. CoreML is very different, since the trained model lives on the device, instead of in the cloud. This means that your user's data never has to leave the device, which is very good for your user's privacy. Also, having your trained model on the device means that no internet connection is required to use CoreML, which saves both time and precious data. And since there is no potential bottleneck regarding response latency, CoreML is capable of calculating results in real time.</p><p>In the previous section, you learned that there are several types of trained models. Each type of model is used slightly differently, so if you were to implement machine learning in your app manually, you would have to write different wrappers around each of the different models your app uses. CoreML makes sure that you can use each type of model without even being aware of this in your app; they all share the same programming interface. A CoreML model is domain agnostic.</p><p>To be domain agnostic, all trained models that you use with <span>CoreML</span><a id="id325615339" class="indexterm"></a> must be in a particular format. Since machine learning already has a vibrant community with several popular formats, Apple has made sure that the most popular models can be easily converted to Apple's own <code class="literal">.mlmodel</code> format. Let's see how to obtain <code class="literal">.mlmodel</code> files for you to use in your own apps.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch14lvl3sec33"></a>Obtaining CoreML models</h4></div></div></div><p>The are two ways to obtain a model for you to use in your apps. The simplest way is to find an existing <code class="literal">.mlmodel</code> file. You can find several ready-to-use <code class="literal">.mlmodel</code> files on Apple's <span>machine</span><a id="id325617723" class="indexterm"></a> learning website, at <a class="ulink" href="https://developer.apple.com/machine-learning/" target="_blank">https://developer.apple.com/machine-learning/</a>. This website contains several of the most popular models. At the time of writing, most of these models are focused on recognizing dominant objects in an image, and chances are that you have different needs for your app.</p><p>If you're looking for something that isn't <span>already</span><a id="id325618089" class="indexterm"></a> converted by Apple, you can try to look in several places online for a pre-converted <code class="literal">.mlmodel</code> file, or you can convert an existing model you have found online. Apple has created converters for several popular machine learning formats, such as <span class="emphasis"><em>caffe</em></span>. The conversion tools for converting an existing model to a <code class="literal">.mlmodel</code> file are written in Python, and they ship as part of Xcode. If your needs do not fit the converters that Apple provides, you can extend the <span class="strong"><strong>toolchain</strong></span>, since the conversion tools are open source. This means that everybody can add their own converters, or tweak existing converters.</p><p>Converting CoreML models using Apple's tools can usually be done with a couple of lines of Python. Writing a good conversion script does typically involve a little bit of domain knowledge in the area of machine learning, because you'll need to make sure that the converted model works just as well as the original model.</p><p>Once you have obtained a CoreML model for your app, either by converting one or finding an existing one, you're ready to add it to your project and begin using it. Let's see how to do this next.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch14lvl3sec34"></a>Using a CoreML model</h4></div></div></div><p>Applications can utilize CoreML for many different purposes. One of these purposes is text analysis. You can use a trained model to detect whether a particular piece of text has a positive or negative sentiment. To implement a feature like this, you can use a trained and converted CoreML model.</p><p>The code bundle for this chapter includes a <span>project</span><a id="id325580636" class="indexterm"></a> named <code class="literal">TextAnalyzer</code>. If you open the start version of this project, you'll find a project that has an implementation of a simple layout along with a button that is hooked up to an <code class="literal">@IBAction</code>, named <code class="literal">analyze()</code>. The project folder also contains a file called <code class="literal">SentimentPolarity.mlmodel</code>. This file is a trained CoreML model that analyzes the sentiment associated with a certain text. Drag this file into Xcode to add the CoreML model to your project.</p><p> </p><p>After adding the model to your project, you can click it in the <strong class="userinput"><code>Project Navigator</code></strong> to see more information about the model, as illustrated in the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781789133202/graphics/60c2e679-7cdc-47f3-9110-4d7d3b1c9c9c.png" /></div><p>You can see that this model is provided by <span class="emphasis"><em>Vadym Markov</em></span> under the <strong class="userinput"><code>MIT</code></strong> license. In the bottom section, you can find out which <strong class="userinput"><code>inputs</code></strong> and <strong class="userinput"><code>outputs</code></strong> you can expect this <span>model</span><a id="id325580691" class="indexterm"></a> to work with. In this case, the <strong class="userinput"><code>input</code></strong> is a dictionary of the <code class="literal">[String: Double]</code> type. This means that we should feed this model a dictionary of word counts. If you add this model to Xcode, the center section that lists the <strong class="userinput"><code>Model Class</code></strong> might notify you that the model isn't part of any targets yet. If this is the case, fix it as you have done previously, by adding this model to your app target in the <strong class="userinput"><code>Utilities</code></strong> sidebar on the right side of the window.</p><p>Now that your model is implemented, it's time to take it for a spin. First, implement a method that extracts the word count from any given string. You can implement this using the <code class="literal">NLTokenizer</code> object from the new <code class="literal">NaturalLanguage</code> framework. <code class="literal">NLTokenizer</code> is a text analysis class that is used to split a string into words, sentences, paragraphs, or even whole documents. In this example, the tokenizer is set up to detect individual words. Implement the word count method as follows:</p><pre class="programlisting">func getWordCounts(from string: String) -&gt; [String: Int] {
  let tokenizer = NLTokenizer(unit: .word)
  tokenizer.string = string
  var wordCount = [String: Int]()

  tokenizer.enumerateTokens(in: string.startIndex..&lt;string.endIndex) { range, attributes in
    let word = String(string[range])
    wordCount[word] = (wordCount[word] ?? 0) + 1

    return true
  }

  return wordCount
}</pre><p>The previous code iterates over all the words that the tokenizer has recognized, and stores it in a dictionary of the <code class="literal">[String: Double]</code> type. You might wonder why a <code class="literal">Double</code> type is used for the word count, rather than an <code class="literal">Int</code> type, since the word counts won't have to deal with decimals. This is true, but the <code class="literal">SentimentPolarity</code> model requires its input to be a dictionary of the <code class="literal">[String: Double]</code> type, so you must prepare the data accordingly.</p><p>Now that you have the code to prepare the input data for the <code class="literal">SentimentPolarity</code> model, let's see how you can use this model to analyze the user's input. Add the following implementation for the <code class="literal">analyze()</code> method:</p><pre class="programlisting">@IBAction func analyze() {
  let wordCount = getWordCounts(from: textView.text)
  let model = SentimentPolarity()

  guard let prediction = try? model.prediction(input: wordCount)
    else { return }

  let alert = UIAlertController(title: nil, message: "Your text is rated: \(prediction.classLabel)", preferredStyle: .alert)
  let okayAction = UIAlertAction(title: "Okay", style: .default, handler: nil)
  alert.addAction(okayAction)
  present(alert, animated: true, completion: nil)
}</pre><p>You might be surprised that this method is so short, but that's how simple CoreML is! First, we retrieve the <code class="literal">wordCount</code> using the method we implemented earlier. Then, an instance of the CoreML <span>model</span><a id="id325580803" class="indexterm"></a> is created. When you added the <code class="literal">SentimentPolarity</code> model to the app target, Xcode generated a class interface that abstracted away all complexities involving the model. Because the model is now a simple class, you can obtain a prediction for the sentiment of the text by calling <code class="literal">prediction(input:)</code> on the model instance.</p><p>The <code class="literal">prediction</code> method returns an object that contains the processed prediction in the <code class="literal">classLabel</code> property, as well as an overview of all available predictions and how certain the model is about each option in the <code class="literal">classProbability</code> property. You can use this property if you want to be a bit more transparent to the user about the different options that the model suggested and how certain it was about these options.</p><p>In the last section of this chapter, you will learn how you can use <span class="strong"><strong>CreateML</strong></span> to train your own natural language model to analyze texts that use domain-specific language relevant to your own app.</p><p>Using CoreML to perform text analysis was quite simple. Now let's see how you can use computer vision together with CoreML to determine the type of object that exists in a particular picture.</p></div></div></div>