<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch02lvl1sec23"></a>Keras functional APIs</h2></div></div><hr /></div><p>Keras functional APIs <span>provide</span><a id="id324602825" class="indexterm"></a> each layer as a function.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec24"></a>How to do it...</h3></div></div></div><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>To use the functional APIs, you need to import the following classes from the <code class="literal">keras</code> package:</li></ol></div><pre class="programlisting">from keras.layers.core import dense, Activation</pre><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>Let's use the preceding imported layers as part of the <code class="literal">Sequential</code> model:</li></ol></div><pre class="programlisting">from keras.models import Sequential
from keras.layers.core import dense, Activation
model = Sequential([
  dense(32, input_dim=784),
  Activation("sigmoid"),
  dense(10),
  Activation("softmax"),
])
model.compile(loss="categorical_crossentropy", optimizer="adam")</pre><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>Let's run the previous <span>functional</span><a id="id324812579" class="indexterm"></a> API-based model on MNIST:</li></ol></div><pre class="programlisting">from keras.utils import plot_model
from keras.layers import Flatten
from keras.models import Sequential
from keras.layers.core import Dense, Activation
from keras.datasets import mnist
import keras

num_classes = 10
batch_size = 32
epochs = 10
batch_size = 128
num_classes = 10
epochs = 12

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)


# input layer
model = Sequential([
  Flatten(input_shape=(28, 28)),
  Dense(32, input_dim=784),
  Activation("sigmoid"),
  Dense(10),
  Activation("softmax"),
])

# summarize layers
print(model.summary())

# plot graph
plot_model(model, to_file='shared_input_layer.png')

opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)

# Let's train the model using RMSprop
model.compile(loss='categorical_crossentropy',
optimizer=opt,
metrics=['accuracy'])


model.fit(x_train, y_train,
batch_size=batch_size,
epochs=epochs,
validation_data=(x_test, y_test),
shuffle=True)

scores = model.evaluate(x_test, y_test, verbose=1)
print('Test loss:', scores[0])
print('Test accuracy:', scores[1])</pre><p>Notice how we flatten the input before feeding it into the model using the first layer:</p><pre class="programlisting">Flatten(input_shape=(28, 28)),</pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl2sec25"></a>The output of the example</h3></div></div></div><p>The following is the output (though please <span>note</span><a id="id325345208" class="indexterm"></a> this is truncated output):</p><pre class="programlisting">50560/60000 [========================&gt;.....] - ETA: 0s - loss: 0.3895 - acc: 0.8933
53504/60000 [=========================&gt;....] - ETA: 0s - loss: 0.3894 - acc: 0.8929
57216/60000 [===========================&gt;..] - ETA: 0s - loss: 0.3889 - acc: 0.8928
60000/60000 [==============================] - 1s 17us/step - loss: 0.3886 - acc: 0.8928 - val_loss: 0.3846 - val_acc: 0.8925
32/10000 [..............................] - ETA: 0s
 2592/10000 [======&gt;.......................] - ETA: 0s
 5184/10000 [==============&gt;...............] - ETA: 0s
 8064/10000 [=======================&gt;......] - ETA: 0s
10000/10000 [==============================] - 0s 19us/step
Test loss: 0.3846480777263641
Test accuracy: 0.8925</pre></div></div>