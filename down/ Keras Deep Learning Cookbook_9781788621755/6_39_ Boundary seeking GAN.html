<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec43"></a>Boundary seeking GAN</h2></div></div><hr /></div><p><span>Following</span><a id="id324602824" class="indexterm"></a> the objective function shown here, in the original <span class="emphasis"><em>GAN paper</em></span>: </p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/90d4d995-621e-431d-8a29-62048ce12c6c.png" /></div><p>Where:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="emphasis"><em>x</em></span>: Data</li><li style="list-style-type: disc"><span class="emphasis"><em>p<sub>g</sub></em></span>: Generator's distribution over data <span class="emphasis"><em>x</em></span></li><li style="list-style-type: disc"><span class="emphasis"><em>p(z)</em></span>: A priori on input noise variable</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="emphasis"><em>G(Z,θ</em></span><sub><span class="emphasis"><em>g</em></span></sub><span class="emphasis"><em>)</em></span>: Map prior to data space</li><li style="list-style-type: disc"><span class="emphasis"><em>G</em></span>: Differentiable function represented by multi-layer perceptron with parameters <span class="emphasis"><em>θ<sub>g</sub></em></span></li><li style="list-style-type: disc"><span class="emphasis"><em>D(x,θ<sub>g</sub>)</em></span>: Discriminator-second multilayer perceptron which outputs a single scalar</li><li style="list-style-type: disc"><span class="emphasis"><em>D(x)</em></span>: The probability that <span class="emphasis"><em>x</em></span> came from the data rather than <span class="emphasis"><em>p<sub>g</sub></em></span></li></ul></div><p>The objective is to train <span class="emphasis"><em>D</em></span> to maximize the probability of assigning the correct label to both training examples and samples from <span class="emphasis"><em>G</em></span>. We simultaneously train <span class="emphasis"><em>G</em></span> to minimize <span class="emphasis"><em>Log(1-D(G(Z)));</em></span> the optimal discriminator <span class="emphasis"><em>D<sub>G</sub>(X) </em></span>is given by: </p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/f80b1ce0-505d-4d71-8d04-c8e6037b8a60.png" /></div><p>Where <sub><div class="mediaobject"><img src="/graphics/9781788621755/graphics/55b3d719-bd9d-46d7-a0e1-351e80c6e0b9.png" /></div></sub>is the real distribution, which can be found by rearranging the terms shown in the preceding example:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/51a3c868-f6a6-478e-b715-78487b02b2d4.png" /></div><p>The assumption is that if we train <span class="emphasis"><em>D(x)</em></span> more and more, it will come closer and closer to <span class="emphasis"><em>D<sub>G</sub>(X)</em></span> and our GAN training becomes better and better. For optimal generator, </p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/9760c400-f6f1-4b08-a7fb-56b1073c1d37.png" /></div><p>, the optimal generator has a value of 0.5. Notice that <span class="emphasis"><em>D(x) = 0.5</em></span><sub> </sub>is the decision boundary. We want to generate </p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/bf340a02-26f7-4c7a-be30-916551fe2829.png" /></div><p> such that it is near the decision boundary. Therefore, this method is called a boundary seeking GAN.</p><p>If we substitute <span class="emphasis"><em>D(x) = 1 - D(x) = 0.5,</em></span> the objective function becomes as shown here:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/353a4ca5-e9a3-4a39-b28b-a48c0f69b8ed.png" /></div><p>We are taking a log of <span class="emphasis"><em>D(x)</em></span>, as <span class="emphasis"><em>D(x)</em></span> is a probability distribution. In this recipe, we are going to look at how to implement a boundary seeking GAN in Keras.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec53"></a>Getting ready</h3></div></div></div><p>Create a class called <span class="strong"><strong>BGAN</strong></span>. Import the relevant <span>classes</span><a id="id325351888" class="indexterm"></a> and initialize the variables:</p><pre class="programlisting">from __future__ import print_function, division

from keras.datasets import fashion_mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
import keras.backend as K
import matplotlib.pyplot as plt
import sys
import numpy as np

class BGAN():
....</pre><p>Define the constants to be used in the program, as shown in the following listing:</p><pre class="programlisting">self.img_rows = 28
self.img_cols = 28
self.channels = 1
self.img_shape = (self.img_rows, self.img_cols, self.channels)
self.latent_dim = 100</pre><p>Note the <code class="literal">img_shape</code> is <code class="literal">(28,28,1)</code> and <code class="literal">latent_dim</code> is <code class="literal">100</code>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec54"></a>How to do it...</h3></div></div></div><p>Create a generator and discriminator, compare the loss, and iterate.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec48"></a>Generator</h4></div></div></div><p>We create a sequential <span>mode</span><a id="id325354160" class="indexterm"></a>l with the following layers:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Dense layer with an input of (<code class="literal">self.latent_dim</code>) and output of (*, 256 units )</li><li style="list-style-type: disc">Leaky ReLU layer applies this function to incoming data</li><li style="list-style-type: disc">Batch Normalization: normalizes the data</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Dense layer of 512: Layer with output of (*, 512 units)</li><li style="list-style-type: disc">Leaky ReLU layer applies this function to incoming data</li><li style="list-style-type: disc">Batch normalization</li><li style="list-style-type: disc">Dense layer of (*, 1024)</li><li style="list-style-type: disc">Leaky RELU </li><li style="list-style-type: disc">Batch normalization</li><li style="list-style-type: disc">Dense layer of size (*, 256) with activation <code class="literal">tanh</code></li><li style="list-style-type: disc">Reshape back to <code class="literal">img_shape</code></li><li style="list-style-type: disc">Add some noise to the model of type <code class="literal">shape=(self.latent_dim,)</code>:</li></ul></div><pre class="programlisting">def build_generator(self):
    model = Sequential()
    model.add(Dense(256, input_dim=self.latent_dim))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(1024))
    model.add(LeakyReLU(alpha=0.2))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Dense(np.prod(self.img_shape), activation='tanh'))
    model.add(Reshape(self.img_shape))
    model.summary()
    noise = Input(shape=(self.latent_dim,))
    img = model(noise)
return Model(noise, img)</pre><p>Next, let's look at the discriminator, which will check how close our images are to the real images.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec49"></a>Discriminator</h4></div></div></div><p>A discriminator is also a sequential model going in the <span>opposite</span><a id="id325563908" class="indexterm"></a> direction:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">The first layer is to flatten <code class="literal">input_shape</code> of 28,28,1</li><li style="list-style-type: disc">Add a dense layer with an output (*, 512)</li><li style="list-style-type: disc">Add an activation function of leaky ReLU</li><li style="list-style-type: disc">Add another dense layer which outputs (*, 256)</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Add another activation function of leaky ReLU</li><li style="list-style-type: disc">Add a final output of (*, 1) with an activation of <code class="literal">sigmoid</code>:</li></ul></div><pre class="programlisting">def build_discriminator(self):
    model = Sequential()
    model.add(Flatten(input_shape=self.img_shape))
    model.add(Dense(512))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(256))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dense(1, activation='sigmoid'))
    model.summary()
    img = Input(shape=self.img_shape)
    validity = model(img)
return Model(img, validity)</pre><p>In the next section, we look at how to initialize the BGAN class.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec50"></a>Initializing the BGAN class</h4></div></div></div><p>We created a custom class GAN, which is <span>initialized</span><a id="id325563956" class="indexterm"></a> with a generator and a discriminator. The steps followed are listed in the following points:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Initialize the variables <code class="literal">img_rows</code>, <code class="literal">img_cols</code>, <code class="literal">channels</code>, <code class="literal">img_shape</code>, and <code class="literal">latent_dim</code></li><li>Initialize the <code class="literal">optimizer</code>; we are using the Adam optimizer in this case</li><li>Instantiate the discriminator:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Use <code class="literal">build_discriminator()</code></li><li style="list-style-type: disc">Compile the discriminator with the loss function as <code class="literal">binary_crossentropy</code>, the optimizer as Adam, and the metrics as accuracy</li></ul></div></li><li>Generator:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Instantiate using <code class="literal">build_generator()</code></li><li style="list-style-type: disc">Get the generated image with noise as the input</li></ul></div></li><li>Discriminator checks the validity of the images</li><li>Combined model: Used to fool the discriminator with the generator:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">z</code> with input shape <code class="literal">(*, self.latent_dim)</code> is the input to the generator</li><li style="list-style-type: disc">Generator's output is the input to the discriminator</li></ul></div></li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="7" type="1"><li>Compile the loss of the combined model. This is where it gets interesting; notice that we are using boundary seeking loss:</li></ol></div><pre class="programlisting">class BGAN():

def __init__(self):
self.img_rows = 28
self.img_cols = 28
self.channels = 1
self.img_shape = (self.img_rows, self.img_cols, self.channels)
self.latent_dim = 100

optimizer = Adam(0.0002, 0.5)

# Build and compile the discriminator
self.discriminator = self.build_discriminator()
self.discriminator.compile(loss='binary_crossentropy',
optimizer=optimizer,
metrics=['accuracy'])

# Build the generator
self.generator = self.build_generator()

# The generator takes noise as input and generated imgs
z = Input(shape=(100,))
        img = self.generator(z)

# For the combined model we will only train the generator
self.discriminator.trainable = False

# The valid takes generated images as input and determines validity
valid = self.discriminator(img)

# The combined model (stacked generator and discriminator)
        # Trains the generator to fool the discriminator
self.combined = Model(z, valid)
self.combined.compile(loss=self.boundary_loss, optimizer=optimizer)</pre><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl4sec0"></a>Boundary seeking loss</h5></div></div></div><p>Boundary seeking loss, as we explained in the section at the start of this recipe, is implemented with the following equation:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/353a4ca5-e9a3-4a39-b28b-a48c0f69b8ed.png" /></div><p>Where <span class="emphasis"><em>D(x)</em></span> is the probability that <span class="emphasis"><em>x</em></span> came from data rather than <span class="emphasis"><em>p<sub>g.</sub></em></span></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note19"></a>Note</h3><p>Boundary seeking loss: See the following reference: <a class="ulink" href="https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/" target="_blank">https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/</a>.</p></div><p>This is the only major change compared to the previous sample. It is implemented in our class with the following function:</p><pre class="programlisting">import keras.backend as K

def boundary_loss(self, y_true, y_pred):
return 0.5 * K.mean((K.log(y_pred) - K.log(1 - y_pred))**2)</pre><p>Next, we will look at how to train this network with the training dataset.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec51"></a>Train the BGAN</h4></div></div></div><p>Let's look at how the <span>model</span><a id="id325974908" class="indexterm"></a> is trained:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>First, load the dataset</li><li>Rescale the data</li><li>Generate valid and fake ground truths</li><li>For each iteration of an epoch, do the following:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Select a random batch of images</li><li style="list-style-type: disc">Generate images</li><li style="list-style-type: disc">Calculate loss for real and fake images
</li><li style="list-style-type: disc">Sample and plot the images:</li></ul></div></li></ol></div><pre class="programlisting">def train(self, epochs, batch_size=128, sample_interval=50):

# Load the dataset
(X_train, _), (_, _) = fashion_mnist.load_data()

# Rescale -1 to 1
X_train = X_train / 127.5 - 1.
X_train = np.expand_dims(X_train, axis=3)

# Adversarial ground truths
valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))

for epoch in range(epochs):

# ---------------------
        #  Train Discriminator
        # ---------------------

        # Select a random batch of images
idx = np.random.randint(0, X_train.shape[0], batch_size)
        imgs = X_train[idx]

        noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

# Generate a batch of new images
gen_imgs = self.generator.predict(noise)

# Train the discriminator
d_loss_real = self.discriminator.train_on_batch(imgs, valid)
        d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)


# ---------------------
        #  Train Generator
        # ---------------------

g_loss = self.combined.train_on_batch(noise, valid)

# Plot the progress
print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))

# If at save interval =&gt; save generated image samples
if epoch % sample_interval == 0:
self.sample_images(epoch)</pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec52"></a>Output the plots</h4></div></div></div><p>The sample plots are <span>shown</span><a id="id325974954" class="indexterm"></a> for various iterations.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl4sec1"></a>Iteration 0</h5></div></div></div><p>This is the sample image <span>generated</span><a id="id325974969" class="indexterm"></a> by the first iteration:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/242f5604-b632-4547-801b-412ba564b987.png" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl4sec2"></a>Iteration 10000</h5></div></div></div><p>This shows the image <span>generated</span><a id="id326090230" class="indexterm"></a> for iteration 10000. Notice how the objects are clearer than with a simple GAN:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/13613ea5-cd9b-49e5-baed-fb2fa2900143.png" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl4sec3"></a>Metrics of the BGAN model</h5></div></div></div><p>We <span>calculated</span><a id="id326090256" class="indexterm"></a> the mean <code class="literal">D loss</code>, <code class="literal">D accuracy</code>, and <code class="literal">G loss</code>. (Here <span class="strong"><strong>discriminator</strong></span> (<span class="strong"><strong>D</strong></span>) and <span class="strong"><strong>generator</strong></span> (<span class="strong"><strong>G</strong></span>)):</p><pre class="programlisting">mean d loss:0.5253478690446334
mean g loss:0.5571205118226668
mean d accuracy:72.77859375</pre><p>As can be seen, <code class="literal">d accuracy</code> is much higher than that of a simple GAN.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h5 class="title"><a id="ch06lvl4sec4"></a>Plotting the metrics </h5></div></div></div><p>Let's also plot the <span>metrics</span><a id="id326142327" class="indexterm"></a> we got the average values for earlier:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/1890a532-46c6-4a34-9105-d97b5e486281.png" /></div><p>Generator loss starts at a very high value and settles down over a period of time. </p></div></div></div></div>