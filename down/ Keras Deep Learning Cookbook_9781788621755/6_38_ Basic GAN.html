<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec42"></a>Basic GAN</h2></div></div><hr /></div><p>In this recipe, we look at the most basic <span>GAN</span><a id="id324812542" class="indexterm"></a> network for the Fashion-MNIST dataset.</p><p>Fashion-MNIST is a dataset of Zalando article images consisting of a training set of 60,000 examples; it also contains a test set of 10,000 examples. Each example is a 28 x 28 grayscale image, associated with a label from 10 classes.</p><p>Here are some example images from Fashion-MNIST:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/f9b9ed47-7f1d-4d91-8f44-99fe75d6b6a1.jpg" /></div><p>Fashion MNIST is directly available in Keras.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec51"></a>Getting ready</h3></div></div></div><p>Create a class called <span class="strong"><strong>GAN</strong></span>. Import the relevant classes <span>and</span><a id="id324812583" class="indexterm"></a> initialize the variables:</p><pre class="programlisting">from __future__ import print_function, division
from keras.datasets import fashion_mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout
from keras.layers import BatchNormalization, Activation, ZeroPadding2D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D
from keras.models import Sequential, Model
from keras.optimizers import Adam
import matplotlib.pyplot as plt
import sys
import numpy as np

GAN class():
....

</pre><p>Define the constants to be used in the <code class="literal">_init_()</code> method of the <span>program:</span></p><pre class="programlisting">self.img_rows = 28
 self.img_cols = 28
 self.channels = 1
 self.img_shape = (self.img_rows, self.img_cols, self.channels)
 self.latent_dim = 100</pre><p>Note the <code class="literal">img_shape</code> is <code class="literal">(28,28,1)</code> and <code class="literal">latent_dim</code> is <code class="literal">100</code>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec52"></a>How to do it...</h3></div></div></div><p>The GAN network for the Fashion-MNIST dataset is explained in the following sections:</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec42"></a>Building a generator </h4></div></div></div><p>We create a sequential model with the <span>following</span><a id="id325345111" class="indexterm"></a> layers:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Dense layer with an input of (<code class="literal">self.latent_dim</code>) and output of (*, 256 units)</li><li style="list-style-type: disc">The leaky ReLU layer applies this function to incoming data</li><li style="list-style-type: disc">Batch normalization: normalizes the data</li><li style="list-style-type: disc">Dense layer of 512: layer with output of (*, 512 units)</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Batch normalization</li><li style="list-style-type: disc">Dense layer of (*, 1024)</li><li style="list-style-type: disc">Leaky RELU </li><li style="list-style-type: disc">Batch normalization</li><li style="list-style-type: disc">Dense layer of size (*, 256) with activation <code class="literal">tanh</code></li><li style="list-style-type: disc">Reshape back to <code class="literal">img_shape</code></li><li style="list-style-type: disc">Add some noise to the model of type <code class="literal">shape=(self.latent_dim,)</code>:</li></ul></div><pre class="programlisting">def build_generator(self):
model = Sequential()
model.add(Dense(256, input_dim=self.latent_dim))
model.add(LeakyReLU(alpha=0.2))
model.add(BatchNormalization(momentum=0.8))
model.add(Dense(512))
model.add(LeakyReLU(alpha=0.2))
model.add(BatchNormalization(momentum=0.8))
model.add(Dense(1024))
model.add(LeakyReLU(alpha=0.2))
model.add(BatchNormalization(momentum=0.8))
model.add(Dense(np.prod(self.img_shape), activation='tanh'))
model.add(Reshape(self.img_shape))
model.summary() 
noise = Input(shape=(self.latent_dim,))
img = model(noise)
return Model(noise, img)</pre><p>Let's look at how the noise is transformed into an image in the generator:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/c7956c47-118d-41fc-b14f-7e587466a365.png" /></div><p>A model summary is listed in the following code snippet:</p><pre class="programlisting">_________________________________________________________________
Layer (type) Output Shape Param # 
=================================================================
dense_4 (Dense) (None, 256) 25856 
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU) (None, 256) 0 
_________________________________________________________________
batch_normalization_1 (Batch (None, 256) 1024 
_________________________________________________________________
dense_5 (Dense) (None, 512) 131584 
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU) (None, 512) 0 
_________________________________________________________________
batch_normalization_2 (Batch (None, 512) 2048 
_________________________________________________________________
dense_6 (Dense) (None, 1024) 525312 
_________________________________________________________________
leaky_re_lu_5 (LeakyReLU) (None, 1024) 0 
_________________________________________________________________
batch_normalization_3 (Batch (None, 1024) 4096 
_________________________________________________________________
dense_7 (Dense) (None, 784) 803600 
_________________________________________________________________
reshape_1 (Reshape) (None, 28, 28, 1) 0 
=================================================================
Total params: 1,493,520
Trainable params: 1,489,936
Non-trainable params: 3,584</pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec43"></a>Building a discriminator</h4></div></div></div><p>A discriminator can also be made into a <span>sequential</span><a id="id325674061" class="indexterm"></a> model by going in the opposite direction:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">The first layer is to flatten the <code class="literal">input_shape</code> of 28,28,1</li><li style="list-style-type: disc">Add a dense layer with an output (*, 512)</li><li style="list-style-type: disc">Add an activation function of Leaky ReLU</li><li style="list-style-type: disc">Add another dense layer, which outputs (*, 256)</li><li style="list-style-type: disc">Add another activation function of leaky ReLU</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Add a final output of (*, 1):</li></ul></div><pre class="programlisting">def build_discriminator(self):
  model = Sequential()
  model.add(Flatten(input_shape=self.img_shape))
  model.add(Dense(512))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(256))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dense(1, activation='sigmoid'))
  model.summary()
  img = Input(shape=self.img_shape)
  validity = model(img)
  return Model(img, validity)</pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec44"></a>Initialize the GAN instance</h4></div></div></div><p>We created a custom GAN class, which is <span>initialized</span><a id="id325791421" class="indexterm"></a> with a generator and a discriminator. The steps followed are listed in the following points:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Initialize the variables <code class="literal">img_rows</code>, <code class="literal">img_cols</code>, <code class="literal">channels</code>, <code class="literal">img_shape</code>, and <code class="literal">latent_dim</code>.</li><li>Initialize the <code class="literal">optimizer</code>; we are using the Adam optimizer in this case.</li><li>Instantiate the discriminator:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Use <code class="literal">build_discriminator()</code></li><li style="list-style-type: disc">Compile the discriminator with the <code class="literal">loss</code> function as <code class="literal">binary_crossentropy</code>, the optimizer as Adam, and the metrics as accuracy</li></ul></div></li><li>Generator:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Instantiate using <code class="literal">build_generator()</code></li><li style="list-style-type: disc">Get the generated image with noise as input</li></ul></div></li><li>Discriminator checks the validity of the images</li><li>Combined model: used to fool the discriminator with the generator:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">z</code> with the input shape <code class="literal">(*, self.latent_dim)</code> is the input to the generator</li><li style="list-style-type: disc">The generator's output is the input to the discriminator</li></ul></div></li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="7" type="1"><li>Compile the <code class="literal">loss</code> of the combined model:</li></ol></div><pre class="programlisting">def __init__(self):
    self.img_rows = 28
    self.img_cols = 28
    self.channels = 1
    self.img_shape = (self.img_rows, self.img_cols, self.channels)
    self.latent_dim = 100
    optimizer = Adam(0.0002, 0.5)

    # Build and compile the discriminator
    self.discriminator = self.build_discriminator()
    self.discriminator.compile(loss='binary_crossentropy',
       optimizer=optimizer,
       metrics=['accuracy'])
    # Build the generator
    self.generator = self.build_generator()

    # The generator takes noise as input and generates imgs
    z = Input(shape=(self.latent_dim,))
    img = self.generator(z)

    # For the combined model we will only train the generator
    self.discriminator.trainable = False
    # The discriminator takes generated images as input and determines validity
    validity = self.discriminator(img)
    # The combined model (stacked generator and discriminator)
    # Trains the generator to fool the discriminator
    self.combined = Model(z, validity)
    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)</pre><p>In the next section, we look at how to tie everything together and train the GAN iteratively, compile the losses, and store the generated images.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec45"></a>Training the GAN </h4></div></div></div><p>Let's look at how the <span>model</span><a id="id325931171" class="indexterm"></a> is trained:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>First, load the dataset</li><li>Rescale the data</li><li>Generate valid and fake ground truths</li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>For each iteration of an epoch, do the following:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Select a random batch of images</li><li style="list-style-type: disc">Generate images</li><li style="list-style-type: disc">Calculate the loss for real and fake images</li><li style="list-style-type: disc">Sample and plot the images:</li></ul></div></li></ol></div><pre class="programlisting">def train(self, epochs, batch_size=128, sample_interval=50):

# Load the dataset
(X_train, _), (_, _) = fashion_mnist.load_data()

# Rescale -1 to 1
X_train = X_train / 127.5 - 1.
X_train = np.expand_dims(X_train, axis=3)

# Adversarial ground truths
valid = np.ones((batch_size, 1))
    fake = np.zeros((batch_size, 1))

for epoch in range(epochs):

# ---------------------
        #  Train Discriminator
        # ---------------------

        # Select a random batch of images
idx = np.random.randint(0, X_train.shape[0], batch_size)
        imgs = X_train[idx]

        noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

# Generate a batch of new images
gen_imgs = self.generator.predict(noise)

# Train the discriminator
d_loss_real = self.discriminator.train_on_batch(imgs, valid)
        d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

# ---------------------
        #  Train Generator
        # ---------------------

noise = np.random.normal(0, 1, (batch_size, self.latent_dim))

# Train the generator (to have the discriminator label samples as valid)
g_loss = self.combined.train_on_batch(noise, valid)

# Plot the progress
print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))

# If at save interval =&gt; save generated image samples
<span>if epoch % sample_interval == 0:
self.sample_images(epoch)</span></pre></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec46"></a>Output plots</h4></div></div></div><p>Let's start with the plot after the <span>first</span><a id="id325939658" class="indexterm"></a> iteration:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/b3b768f5-98a7-4265-84ad-a834b6e12ad8.png" /></div><p>These are images after 9,000 iterations:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/e8e3da6e-3e88-4091-b39a-95aaed33392f.png" /></div><p>These are images after 29,800 iterations:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/d1d1f809-7680-4109-9c3b-d4289af1240c.png" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch06lvl3sec47"></a>Average metrics of the GAN</h4></div></div></div><p>After running the model for 30,000 iterations, the <span>following</span><a id="id325974936" class="indexterm"></a> metrics can be seen:</p><pre class="programlisting">mean d loss:0.6404680597275333
 mean g loss:0.9513815407413333
 mean d accuracy:62.71046875</pre><p>Mean discriminator loss is about 0.64 and generator loss is 0.95. Discriminator accuracy is about 62 percent. We also plotted the metrics as a function of epochs:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/5721a18d-d5ef-4251-8ccb-d91874008f27.png" /></div><p><span>Next,</span>let's look at a more advanced GAN called a<span class="strong"><strong>boundary seeking GAN</strong></span>.</p></div></div></div>