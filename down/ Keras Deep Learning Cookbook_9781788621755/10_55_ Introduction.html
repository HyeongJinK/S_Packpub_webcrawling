<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec55"></a>Introduction</h2></div></div><hr /></div><p>Reinforcement learning is a subset of machine learning, where AI agents learn from the environment by interacting with it and improving their performance. This branch of AI learns by trial and error instead of human supervision. The following diagram illustrates how an AI agent acts on the environment and receives feedback after each action. Feedback is made up of two parts: reward and the next state of the environment. Rewards are defined by a human:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/343c3816-4265-4bed-9835-e9f7d0c14767.png" /></div><p>Google's DeepMind published a paper in 2013 about <span class="emphasis"><em>Playing Atari with Deep Reinforcement Learning</em></span>. In this paper, a new algorithm called <span class="strong"><strong>Deep Q Network</strong></span> (<span class="strong"><strong>DQN</strong></span>). It explains how an AI agent can learn to play games by just observing the screen <span>without</span><a id="id324812573" class="indexterm"></a> any prior <span>information</span><a id="id324812580" class="indexterm"></a> about the game. The result of the experiment turned out to be pretty impressive in terms of accuracy. It opened the era of what is called <span class="strong"><strong>deep reinforcement learning</strong></span>, a mix of deep learning and reinforcement learning.</p><p>The Q-Learning algorithm <span>has</span><a id="id324812593" class="indexterm"></a> a function called <span class="strong"><strong>Q function</strong></span>. It is used to approximate the reward based on a state. We call it <span class="emphasis"><em>Q(s,a)</em></span>, where <span class="emphasis"><em>Q</em></span> is a function that calculates the expected future value from state <span class="emphasis"><em>s</em></span> and action <span class="emphasis"><em>a</em></span>. In the DQN algorithm, we will use a neural network to approximate the reward based on the state. In the next section, we will discuss how this works in detail.</p></div>