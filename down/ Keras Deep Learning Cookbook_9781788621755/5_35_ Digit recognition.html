<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec40"></a>Digit recognition</h2></div></div><hr /></div><p>The digit recognition MNIST dataset was developed by <span>Yann</span><a id="id324812542" class="indexterm"></a> LeCun, Corinna Cortes, and Christopher Burges for assessing machine learning models on the handwritten digit problem. Digit images were taken from a mixture of scanned documents, normalized in size, and centered. Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel value is an integer between 0 and 255, inclusive. We develop a digit recognition pipeline. We have 10 digits (0 to 9), or 10 classes, to predict.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec48"></a>Getting ready</h3></div></div></div><p>In this recipe, we develop a modeling pipeline that tries to recognize a digit (0-9) based on images with greater accuracy. The modeling pipelines use CNN models written using the Keras functional API for image classification. </p><p>The Keras library provides a simple method for loading the MNIST data. The dataset is downloaded automatically into the user's home directory as the <code class="literal">mnist.pkl.gz</code> (15 MB) file:</p><pre class="programlisting"><span>from </span><span>keras</span><span>.</span><span>datasets </span><span>import </span><span>mnist</span>
# get dataset
(XTrain, yTrain), (XTest, yTest) = mnist.load_data()</pre><p>We can see that downloading and loading the MNIST dataset is as easy as calling the <code class="literal">mnist.load_data()</code> function:</p><pre class="programlisting"># plot 4 images as gray scale
plt.subplot(221)
plt.imshow(XTrain[1], cmap=plt.get_cmap('gray'))
plt.subplot(222)
plt.imshow(XTrain[2], cmap=plt.get_cmap('gray'))
plt.subplot(223)
plt.imshow(XTrain[3], cmap=plt.get_cmap('gray'))
plt.subplot(224)
plt.imshow(XTrain[4], cmap=plt.get_cmap('gray'))
# show the plot
plt.show()</pre><p>Running the preceding code shows us the following digits.</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/2fe658a8-d82a-4400-96dd-71e715653777.png" /></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec49"></a>How to do it…</h3></div></div></div><p>Let's create a simple CNN for the MNIST dataset that explains how to <span>use</span><a id="id325338089" class="indexterm"></a> all of the aspects of a CNN implementation, including the convolutional layers, pooling layers, and dropout layers. CNNs reduce the dimensions of the layers as we go deeper and increase the number of feature maps to detect more features and decrease the computational cost:</p><div class="mediaobject"><img src="/graphics/9781788621755/graphics/0c1d4ab7-a751-4d58-b08e-2715cac42aee.png" /></div><p>Let's import the required APIs:</p><pre class="programlisting">import numpy
from keras import backend as K
from keras.utils import np_utils
from keras.layers import Dense, Flatten, Dropout
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.models import Sequential
import matplotlib.pyplot as plt
from keras.datasets import mnist
from keras.layers.core import Activation</pre><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch05lvl3sec41"></a>Modeling</h4></div></div></div><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Firstly, let's initialize the random number generator to a <span>constant</span><a id="id325345125" class="indexterm"></a> seed value for reproducibility of results:</li></ol></div><pre class="programlisting">numpy.random.seed(0)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>Keras sequential layers are stacked so that every layer transfers its output to the next layer without defining additional data; let's import <code class="literal">Sequential</code> from the models:</li></ol></div><pre class="programlisting"># create sequential model
model = Sequential()</pre><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>To improve the efficiency and the convergence of the algorithm, we normalize the data based on the fact that the maximum pixel value is 255, so we divide all the pixels by 255 to obtain results between 0 and 1:</li></ol></div><pre class="programlisting"># normalize the dataset
XTrain = XTrain / 255
XTest = XTest / 255
</pre><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>Exploring the data is an important aspect for choosing the right algorithm and getting the accuracy metric we need to use. If the data is balanced with class distribution we can easily use accuracy, but if the data is skewed, then we won't be able to use accuracy, as its results will be misleading and we should use another score mechanism:</li></ol></div><pre class="programlisting"># data exploration
print("Number of training examples = %i" % XTrain.shape[0])
print("Number of classes = %i" % len(numpy.unique(yTrain)))
print("Dimension of images = {:d} x {:d}  ".format(XTrain[1].shape[0], XTrain[1].shape[1]))
unique, count = numpy.unique(yTrain, return_counts=True)
print("The number of occurrences of each class in the dataset = %s " % dict(zip(unique, count)), "\n")</pre><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>This is the output:</li></ol></div><pre class="programlisting">Number of training examples = 60000
Number of classes = 10
Dimension of images = 28 x 28  
The number of occurrences of each class in the dataset = {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}  </pre><p>Here, we can see that the dataset consists of 60,000 training samples, where each is an image with dimensions of 28 x 28. Since class distribution is balanced, we will use accuracy as the metric.</p><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>We reshape the data samples or images, in this case, so that they are suitable for training using a CNN API. In the <code class="literal">keras</code> library, the layers use pixel values with the dimensions as <span class="emphasis"><em>(pixels) (width) (height)</em></span>. In the case of MNIST, where the pixel values are grayscale, the pixel dimension is set to 1.</li><li>We should also make the output in the form of one-hot encoding, which means that we will have 10 classes from 0 to 9, one class for each number:</li></ol></div><pre class="programlisting">XTrain = XTrain.reshape(XTrain.shape[0], 28, 28, 1).astype('float32')
XTest = XTest.reshape(XTest.shape[0], 28, 28, 1).astype('float32')
yTrain = np_utils.to_categorical(yTrain)
yTest = np_utils.to_categorical(yTest)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="8" type="1"><li>Let's now implement the first layer of the CNN with a simplistic architecture. For the sequential model, we will stack the layers and specify the images' input dimensions in the first layer, where the first layer will be a convolutional layer <code class="literal">Conv2D()</code>, specifying the number of feature maps, the input shape and the activation function, which is <code class="literal">relu</code>, in this case. We later add the max pooling layer with a kernel of dimensions 2 x 2:</li></ol></div><pre class="programlisting"># modeling
model.add(Conv2D(40, kernel_size=5, padding="same", input_shape=(28, 28, 1), activation='relu'))
model.add(Conv2D(50, kernel_size=5, padding="valid", activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Dropout(0.2))</pre><div class="orderedlist"><ol class="orderedlist arabic" start="9" type="1"><li>We then add a flatten layer that receives the output of the CNN and flattens it, passing it then as an input to the dense layers, which further more pass it to the output layer. We will use <code class="literal">softmax</code> with the output layer to output the expected probability vector for multiclass classification:</li></ol></div><pre class="programlisting">model.add(Flatten())
model.add(Dense(100))
model.add(Activation("relu"))
model.add(Dropout(0.2))
model.add(Dense(10))
model.add(Activation("softmax"))</pre><div class="orderedlist"><ol class="orderedlist arabic" start="10" type="1"><li>We finally compile the model and train it using the <code class="literal">fit()</code> method, which fits the training data and classes, the number of epochs, and <code class="literal">batch_size</code>, which is the number of images per training cycle. As the last step, we evaluate the model to ensure that it doesn't overfit the training data. Evaluating the model is done by using the weights that resulted from the training step to predict the value of the test dataset, which the model hasn't seen before, to determine how well the model will perform on the unseen dataset. We use <code class="literal">categorical_crossentropy</code> as the cost function for that model, but what do we mean by the cost function? You can find it in the following snippet:</li></ol></div><pre class="programlisting">model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(XTrain, yTrain, epochs=32, batch_size=200, validation_split=0.2)
scores = model.evaluate(XTest, yTest, verbose=10)
print(scores)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="11" type="1"><li>Following is the output that was obtained by training 48,000 samples and was validated on 12,000 samples:</li></ol></div><pre class="programlisting">200/48000 [..............................] - ETA: 33:31 - loss: 2.3074 - acc: 0.0650
400/48000 [..............................] - ETA: 32:15 - loss: 2.2640 - acc: 0.1350
600/48000 [..............................] - ETA: 32:12 - loss: 2.2285 - acc: 0.1600
800/48000 [..............................] - ETA: 32:40 - loss: 2.1714 - acc: 0.1975
1000/48000 [..............................] - ETA: 33:09 - loss: 2.0927 - acc: 0.2650
48000/48000 [==============================] - 2382s 50ms/step - <span class="strong"><strong>loss</strong></span>: 0.2471 - <span class="strong"><strong>acc</strong></span>: 0.9238
...
...
47600/48000 [============================] - ETA: 17s - loss: 0.0067 - acc: 0.9978
47800/48000 [============================] - ETA: 8s - loss: 0.0068 - acc: 0.9977
48000/48000 [==============================] - 2237s 47ms/step - <span class="strong"><strong>loss</strong></span>: 0.0069 - <span class="strong"><strong>acc</strong></span>: 0.9977</pre><p>We can run this network on a CPU. You should be able to see the <span>preceding</span><a id="id325350577" class="indexterm"></a> output. With a simple architecture, it achieves an accuracy of <code class="literal">99~</code>.</p></div></div></div>