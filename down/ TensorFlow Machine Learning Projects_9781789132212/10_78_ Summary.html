<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec77"></a>Summary</h2></div></div><hr /></div><p>In this chapter, we looked at the very popular neural network architecture CapsNet, by Geoff Hinton (presumably the father of deep learning).</p><p>We started off by understanding the limitations of CNNs in their current form. They use max pooling as a crutch to achieve invariance in activities. Max pooling has a tendency to lose information, and it can't model the relationships between different objects in the image. We then touched upon how the human brain detects objects and are viewpoint invariant. We drew an analogy to computer graphics and understood how we can probably incorporate pose information in neural networks.</p><p>Subsequently, we learned about the basic building blocks of capsule networks, that is, capsules. We understood how they differ from the traditional neuron in that they take a vector as the input and produce a vector output. We also learned about a special kind of non-linearity in capsules, namely the <code class="literal">squash</code><span class="strong"><strong> </strong></span>function. </p><p>In the next section, we learned about the novel <span class="strong"><strong>dynamic routing algorithm</strong></span>, which helps route the output from lower layer capsules to higher layer capsules. The coefficients </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/1d262237-6321-4959-a434-fab45cadf1ea.png" /></div><p> are learned through several iterations of the routing algorithm. The crux of the algorithm was the step in which we update the coefficients </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/8e77a9f4-7eb5-4481-87f6-cbecc88a5551.png" /></div><p>  by using the dot product of the predicted vector </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/b69f3b1c-eff5-4d7d-83ab-d4e92be9db9a.png" /></div><p> and the output vector of the higher-layer capsule </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/c7c9e753-0458-42eb-9793-9d80d74aeb55.png" /></div><p>. </p><p>Furthermore, we implemented CapsNet for the Fashion MNIST dataset. We used a convolutional layer, followed by a PrimaryCaps layer and a DigitCaps layer. We learned about the encoder architecture and how we can get a vector representation of the images. This was followed by an understanding of the decoder architecture to reconstruct the image from the learned representations. The loss function in this architecture was a combination of margin loss (like in SVMs) and weighted-down reconstruction loss. The reconstruction loss was weighted down so that the model could focus more on margin loss during training. </p><p>We then trained the model on 10 epochs with a batch size of 128 and achieved over 99% accuracy on the validation and test sets. We reconstructed some sample images to visualize the output and found the reconstruction to be fairly accurate. </p><p>In summary, throughout this chapter, we were able to understand and implement capsule networks from scratch using TensorFlow and trained them on the Fashion MNIST dataset.</p><p>Now that you have built the basic capsule network, you can try to extend this model by incorporating multiple capsule layers and see how it performs, use on other image datasets and see whether this algorithm is scalable, run it without reconstruction loss, and see whether you can still reconstruct the input image. By doing this, you will be able to develop a good intuition toward this algorithm.</p><p>In the next chapter, we will <span>look at the face-detection project using TensorFlow. </span></p></div>