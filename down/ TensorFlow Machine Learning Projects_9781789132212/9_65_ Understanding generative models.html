<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch09lvl1sec65"></a>Understanding generative models</h2></div></div><hr /></div><p>An unsupervised learning <span>model</span><a id="id326461089" class="indexterm"></a> that learns the underlying data distribution of the training set and generates new data that may or may not have variations is commonly known as a <span class="strong"><strong>generative model</strong></span>. Knowing the true underlying distribution might not always be a possibility, hence the neural network trains on a function that tries to be as close a match as possible to the true distribution.</p><p>The most common methods used to train generative models are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Variational autoencoders: </strong></span>A high dimensional input image is encoded by an auto-encoder to <span>create</span><a id="id325617693" class="indexterm"></a> a lower dimensional representation. During this process, it is of the utmost importance to preserve the underlying data distribution. This encoder can only be used to map to the input image using a decoder and cannot introduce any variability to generate similar images. The VAE introduces variability by generating constrained latent vectors that still follow the underlying distribution. Though VAEs help in creating probabilistic graphical models, the generated images tend to be slightly blurry.</li><li style="list-style-type: disc"><span class="strong"><strong>PixelRNN/PixelCNN: </strong></span>These auto-regressive models are used to train networks that <span>model</span><a id="id325748226" class="indexterm"></a> the conditional distribution of a successive individual pixel, given previous pixels starting from the top left. RNNs move horizontally and vertically over any image. The training for PixelRNNs is a stable and simple process with better log likelihoods than other models, but they are time consuming and relatively inefficient.</li><li style="list-style-type: disc"><span class="strong"><strong><span>Generative adversarial networks</span>: </strong></span>Generative adversarial networks were first published in the 2014 paper by <span class="emphasis"><em>Goodfellow et al.</em></span> (<a class="ulink" href="https://arxiv.org/abs/1406.2661" target="_blank">https://arxiv.org/abs/1406.2661</a>). These can be thought of as a competition framework <span>with</span><a id="id325940636" class="indexterm"></a> two adversaries called the generator and the discriminator. These are nothing but two differentiable functions in the form of neural networks. The generator takes a randomly generated input known as a latent sample and produces an image. The overall objective of the <span>generator</span> is to generate an image that is as close as possible to the real input image (such as MNIST digits) and give it as an input to the discriminator.</li></ul></div><p>The discriminator is essentially a classifier that's trained to distinguish between real images (original MNIST digits) and fake images (output of the generator). Ideally, after being trained, the generator should adapt its parameters and capture the underlying training data distribution and fool the discriminator about its input being a real image.</p><p>Let's consider an analogy that is inspired by the real world. Imagine that GANs work like the relationship between a forger making counterfeit currency and the police identifying and discarding that forged currency. The aim of the forger is to try and pass off the fake currency as <span>real</span><a id="id325940654" class="indexterm"></a> currency in the market. This is analogous to what a generator tries to do. The police try and inspect every currency note it can, accepting the original notes and scrapping the fake ones. The police know of the details of the original currency and compare it to the properties of the currency in question in order to make a decision regarding its authenticity. If there is a match, the currency is retained; otherwise, it is scrapped. This is in line with the work of a discriminator.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl2sec34"></a>Training GANs</h3></div></div></div><p>The following diagram illustrates <span>the</span><a id="id325940669" class="indexterm"></a> basic architecture of GANs:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/4041edef-a656-4969-bb1b-f7a01b579dbb.png" /></div><p>A random input is used to generate a sample of data. For example, a generator, <span class="emphasis"><em>G(z)</em></span>, uses a prior distribution, <span class="emphasis"><em>p(z)</em></span>, to achieve an input, <span class="emphasis"><em>z</em></span>. Using <span class="emphasis"><em>z</em></span>, it then generates some data. This output is fed as input to the discriminator neural network, <span class="emphasis"><em>D(x)</em></span>. It takes an input x from </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/bbbe6405-7d5a-4b43-b343-70b07ff9accb.png" /></div><p>, where </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/cbd1425a-b4ac-4ffa-b1d6-5cbbe7a1d9c0.png" /></div><p>is our real data distribution. <span class="emphasis"><em>D(x)</em></span> then solves a binary classification problem using the <code class="literal">sigmoid</code> function, which gives us an output in the range of 0 to 1.</p><p>GANS are trained to be part of a competition between the generator and discriminator. The objective function can be represented mathematically as follows:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/f08933be-0e08-45b4-94f3-f025265c152b.png" /></div><p><span>In this, the following applies:</span></p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><div class="mediaobject"><img src="/graphics/9781789132212/graphics/a995d841-8776-4aa4-97c8-17ca91b7c2e9.png" /></div> denotes the parameters of the discriminator</li><li style="list-style-type: disc"><div class="mediaobject"><img src="/graphics/9781789132212/graphics/1fdcf7c0-43e2-4bec-9809-020213db3830.png" /></div> denotes the parameters of the generator</li><li style="list-style-type: disc"><div class="mediaobject"><img src="/graphics/9781789132212/graphics/f8b85f25-ce9f-4026-9ba5-e27496c37cb2.png" /></div>denotes the underlying distribution of training data</li><li style="list-style-type: disc"><div class="mediaobject"><img src="/graphics/9781789132212/graphics/89d160f1-b550-4509-b764-7dafa147d2fe.png" /></div> denotes the discriminator operation over input images <span class="emphasis"><em>x</em></span></li><li style="list-style-type: disc"><div class="mediaobject"><img src="/graphics/9781789132212/graphics/be34eaab-bc84-4fa0-af0c-d5b30e164950.png" /></div> denotes the generator operation over latent sample <span class="emphasis"><em>z</em></span></li><li style="list-style-type: disc"><div class="mediaobject"><img src="/graphics/9781789132212/graphics/ec957ce8-e97d-4f5e-8eb9-989978a0e128.png" /></div> denotes the discriminator output for generated fake data <div class="mediaobject"><img src="/graphics/9781789132212/graphics/35188113-bcce-4d25-8e2b-01112b02a94f.png" /></div></li></ul></div><p>In the objective function, the first term from <span>the</span><a id="id326069626" class="indexterm"></a> left represents the cross entropy of the discriminator's output from a real distribution (</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/f55d204f-af1e-43a1-a398-7d936a822765.png" /></div><p>). The second term from the left is the cross entropy between the random distribution (</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/8016e097-b8fb-4af0-b241-0501ba02e170.png" /></div><p>) and one minus the prediction of the discriminator on the output of the generator that was generated using random sample z from </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/80f19f3c-6516-499b-a7ef-1258cc565dd7.png" /></div><p>. The discriminator tries to maximize both terms to classify the images as real and fake, respectively. On the other hand, the generator tries to fool the discriminator by minimizing this objective. </p><p>In order to train GANs, gradient-based optimization algorithms, such as stochastic gradient descent, are used. Algorithmically, it flows as follows:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>First, sample <span class="emphasis"><em>m</em></span> noise samples and <span class="emphasis"><em>m</em></span> real data samples.</li><li>Freeze the generator, that is, set the training as false so that the generator network only does a forward pass without any back propagation. Train the discriminator on this data.</li><li>Sample different <span class="emphasis"><em>m</em></span> noise samples.</li><li>Freeze the discriminator and train the generator on this data.</li><li>Iterate through the preceding steps.</li></ol></div><p>Formally, the pseudocode is as follows.</p><p>In this example, we are performing mini-batch stochastic gradient descent training of generative adversarial nets. The number of steps to apply to the discriminator, <span class="emphasis"><em>k</em></span>, is a hyper parameter. We used <span class="emphasis"><em>k=1</em></span>, the least expensive option, in our experiment:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/78816e44-f14e-42f3-8d0c-a1c7fee350a5.png" /></div><p>Pseudocode for GAN training. With k=1, this equates to training D, then G, one after the other. Adapted from Goodfellow et al. 2014</p><p>The gradient-based updates can <span>use</span><a id="id326202218" class="indexterm"></a> any standard gradient-based learning rule. We used momentum in our experiment. </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl2sec35"></a>Applications</h3></div></div></div><p>Some of the applications of GANs <span>include</span><a id="id326258385" class="indexterm"></a> converting monochrome or black and white images into colored images, filling additional details in an image, such as the insertion of objects into a partial image or into an image with only edges, and constructing images representing what somebody would look like when they are older given an image of their present self.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl2sec36"></a>Challenges</h3></div></div></div><p>Though GANs generate one of the <span>sharpest</span><a id="id326258400" class="indexterm"></a> images from a given piece of input data, their optimization is difficult to achieve due to unstable training dynamics. They also suffer from other challenges, such as mode collapse and bad initialization. Mode collapse is a phenomena where, if the data is multimodal, the generator is never incentivized to cover both modes, which leads to lower variability among generated samples and, hence, lower utility of GANs. If all generated samples start to become identical, it leads to complete collapse. In cases where most of the samples show some commonality, there is partial collapse of the model. At the core of this, GANs work on an objective function that aims to achieve optimization of min-max, but if the initial parameters end up being inefficient, then it becomes an oscillating process with no true optimization. In addition to this, there are issues such as GANs failing to differentiate the count of particular objects that should occur at a location. For example, GANs have no idea that there can't be more than two eyes and can generate images of human faces with 3 eyes.  There are also issues with GANs being unable to adapt to a 3D perspective, such as front and posterior view. This gives a flat 2D image instead of depth for a 3D object.</p><p>Different variants of GANs have evolved over time. Some of them are as follows: </p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Deep convolutional GANs</strong></span> (<span class="strong"><strong>DCGANs</strong></span>) were one of the first major improvements on the GAN architecture. It is made up of convolutional layers that <span>avoid</span><a id="id326258434" class="indexterm"></a> the use of max pooling or fully connected layers. The convolutional stride and transposed convolution for downsampling and upsampling is majorly used by this. It also uses ReLU activation <span>in</span> the generator and LeakyReLU in the discriminator.</li><li style="list-style-type: disc"><span class="strong"><strong>InfoGANs</strong></span> are another <span>variant</span><a id="id326259580" class="indexterm"></a> of GANs that try and encode meaningful features of the image (for example, rotation) in parts of the noise vector, z. </li><li style="list-style-type: disc"><span class="strong"><strong>Conditional GANs</strong></span> (<span class="strong"><strong>cGANs</strong></span>) use extra conditional information that describes some aspect of the <span>data</span><a id="id326259600" class="indexterm"></a> as input to the generator and discriminator. For example, if we are dealing with vehicles, the condition could describe attributes such as four-wheeled or two-wheeled. This helps generate better samples and additional features. In this chapter, we will mainly focus on DiscoGANs, which are described in the following section.</li></ul></div></div></div>