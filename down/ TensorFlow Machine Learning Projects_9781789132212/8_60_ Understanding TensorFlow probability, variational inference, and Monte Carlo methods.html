<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch08lvl1sec61"></a>Understanding TensorFlow probability, variational inference, and Monte Carlo methods</h2></div></div><hr /></div><p><span class="strong"><strong>TensorFlow Probability</strong></span> (<span class="strong"><strong>tfp</strong></span> in code – <a class="ulink" href="https://www.tensorflow.org/probability/overview#layer_2_model_building" target="_blank">https://www.tensorflow.org/probability/overview#layer_2_model_building</a>) was recently released by Google to perform probabilistic reasoning in a <span>scalable</span><a id="id325607374" class="indexterm"></a> manner. It provides tools and functionalities to <span>define</span><a id="id325607367" class="indexterm"></a> distributions, build neural <span>networks</span><a id="id325606019" class="indexterm"></a> with prior on weights, and perform probabilistic <span>inference</span><a id="id325606022" class="indexterm"></a> tasks such as Monte Carlo or Variational Inference.</p><p>Let's take a look at some of the functions/utilities we will be using for building our model:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Tfp.distributions.categorical</strong></span>: This is a <span>standard</span><a id="id325601673" class="indexterm"></a> categorical distribution that's characterized by probabilities or log-probabilities over K classes. In this project, we have Traffic Sign images from 43 different traffic signs. We will define a categorical distribution over 43 classes in this project.</li><li style="list-style-type: disc"><span class="strong"><strong>Probabilistic layers</strong></span>: Built on top of <span>the</span><a id="id325585522" class="indexterm"></a> TensorFlow layers implementation, probabilistic layers incorporate uncertainty over the functions they represent. Effectively, they incorporate uncertainty in the weights of the neural networks. They have the functionality to forward pass through the inputs by sampling from the posterior of weight distributions (<div class="mediaobject"><img src="/graphics/9781789132212/graphics/7b5a540f-a142-47c5-ad67-fab34786d9a7.png" /></div>). Specifically, we will use the Convolutional2DFlipout (<a class="ulink" href="https://www.tensorflow.org/probability/api_docs/python/tfp/layers/Convolution2DFlipout" target="_blank">https://www.tensorflow.org/probability/api_docs/python/tfp/layers/Convolution2DFlipout</a>) layer, which can compute the forward pass by sampling from the posterior of the weight parameters of the model.
</li><li style="list-style-type: disc"><span class="strong"><strong>Kullback-leibler (KL) divergence</strong></span>: If we want to measure the difference between two numbers, we just subtract them. What if we want to obtain a difference between two probability distributions? What is <span>the</span><a id="id325091911" class="indexterm"></a> equivalent of subtraction in this case? Often in the case in probability and statistics, we will replace the observed data or complex distributions with a simpler, approximating distribution. KL <span>Divergence</span> helps us measure just how much information we lose when we choose an approximation. Essentially, it is a measure of one probability distribution from others. A KL divergence of 0 indicates that two distributions are identical. If you want to know more about the mathematics of KL divergence, please refer to a great explanation from MIT open courseware, which can be found at <a class="ulink" href="https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec15.pdf" target="_blank">https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec15.pdf</a>.</li><li style="list-style-type: disc"><span class="strong"><strong>Variational inference</strong></span>: Variational <span>inference</span><a id="id325091936" class="indexterm"></a> is a machine learning method that's used to approximate complex, intractable integrals in Bayesian learning through optimization. </li></ul></div><p>As we know, our aim in Bayesian learning is to calculate the posterior </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/20500e6e-c205-4a3f-b2e2-fcba22086c2a.png" /></div><p>, given prior </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/37adaa69-f95e-43c2-9506-638eb1477f6c.png" /></div><p> and data </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/39478fe6-bb0e-471e-a684-ceca56ac59ce.png" /></div><p>. A prerequisite for computing the posterior is the computation of distribution of </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/4e9c1cd1-d2ba-4eb2-aa8c-fa916715dd60.png" /></div><p> (data) in order to obtain </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/7a2c704d-1722-4e2c-8fa1-e33a10192c3a.png" /></div><p>, or <span class="emphasis"><em>evidence</em></span>. As mentioned earlier, the distribution of X is intractable as it is too expensive to compute using a brute-force approach. To address this problem, we will use something called <span>Variational Inference</span> (VI). In VI, we define a family of distributions </p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/0b5ca1e8-7ef8-4d56-b19f-a9ac21e00aee.png" /></div><p>, parameterized by</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/422559e1-1829-4cae-8d32-1b84cd42ffb1.png" /></div><p>. The core idea is to optimize</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/e2e7d162-4861-4439-b50f-f58ef3000556.png" /></div><p> so that the approximate distribution is as close to the true posterior as possible. We measure the difference between two distributions using KL divergence. As it turns out, it is not easy to minimize the KL divergence. We can show you that this KL divergence is always positive and <span>that</span><a id="id326070666" class="indexterm"></a> it comprises two parts using the following mathematical formula:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/2a68e294-5a03-4442-8bda-da11e6414954.png" /></div><p>Here, <span class="strong"><strong>ELBO</strong></span> is <span class="strong"><strong>Evidence Lower Bound</strong></span> (<a class="ulink" href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf" target="_blank">https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf</a>).</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Monte Carlo method: </strong></span>Monte Carlo <span>methods</span><a id="id326487506" class="indexterm"></a> are computational methods which rely on repeated random sampling to obtain the statistical behavior of some phenomenon (behavior). They are typically used to model uncertainties or generate what-if scenarios for business.</li></ul></div><p>Let's say you commute by train every day to work. You are thinking about whether to take the company shuttle to the office instead. Now, there are many random variables associated with a bus ride, such as time of arrival, traffic, number of passengers boarding the bus, and so on.</p><p>One way that we can look at this what-if scenario is if we take the mean of these random variables and calculate the arrival time. However, that will be too naive as it doesn't take into account variance in these variables. Another way is to sample from these random variables (somehow, if you are able to do that!) and generate what-if scenarios of reaching the office.</p><p>To make a decision, you will need an acceptable criteron. For instance, if you observe that in 80% of these what-if scenarios you reach office on or before time, you can continue forward. This approach is also known as the Monte Carlo simulation. </p><p>In this project, we will model the weights of neural networks as random variables. To determine the final prediction, we will sample from the distributions of these <span>weights</span><a id="id326487524" class="indexterm"></a> repeatedly to obtain the distribution of predictions.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note48"></a>Note</h3><p>Note that we have skipped some mathematical details. Feel free to read more about Variational Inference (<a class="ulink" href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf" target="_blank">https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf</a><a class="ulink" href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf" target="_blank">)</a>.</p></div></div>