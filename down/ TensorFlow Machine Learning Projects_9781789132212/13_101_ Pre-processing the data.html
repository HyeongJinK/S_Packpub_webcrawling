<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec97"></a>Pre-processing the data</h2></div></div><hr /></div><p>As mentioned previously, the <span>dataset</span><a id="id325585512" class="indexterm"></a> used in this project is from a popular Packt book that goes by the name of <span class="emphasis"><em>Mastering PostgreSQL 10</em></span>, and was written by Hans-Jürgen Schönig (<a class="ulink" href="https://www.cybertec-postgresql.com" target="_blank">https://www.cybertec-postgresql.com</a>). We considered text from the first 100 pages of the book, excluding any figures, tables, and SQL code. The cleaned dataset is stored, alongside the code, in a text file. The dataset contains almost 44,000 words, which is just enough to train the model. The following are a few lines from the script:</p><p><span class="emphasis"><em>"PostgreSQL Overview</em></span></p><p><span class="emphasis"><em>PostgreSQL is one of the world's most advanced open source database systems, and it has many features that are widely used by developers and system administrators alike. Starting with PostgreSQL 10, many new features have been added to PostgreSQL, which contribute greatly to the success of this exceptional open source product. In this book, many of these cool features will be covered and discussed in great detail.</em></span><span class="emphasis"><em>In this chapter, you will be introduced to PostgreSQL and the cool new features available in PostgreSQL 10.0 and beyond. All relevant new functionalities will be covered in detail. Given the sheer number of changes made to the code and given the size of the PostgreSQL project, this list of features is of course by far not complete, so I tried to focus on the most important aspects that are relevant to most people.</em></span><span class="emphasis"><em>The features outlined in this chapter will be split into the following categories Database administration</em></span><span class="emphasis"><em>SQL and developer related Backup, recovery, and replication Performance related topics</em></span><span class="emphasis"><em>What is new in PostgreSQL 10.0.</em></span><span class="emphasis"><em>PostgreSQL 10.0 was released in late 2017 and is the first version that follows the new numbering scheme introduced by the PostgreSQL community. From now on, the way major releases are done will change and therefore, the next major version after PostgreSQL</em></span><span class="emphasis"><em>10.0 will not be 10.1 but PostgreSQL 11. Versions 10.1 and 10.2 are merely service releases and will only contain bug fixes."</em></span></p><p>For pre-processing the data so that we prepare it for a LSTM model, go through the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><span class="strong"><strong>Tokenize punctuation</strong></span>: While pre-processing, we consider the splitting criteria as words using spaces. However, in this scenario, the neural network will have a hard time distinguishing words such as Hello and Hello!. Due to this limitation, it is required <span>that</span><a id="id325091911" class="indexterm"></a> you tokenize the punctuations in the dataset. For example, <code class="literal">!</code> will be mapped to <code class="literal">_Sym_Exclamation_</code>. In the code, we implement a function named <code class="literal">define_tokens</code>. This is used to create a dictionary. Here, each piece of punctuation is considered a key, and its respective token is a value. In this example, we will create tokens for the following symbols:</li></ol></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Period ( . )</li><li style="list-style-type: disc">Comma ( , )</li><li style="list-style-type: disc">Quotation mark (" )</li><li style="list-style-type: disc">Semicolon ( ; )</li><li style="list-style-type: disc">Exclamation mark ( ! )</li><li style="list-style-type: disc">Question mark ( ? )</li><li style="list-style-type: disc">Left parenthesis ( ( )</li><li style="list-style-type: disc">Right parenthesis ( ) )</li><li style="list-style-type: disc">Dash ( -- )</li><li style="list-style-type: disc">Return ( \n )</li></ul></div></li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note70"></a>Note</h3><p>Avoid using a token that will probably be a word in the dataset. For example, <code class="literal">?</code> is replaced by <code class="literal">_Sym_Question_</code>, which is not a word in the dataset.</p></div><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li><span class="strong"><strong>Lower and split</strong></span>: We must convert all of the uppercase letters in the text to lowercase so that the neural network will learn that the two words "Hello" and "hello" are actually the same. As the basic unit of input to neural networks will be words, the very next step would be to split the sentences in the text into words.</li><li><span class="strong"><strong>Map creation</strong></span>: Neural networks do not accept text as an input, and so we need to map these words to indexes/IDs. To do this, we must create two dictionaries, as follows:</li></ol></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">Vocab_to_int</code>: Mapping of each word in the text to its unique ID</li><li style="list-style-type: disc"><code class="literal">Int_to_vocab</code>: Inverse dictionary which maps IDs to their corresponding words</li></ul></div></li></ul></div></div>