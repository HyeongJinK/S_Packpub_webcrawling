<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch10lvl1sec74"></a>Training and testing the model</h2></div></div><hr /></div><p>The following are the steps for training and testing the model:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>The first step is to read the training and testing datasets. Here are steps we must implement for reading the data: 
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">First, we load <span>the</span> training/testing images and label data from the <span>files</span><a id="id325642523" class="indexterm"></a> we downloaded for the <span class="strong"><strong>Fashion MNIST </strong></span>data (<a class="ulink" href="https://github.com/zalandoresearch/fashion-mnist" target="_blank">https://github.com/zalandoresearch/fashion-mnist</a>).</li><li style="list-style-type: disc">Then, we reshape the image data to a shape of 28 x 28 x 1 for our <span>model</span><a id="id326486690" class="indexterm"></a> and normalize it by 255 to keep the input of the <span>model</span><a id="id326486674" class="indexterm"></a> between 0 and 1.</li><li style="list-style-type: disc">We split the training data into train and validation datasets, each with <span>55,000</span> and 5000 images respectively.</li><li style="list-style-type: disc">We convert our target array <span class="strong"><strong>y</strong></span> for both training and testing datasets so that we have a one-hot representation of the 10 classes in the dataset that we are going to feed into the model. </li></ul></div></li></ol></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip58"></a>Note</h3><p>Make sure to choose around 10% of data for out validation. In this project, we choose 5000 random images (8% of the total images) for the validation data set.</p></div><p>The code for the preceding steps is as follows:</p><pre class="programlisting">def load_data(load_type='train'):
'''

    :param load_type: train or test depending on the use case
    :return: x (images), y(labels)
    '''
data_dir = os.path.join('data','fashion-mnist')
if load_type == 'train':
image_file = open(os.path.join(data_dir,'train-images-idx3-ubyte'))
        image_data = np.fromfile(file=image_file, dtype=np.uint8)
        x = image_data[16:].reshape((60000, 28, 28, 1)).astype(np.float32)

        label_file = open(os.path.join(data_dir, 'train-labels-idx1-ubyte'))
        label_data = np.fromfile(file=label_file, dtype=np.uint8)
        y = label_data[8:].reshape(60000).astype(np.int32)

        x_train = x[:55000] / 255.
y_train = y[:55000]
        y_train = (np.arange(N_CLASSES) == y_train[:, None]).astype(np.float32)

        x_valid = x[55000:, ] / 255.
y_valid = y[55000:]
        y_valid = (np.arange(N_CLASSES) == y_valid[:, None]).astype(np.float32)
return x_train, y_train, x_valid, y_valid
elif load_type == 'test':
image_file = open(os.path.join(data_dir, 't10k-images-idx3-ubyte'))
        image_data = np.fromfile(file=image_file, dtype=np.uint8)
        x_test = image_data[16:].reshape((10000, 28, 28, 1)).astype(np.float)

        label_file = open(os.path.join(data_dir, 't10k-labels-idx1-ubyte'))
        label_data = np.fromfile(file=label_file, dtype=np.uint8)
        y_test = label_data[8:].reshape(10000).astype(np.int32)
        y_test = (np.arange(N_CLASSES) == y_test[:, None]).astype(np.float32)
return x_test / 255., y_test</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip59"></a>Note</h3><p>Note that we normalize the image pixels by <code class="literal">255</code> after loading the dataset for training stability and faster convergence.</p></div><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>Implement the encoder by creating the three neural network layers that have been defined in the <span class="emphasis"><em>U</em></span><span class="emphasis"><em>nderstanding the encoder</em></span> section:</li></ol></div><pre class="programlisting">with tf.variable_scope('Conv1_layer'):
conv1_layer = tf.layers.conv2d(self.X, name="conv1_layer", **CONV1_LAYER_PARAMS) # [batch_size, 20, 20, 256]

with tf.variable_scope('PrimaryCaps_layer'):
conv2_layer = tf.layers.conv2d(conv1_layer, name="conv2_layer", **CONV2_LAYER_PARAMS) # [batch_size, 6, 6, 256]

primary_caps = tf.reshape(conv2_layer, (BATCH_SIZE, NCAPS_CAPS1, CAPS_DIM_CAPS1, 1), name="primary_caps") # [batch_size, 1152, 8, 1]
primary_caps_output = squash(primary_caps, name="caps1_output")
# [batch_size, 1152, 8, 1]

# DigitCaps layer, return [batch_size, 10, 16, 1]
with tf.variable_scope('DigitCaps_layer'):
digitcaps_input = tf.reshape(primary_caps_output, shape=(BATCH_SIZE, NCAPS_CAPS1, 1, CAPS_DIM_CAPS1, 1)) # [batch_size, 1152, 1, 8, 1]
    # [batch_size, 1152, 10, 1, 1]
self.digitcaps_output = routing(digitcaps_input) # [batch_size, 10, 16, 1]</pre><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>Next, implement the decoder layers to reconstruct the images, as described in the <span class="emphasis"><em>Understanding the decoder</em></span><span class="strong"><strong> </strong></span>section. Here are the important steps once again for reference:</li></ol></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">First, we calculate the norm of each activity vector in a digit caps output for masking purposes. We also add an epsilon to the norm for stability purposes.
</li><li style="list-style-type: disc">For training, we mask all of the activity vectors in digit caps output, except the one with the correct label. On the other hand, for testing, we mask all the activity vectors in digit caps output, except the one with the highest norm (or predicted label). We implement this branching mechanism in the decoder with <span class="strong"><strong>tf.cond</strong></span>, which defines a <span>control</span><a id="id325091929" class="indexterm"></a> flow operation in the TensorFlow graph. </li><li style="list-style-type: disc">Finally, we flatten the masked output from the digit caps and flatten it as a one-dimensional vector that can be fed to the fully connected layers.</li></ul></div></li></ul></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note60"></a>Note</h3><p>To read up on <code class="literal">tf.cond</code>, refer to <a class="ulink" href="https://www.tensorflow.org/api_docs/python/tf/cond" target="_blank">https://www.tensorflow.org/api_docs/python/tf/cond</a>.</p></div><p>The code for the preceding steps is as follows:</p><pre class="programlisting"># Decoder
with tf.variable_scope('Masking'):
self.v_norm = tf.sqrt(tf.reduce_sum(tf.square(self.digitcaps_output), axis=2, keep_dims=True) + tf.keras.backend.epsilon())

    predicted_class = tf.to_int32(tf.argmax(self.v_norm, axis=1)) #[batch_size, 10,1,1]
self.y_predicted = tf.reshape(predicted_class, shape=(BATCH_SIZE,))  #[batch_size]
y_predicted_one_hot = tf.one_hot(self.y_predicted, depth=NCAPS_CAPS2)  #[batch_size,10]  One hot operation

reconstruction_targets = tf.cond(self.mask_with_labels,  # condition
lambda: self.Y,  # if True (Training)
lambda: y_predicted_one_hot,  # if False (Test)
name="reconstruction_targets")

    digitcaps_output_masked = tf.multiply(tf.squeeze(self.digitcaps_output), tf.expand_dims(reconstruction_targets, -1)) # [batch_size, 10, 16]


    #Flattening as suggested by the paper
decoder_input = tf.reshape(digitcaps_output_masked, [BATCH_SIZE, -1]) # [batch_size, 160]


with tf.variable_scope('Decoder'):
fc1 = tf.layers.dense(decoder_input, layer1_size, activation=tf.nn.relu, name="FC1") # [batch_size, 512]
fc2 = tf.layers.dense(fc1, layer2_size, activation=tf.nn.relu, name="FC2") # [batch_size, 1024]
self.decoder_output = tf.layers.dense(fc2, output_size, activation=tf.nn.sigmoid, name="FC3") # [batch_size, 784]</pre><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>Implement margin loss using the formula mentioned in the <span class="emphasis"><em>Defining the loss function</em></span> section as follows:</li></ol></div><pre class="programlisting">with tf.variable_scope('Margin_Loss'):
# max(0, m_plus-||v_c||)^2
positive_error = tf.square(tf.maximum(0., 0.9 - self.v_norm)) # [batch_size, 10, 1, 1]
    # max(0, ||v_c||-m_minus)^2
negative_error = tf.square(tf.maximum(0., self.v_norm - 0.1)) # [batch_size, 10, 1, 1]
    # reshape: [batch_size, 10, 1, 1] =&gt; [batch_size, 10]
positive_error = tf.reshape(positive_error, shape=(BATCH_SIZE, -1))
    negative_error = tf.reshape(negative_error, shape=(BATCH_SIZE, -1))

    Loss_vec = self.Y * positive_error + 0.5 * (1- self.Y) * negative_error # [batch_size, 10]
self.margin_loss = tf.reduce_mean(tf.reduce_sum(Loss_vec, axis=1), name="margin_loss")

</pre><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>Implement reconstruction loss using the formula mentioned in the <span class="emphasis"><em>Defining the loss function</em></span> section:</li></ol></div><pre class="programlisting">with tf.variable_scope('Reconstruction_Loss'):
ground_truth = tf.reshape(self.X, shape=(BATCH_SIZE, -1))
self.reconstruction_loss = tf.reduce_mean(tf.square(self.decoder_output - ground_truth))</pre><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>Define the optimizer as an Adam op<span>timize</span>r, using the default parameters and an accuracy metric as the usual classification accuracy. These need to be implemented in the CapsNet class itself using the following code:</li></ol></div><pre class="programlisting">def define_accuracy(self):
with tf.variable_scope('Accuracy'):
correct_predictions = tf.equal(tf.to_int32(tf.argmax(self.Y, axis=1)), self.y_predicted)
self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))

def define_optimizer(self):
with tf.variable_scope('Optimizer'):
optimizer = tf.train.AdamOptimizer()
self.train_optimizer = optimizer.minimize(self.combined_loss, name="training_optimizer")</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip61"></a>Note</h3><p>To learn more about the Adam Optimizer, refer to<a class="ulink" href="https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer" target="_blank"> https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer</a>.</p></div><div class="orderedlist"><ol class="orderedlist arabic" start="7" type="1"><li>Implement the support for checkpointing and <span>restoring</span><a id="id325614962" class="indexterm"></a> the model. Select the best <span>model</span><a id="id325614970" class="indexterm"></a> based on validation set accuracy; we checkpoint the <span>model</span><a id="id325615011" class="indexterm"></a> only for the epoch, where we observe a decrease in the validation set accuracy and finally, log the summary output for TensorBoard visualization. We train our model for 10 epochs each having batch size 128. Remember, you can vary these parameters to improve the accuracy of your model:</li></ol></div><pre class="programlisting">def train(model):
global fd_train
    x_train, y_train, x_valid, y_valid = load_data(load_type='train')
print('Data set Loaded')
    num_batches = int(y_train.shape[0] / BATCH_SIZE)
if not os.path.exists(CHECKPOINT_PATH_DIR):
os.makedirs(CHECKPOINT_PATH_DIR)

with tf.Session() as sess:
if RESTORE_TRAINING:
saver = tf.train.Saver()
            ckpt = tf.train.get_checkpoint_state(CHECKPOINT_PATH_DIR)
            saver.restore(sess, ckpt.model_checkpoint_path)
print('Model Loaded')
            start_epoch = int(str(ckpt.model_checkpoint_path).split('-')[-1])
            train_file, val_file, best_loss_val = load_existing_details()
else:
saver = tf.train.Saver(tf.global_variables())
            tf.global_variables_initializer().run()
print('All variables initialized')
            train_file, val_file = write_progress('train')
            start_epoch = 0
best_loss_val = np.infty
print('Training Starts')
        acc_batch_all = loss_batch_all = np.array([])
        train_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)
for epoch in range(start_epoch, EPOCHS):
# Shuffle the input data
x_train, y_train = shuffle_data(x_train, y_train)
for step in range(num_batches):
start = step * BATCH_SIZE
                end = (step + 1) * BATCH_SIZE
                global_step = epoch * num_batches + step
                x_batch, y_batch = x_train[start:end], y_train[start:end]
                feed_dict_batch = {model.X: x_batch, model.Y: y_batch, model.mask_with_labels: True}
if not (step % 100):
_, acc_batch, loss_batch, summary_ = sess.run([model.train_optimizer, model.accuracy,
model.combined_loss, model.summary_],
feed_dict=feed_dict_batch)
                    train_writer.add_summary(summary_, global_step)
                    acc_batch_all = np.append(acc_batch_all, acc_batch)
                    loss_batch_all = np.append(loss_batch_all, loss_batch)
                    mean_acc,mean_loss = np.mean(acc_batch_all),np.mean(loss_batch_all)
                    summary_ = tf.Summary(value=[tf.Summary.Value(tag='Accuracy', simple_value=mean_acc)])
                    train_writer.add_summary(summary_, global_step)
                    summary_ = tf.Summary(value=[tf.Summary.Value(tag='Loss/combined_loss', simple_value=mean_loss)])
                    train_writer.add_summary(summary_, global_step)

                    train_file.write(str(global_step) + ',' + str(mean_acc) + ',' + str(mean_loss) + "\n")
                    train_file.flush()
print("  Batch #{0}, Epoch: #{1}, Mean Training loss: {2:.4f}, Mean Training accuracy: {3:.01%}".format(
                        step, (epoch+1), mean_loss, mean_acc))
                    acc_batch_all = loss_batch_all = np.array([])
else:
_, acc_batch, loss_batch = sess.run([model.train_optimizer, model.accuracy, model.combined_loss],
feed_dict=feed_dict_batch)
                    acc_batch_all = np.append(acc_batch_all, acc_batch)
                    loss_batch_all = np.append(loss_batch_all, loss_batch)

# Validation metrics after each EPOCH
acc_val, loss_val = eval_performance(sess, model, x_valid, y_valid)
            val_file.write(str(epoch + 1) + ',' + str(acc_val) + ',' + str(loss_val) + '\n')
            val_file.flush()
print("\rEpoch: {}  Mean Train Accuracy: {:.4f}% ,Mean Val accuracy: {:.4f}%  Loss: {:.6f}{}".format(
                epoch + 1, mean_acc * 100, acc_val * 100, loss_val,
" (improved)" if loss_val &lt; best_loss_val else ""))

# Saving the improved model
if loss_val &lt; best_loss_val:
saver.save(sess, CHECKPOINT_PATH_DIR + '/model.tfmodel', global_step=epoch + 1)
                best_loss_val = loss_val
        train_file.close()
        val_file.close()</pre><p>This model achieved almost <code class="literal">99%</code> accuracy with <code class="literal">10</code> epochs on the validation and test sets, which is quite good. </p></div>