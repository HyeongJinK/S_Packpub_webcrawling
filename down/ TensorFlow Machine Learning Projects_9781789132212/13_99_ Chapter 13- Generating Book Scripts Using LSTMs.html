<div class="chapter" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="ch13"></a>Chapter 13. Generating Book Scripts Using LSTMs</h2></div></div></div><p><span class="strong"><strong>Natural language generation</strong></span> (<span class="strong"><strong>NLG</strong></span>), which is a sub-field of artificial intelligence, is a natural language processing task of generating human-readable text from various <span>data</span><a id="id325795670" class="indexterm"></a> inputs. It is an active area of research that has achieved great popularity in recent times.</p><p>The ability to generate natural language through machines can have wide variety of applications, including text autocomplete feature in phones, generating the summary of a document, and even generating new scripts for comedies. Google's S<span>mart Reply</span> also uses a technology that runs on similar lines to give reply suggestions when you're writing an email.</p><p>In this chapter, we will look at an NLG task of generating a book script from another Packt book that goes by the name of <span class="emphasis"><em>Mastering PostgreSQL 10</em></span>. We took almost 100 pages of this book and removed any figures, tables, and SQL code. The data is fairly large and has enough words for a neural network to learn the nuances of the dataset.</p><p>We will learn how to generate book scripts using reinforcement neural networks by going through the following topics:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Introduction to recurrent neural networks and LSTMs</li><li style="list-style-type: disc">Description of the book script dataset</li><li style="list-style-type: disc">Modeling using LSTMs and generating a new book script</li></ul></div></div>