<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec15"></a>Logistic regression with Keras</h2></div></div><hr /></div><p><span class="strong"><strong>Keras</strong></span> is a high-level library <span>that</span><a id="id325677131" class="indexterm"></a> is available as part of TensorFlow. In this section, we will <span>rebuild</span><a id="id325677118" class="indexterm"></a> the same model we <span>built</span><a id="id325677107" class="indexterm"></a> earlier with TensorFlow core with Keras:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Keras takes data in a different format, and so we must first reformat the data using <code class="literal">datasetslib</code>:</li></ol></div><pre class="programlisting">x_train_im = mnist.load_images(x_train)

x_train_im, x_test_im = x_train_im / 255.0, x_test / 255.0</pre><p>In the preceding code, we are loading the training images in memory before both the training and test images are scaled, which we do by dividing them by <code class="literal">255</code>.</p><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>Then, we build the model:</li></ol></div><pre class="programlisting">model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])</pre><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>Compile the model with the <code class="literal">sgd</code> optimizer. Set the categorical entropy as the <code class="literal">loss</code> function and the accuracy as a metric to test the model:</li></ol></div><pre class="programlisting">model.compile(optimizer='sgd',
loss='sparse_categorical_crossentropy',
metrics=['accuracy'])</pre><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>Train the model for <code class="literal">5</code> epochs with the training set of images and labels:</li></ol></div><pre class="programlisting">model.fit(x_train_im, y_train, epochs=5)

Epoch 1/5
60000/60000 [==============================] - 3s 45us/step - loss: 0.7874 - acc: 0.8095
Epoch 2/5
60000/60000 [==============================] - 3s 42us/step - loss: 0.4585 - acc: 0.8792
Epoch 3/5
60000/60000 [==============================] - 2s 42us/step - loss: 0.4049 - acc: 0.8909
Epoch 4/5
60000/60000 [==============================] - 3s 42us/step - loss: 0.3780 - acc: 0.8965
Epoch 5/5
60000/60000 [==============================] - 3s 42us/step - loss: 0.3610 - acc: 0.9012
10000/10000 [==============================] - 0s 24us/step</pre><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>Evaluate the model with the test data:</li></ol></div><pre class="programlisting">model.evaluate(x_test_im, nputil.argmax(y_test))</pre><p>We get the following evaluation scores as output:</p><pre class="programlisting"><span>[0.33530342621803283, 0.9097]</span></pre><p>Wow! Using Keras, we can achieve higher accuracy. We achieved approximately 90% accuracy. This is because Keras internally sets many optimal values for us so that we can quickly start building models.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note10"></a>Note</h3><p>To learn more about Keras and to look at more examples, refer to the book <span class="emphasis"><em>Mastering TensorFlow,</em></span> from Packt Publications.</p></div></div>