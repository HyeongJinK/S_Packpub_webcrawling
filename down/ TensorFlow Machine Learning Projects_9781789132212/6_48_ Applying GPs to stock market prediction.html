<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec51"></a>Applying GPs to stock market prediction</h2></div></div><hr /></div><p>In this project, we will try to predict the prices of three major <span>stocks</span><a id="id326280163" class="indexterm"></a> in the market. The <span>dataset</span><a id="id326280206" class="indexterm"></a> for this exercise can be downloaded from Yahoo Finance (<a class="ulink" href="https://finance.yahoo.com" target="_blank">https://finance.yahoo.com</a>). We downloaded the entire stock history for three companies:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Google (<a class="ulink" href="https://finance.yahoo.com/quote/GOOG" target="_blank">https://finance.yahoo.com/quote/GOOG</a>)</li><li style="list-style-type: disc">Netflix (<a class="ulink" href="https://finance.yahoo.com/quote/NFLX" target="_blank">https://finance.yahoo.com/quote/NFLX</a>)</li><li style="list-style-type: disc">General Electric company (<a class="ulink" href="https://finance.yahoo.com/quote/GE" target="_blank">https://finance.yahoo.com/quote/GE</a>)</li></ul></div><p>We choose three datasets to compare GP performance across different stocks. Feel free to try this for more stocks.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note40"></a>Note</h3><p>All of these datasets are present in the GitHub repository. Thus, there is no need to download them again to run the code.</p></div><p>The CSV files in the dataset have multiple columns. They are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Date</strong></span>: Calendar date when the price of the stock was measured.</li><li style="list-style-type: disc"><span class="strong"><strong>Open</strong></span>: The opening price of the day.</li><li style="list-style-type: disc"><span class="strong"><strong>High:</strong></span> The highest price of the day.</li><li style="list-style-type: disc"><span class="strong"><strong>Low:</strong></span> The lowest price of the day.</li><li style="list-style-type: disc"><span class="strong"><strong>Close:</strong></span> The closing price of the day.</li><li style="list-style-type: disc"><span class="strong"><strong>Adj Close:</strong></span> The adjusted closing price is the closing price of the stock that has been amended to include any dividends or other corporate actions before the following day's opening. This is our target variable or Y in the dataset.</li><li style="list-style-type: disc"><span class="strong"><strong>Volume:</strong></span> The volume denotes the number of shares traded during a day.</li></ul></div><p> </p><p>To begin our project, we will consider two forecasting problems each, for all three stock datasets: </p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">In the first problem, we will train on prices from the years 2008-2016 and predict for the entire year of 2017</li><li style="list-style-type: disc">In the second problem, we will train on prices from the years 2008-2018 (up to the third quarter) and predict the fourth quarter of 2018</li></ul></div><p>For predicting stock prices, we don't need to model the entire time series of a stock as a single time series, as in many classical methods (an example of this is regression). For GP, each time series is divided into several time series (one for each year) for every stock. Intuitively, this makes sense, as each stock follows a yearly cycle. </p><p>The time series of each year of a stock is an input to the model as a separate time series. Therefore<span>, the forecasting problem becomes as follows: predict future prices of the stock given multiple yearly time series (one for each historical year) as the input.</span> As GP models are distributions over functions, we want to predict the mean and uncertainty at each data point in the future.</p><p>Before modeling, we need to normalize the prices to be zero mean and unit standard deviation. This is a requirement in Gaussian processes because of the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">We assume the prior on the output distribution to be zero mean, so normalization is required to match our assumption.</li><li style="list-style-type: disc">Many kernels for the <span>covariance</span><a id="id325091892" class="indexterm"></a> matrix have scale <span>parameters</span><a id="id325091900" class="indexterm"></a> in them. Normalizing the input helps us to get better estimates of kernel parameters.</li><li style="list-style-type: disc">For obtaining the posterior distribution in Gaussian processes, we have to invert the covariance matrix. Normalization helps to avoid any kind of numerical issues with this procedure. Note that we haven't discussed the linear algebra of obtaining the posterior in detail in this chapter.</li></ul></div><p>Once the data has <span>been</span><a id="id325091913" class="indexterm"></a> normalized, we can train our model and predict prices using Gaussian processes. For modeling, we use the plug, and play functions from the GPflow (<a class="ulink" href="https://github.com/GPflow/GPflow" target="_blank">https://github.com/GPflow/GPflow</a>) library, which is a wrapper on top of TensorFlow for Gaussian processes. </p><p>The independent variable (X) in the prediction problem is comprised of two factors:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">The year </li><li style="list-style-type: disc">The day of the year</li></ul></div><p>The dependent variable (Y) in the problem is the normalized adjusted closing price for each day in a year as mentioned before.</p><p>Before training the model, we need to define the prior and kernel function for Gaussian Processes. For this problem, we use the standard zero mean prior. We use a kernel function for the covariance matrix that is generated as the sum of two kernels which are defined as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Squared exponential (or RBF, as mentioned in the GPflow package) kernel with <code class="literal"><span>lengthscale</span></code> = <code class="literal">1</code> and <code class="literal">variance</code> = 63. </li><li style="list-style-type: disc">White noise with initial <code class="literal">variance</code> to be very low, such as <span class="emphasis"><em>1e-10.</em></span></li></ul></div><p>The idea behind choosing squared exponential is that it is infinitely differentiable and it's the easiest one to understand. White noise is used to account for any systemic noise we might observe in our target variables. While it may not be the best choice of kernels, it is good for understanding purposes. Feel free to experiment with other kernels and see whether they work well.</p></div>