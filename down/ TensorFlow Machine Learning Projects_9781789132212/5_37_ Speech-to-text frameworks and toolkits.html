<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec41"></a>Speech-to-text frameworks and toolkits</h2></div></div><hr /></div><p>Many cloud-based AI <span>providers</span><a id="id325989188" class="indexterm"></a> offer <span>speech</span><a id="id325988812" class="indexterm"></a> to text as a service:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Amazon's offering for <span>speech</span><a id="id325091913" class="indexterm"></a> recognition is known as <span class="strong"><strong>Amazon Transcribe</strong></span>. Amazon Transcribe allows transcription of the audio files stored in Amazon S3 in four different formats: <code class="literal">.flac</code>, <code class="literal">.wav</code>, <code class="literal">.mp4</code>, and <code class="literal">.mp3</code>. It allows an audio file with a maximum of two hours in length and 1 GB in size. The results of the transcription are created as a JSON file in an Amazon S3 bucket.</li><li style="list-style-type: disc">Google offers speech to text as part of its Google Cloud ML Services. Google Cloud Speech to Text supports <code class="literal">FLAC</code>, <code class="literal">Linear16</code>, <code class="literal">MULAW</code>, <code class="literal">AMR</code>, <code class="literal">AMR_WB</code>, and <code class="literal">OGG_OPUS</code> file formats. </li><li style="list-style-type: disc">Microsoft offers a speech to text API as part of its Azure Cognitive Services platform, known as Speech Service SDK. The Speech Service SDK integrates with rest of the Microsoft APIs to transcribe recorded audio. It only allows the WAV or PCM file format with a single channel and sample rate of 6 kHz.</li><li style="list-style-type: disc">IBM offers a speech to text API as part if its Watson platform. Watson Speech to Text supports eight audio formats: BASIC, FLAC, L16, MP3, MULAW, OGG, WAV, and WEBM. The maximum size and length of the audio files vary depending on the format used. The results of transcription are returned as a JSON file.</li></ul></div><p>Apart from the support for various international spoken languages and an extensive global vocabulary, these cloud services support the following features to different extents:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Multichannel recognition</strong></span>: Identifying multiple participants recorded in multiple channels</li><li style="list-style-type: disc"><span class="strong"><strong>Speaker diarization</strong></span>: Prediction of speech of a certain speaker</li><li style="list-style-type: disc"><span class="strong"><strong>Custom models and model selection</strong></span>: Plug in your own models and select from a plethora of pre-built models</li><li style="list-style-type: disc">Inappropriate content filtering and noise filtering</li></ul></div><p>There are also many <span>open</span><a id="id325601668" class="indexterm"></a> source toolkits for speech recognition, such as Kaldi.</p><p>Kaldi (<a class="ulink" href="http:/kaldi-asr.org" target="_blank">http:/kaldi-asr.org</a>) is a popular open source speech to text recognition library. It is written in C++ and is available from <a class="ulink" href="https://github.com/kaldi-asr/kaldi" target="_blank">https://github.com/kaldi-asr/kaldi</a>. Kaldi can be integrated into your applications using its C++ API. It also supports Android using NDK, clang++, and OpenBLAS.</p></div>