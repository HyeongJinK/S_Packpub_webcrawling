<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch15lvl1sec114"></a>Recommendations for building AI applications</h2></div></div><hr /></div><p>Now that we understand <span>some</span><a id="id325617675" class="indexterm"></a> of the tools from TensorFlow that can help us in developing and deploying models at scale, let's try to understand the general rules of thumb when building AI applications.</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Engineering over machine learning</strong></span>: Almost all the solutions to problems start with engineering. It is very important to get the data pipeline right before building any machine learning model.</li><li style="list-style-type: disc"><span class="strong"><strong>Keep it simple</strong></span>: Generally, data scientists have a natural tendency to build the most complex model for the problem. However, it is great to start with a simple, interpretable model—say, a logistic regression model for classification. It helps in discovering and debugging data or engineering pipeline issues better. Only when you are not satisfied with the results of the basic model should you use advanced techniques like deep learning.</li><li style="list-style-type: disc"><span class="strong"><strong>Distributed processing</strong></span>: In the era of big data, you will almost always run into issues where you can't fit the data into RAM. Learning about distributed frameworks like Spark can help a lot in processing and building scalable machine learning applications.</li><li style="list-style-type: disc"><span class="strong"><strong>Automated model retraining</strong></span>: Once the model is deployed, its performance can degrade over time. It is important to keep checking the model's accuracy so that automated training of the model can be kicked off with new data. This will help in maintaining prediction accuracy for the product.</li><li style="list-style-type: disc"><span class="strong"><strong>Training and testing pipelines</strong></span>: With separate pipelines for training and testing, there is always a possibility of divergence between training and testing features. Try to have as much overlap as possible between training and testing pipelines. This can help make debugging model predictions easier.</li><li style="list-style-type: disc"><span class="strong"><strong>Launch new models with <span>A/B testing</span></strong></span><span>:</span> A/B testing is a method of comparing two versions of model/webpage and others. It is a statistical experiment conducted where two different versions are shown to the users at random. You can read more about them in lecture notes from Purdue (<a class="ulink" href="https://www.cs.purdue.edu/homes/ribeirob/courses/Fall2016/lectures/hyp_tests.pdf" target="_blank">https://www.cs.purdue.edu/homes/ribeirob/courses/Fall2016/lectures/hyp_tests.pdf</a>)</li></ul></div><p>If you build a better model than the one already existing in production, you will see some uplift in accuracy for testing datasets. However, there is a real chance that you might not see the <span>same</span><a id="id325622461" class="indexterm"></a> uplift in production compared to the existing model because of a variety of issues like correlations versus causation, change in user behavior, and so on. It is very important to perform A/B tests with a new model in production before rolling them out to all users.</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>One model over ensemble</strong></span>: Ensemble models (a combination of many single models) might give better accuracy over a single model. However, if the gain is not significant, always prefer using a single model. This is because ensemble models are difficult to maintain, debug, and scale in production systems.</li></ul></div></div>