<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch04lvl1sec39"></a>Summary</h2></div></div><hr /></div><p>Machine learning is at the edge of the next wave, where we try to make ML ubiquitous in our everyday life. It has several advantages such as offline access, data privacy, and so on.</p><p>In this chapter, we looked at a new library from Google known as TensorFlow Lite, which has been optimized for deploying ML models on mobile and embedded devices. We understood the architecture of TensorFlow Lite, which converts the trained TensorFlow model into <code class="literal">.tflite</code> format. This is designed for inference at fast speed and low memory on devices. TensorFlow Lite also supports multiple platforms, such as Android, iOS, Linux, and Raspberry Pi.</p><p>Next, we used the MNIST handwritten digit dataset to train a deep learning model. Subsequently, we followed the necessary steps to convert the trained model into <code class="literal">.tflite</code> format. The steps are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Froze the graph with variables converted to constants</li><li>Optimized the graph for inference by removing the unused ops like Dropout</li><li>Used <span class="strong"><strong>TensorFlow Optimization Converter Tool</strong></span> (<span class="strong"><strong>toco</strong></span>) to convert the optimized model to <code class="literal">.tflitte</code> format</li></ol></div><p>At every step, we used TensorBoard to visualize the state of the graph.</p><p>This is a very exciting field that is continuing to evolve, both in terms of hardware and software. Once this technology reaches maturity, it will open up new use cases and business models across the world.</p><p>In the next chapter, we'll create a project that will help us convert text to speech.Â </p></div>