<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch12lvl1sec94"></a>Object detection using TensorFlowOnSpark and Sparkdl</h2></div></div><hr /></div><p>Apache Spark has a higher <span>level</span><a id="id325951722" class="indexterm"></a> API Sparkdl <span>for</span><a id="id325951710" class="indexterm"></a> scalable deep learning in Python. In this section, we'll use the Sparkdl API. In this section, you will learn how to build a <span>model</span><a id="id325951698" class="indexterm"></a> over the pre-trained Inception v3 model to detect cars and buses. This technique of <span>using</span><a id="id325951566" class="indexterm"></a> a pre-trained <span>model</span><a id="id325951561" class="indexterm"></a> is called <span class="strong"><strong>transfer learning</strong></span>.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec47"></a>Transfer learning</h3></div></div></div><p>Learning in humans is a continuous process—whatever we learn today is built upon the learning we <span>have</span><a id="id325951533" class="indexterm"></a> had in the past. For example, if you know how to drive a bicycle, you can extend the same knowledge to drive a motorcycle, or drive a car. The <span>driving</span><a id="id325951523" class="indexterm"></a> rule remains the same—the only thing that changes is the control panel and actuators. However, in deep learning, we often start afresh. Is it possible to use the knowledge the model has gained in solving a problem in one domain, to solve the problem in another related domain? </p><p>Yes, it's indeed possible, and it's called transfer learning. Though a lot of research is still going on in the field, a great deal of success has been achieved in applying <span>transfer</span><a id="id325951302" class="indexterm"></a> learning in the area of computer vision. This is due to the fact that for computer vision tasks <span class="strong"><strong>Convolutional Neural Networks</strong></span> (<span class="strong"><strong>CNNs</strong></span>) are preferred since they are good in extracting features from the image (features such as lines, circles, and squares, at lower layers, and higher abstract features such as ears and nose at the higher layers). Hence, the features extracted by convolutional layers while learning one type of image dataset can be reused in other similar domain images. This can help in reducing the training time.</p><p>In this section, we'll use Inception v3 (<a class="ulink" href="https://arxiv.org/pdf/1512.00567v1.pdf" target="_blank">https://arxiv.org/pdf/1512.00567v1.pdf</a>), a state-of-the-art CNN trained on the ImageNet dataset. ImageNet (<a class="ulink" href="http://image-net.org/" target="_blank">http://image-net.org/</a>) contains over 14 million labelled high-resolution hand-annotated images that have been classified into 22,000 categories. Inception v3 was trained on a subset of it consisting of about 1.3 million images with 1,000 categories. </p><p>In the transfer learning approach, you keep the feature extractor CNN layers but replace the classifier layers with a new classifier. This new classifier is then trained on the new images. Two approaches are generally followed: either we only train the new classifier or we fine-tune the entire network. In the first case, we extract the <span>features</span><a id="id325951274" class="indexterm"></a> from our new dataset, called <span class="strong"><strong>bottleneck features</strong></span>, by feeding the new dataset into CNN layers. The extracted bottleneck features are then used to train the final classifier. In the second case, we train the entire network, the original CNN, along with the new classifier on the training dataset. </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec48"></a>Understanding the Sparkdl interface </h3></div></div></div><p>To access Spark functionality in the <span>deep</span><a id="id325610512" class="indexterm"></a> learning pipeline, we need to use a Spark driver program. From Spark 2.0.0, we have a single point entry using <code class="literal">SparkSession</code>. The simplest way to do this is by using <code class="literal">builder</code>:</p><pre class="programlisting">SparkSession.builder().getOrCreate()</pre><p>This can allow us to get an existing session or create a new session. At the time of instantiation, we can use the <code class="literal">.config()</code>, <code class="literal">.master()</code>, and <code class="literal">.appName()</code> methods to set configuration options, set the Spark master, and set the application name.</p><p>To read and manipulate images, Sparkdl provides the <code class="literal">ImageSchema</code> class. Out of its many methods, we'll be using the <code class="literal">readImages</code> method to read the directory of images. It returns a Spark DataFrame with a single column – <code class="literal">image</code>, of images. </p><p>We can add or remove column/rows from the Spark DataFrames using transformations. The example code in this section uses the <code class="literal">withColumn</code> transformation to add a column named <code class="literal">label</code> and assign label classes to our dataset. Just like with a pandas Dataframe, we can view the rows of the Spark DataFrame with the help of the <code class="literal">show()</code> method. The Spark DataFrames can also be split or combined together.</p><p>The Sparkdl API has methods to <span>enable</span><a id="id325617664" class="indexterm"></a> fast transfer learning. It provides the <code class="literal">DeepImageFeaturizer</code> class, which automatically peels the classifier layer from the pre-trained model and uses the features (bottleneck features) from the pre-trained CNN layers as an input to the new classifier. </p><p>One advantage of working with Sparkdl is that we can access all of the Spark APIs—even its machine learning API MLlib from the same <code class="literal">SparkSession</code> instance. Using MLlib, we can easily combine multiple algorithms into a single a pipeline. The Spark machine learning API MLlib also provides support for various classification and regression methods. </p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl2sec49"></a>Building an object detection model</h3></div></div></div><p>We'll now make some <span>code</span><a id="id325617688" class="indexterm"></a> by using TFoS and Sparkdl. The dataset consists of images of buses and cars that have been curated from a Google image search. The aim is to train a model so that it can differentiate between cars and buses. The following is a list of prerequisites that you will need for this code to work:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">PySpark</li><li style="list-style-type: disc">Python</li><li style="list-style-type: disc">TensorFlow</li><li style="list-style-type: disc">TensorFlowOnSpark</li><li style="list-style-type: disc">Pillow</li><li style="list-style-type: disc">Keras</li><li style="list-style-type: disc">TensorFrames
</li><li style="list-style-type: disc">Wrapt</li><li style="list-style-type: disc">pandas</li><li style="list-style-type: disc">FindSpark</li><li style="list-style-type: disc">py4j</li></ul></div><p>First, let's explore our dataset. Inception v3 was trained on ImageNet data with 1,000 categories. These included <span>images</span><a id="id325748253" class="indexterm"></a> of various vehicles as well. We have 49 images for buses and 41 images of cars. Here, you can see the sample images from the dataset:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/0c9b9d2d-9b35-49dd-bf11-a3479c2cfc0e.png" /></div><div class="mediaobject"><img src="/graphics/9781789132212/graphics/35246557-69c7-4b6c-b29e-b480685c4f75.png" /></div><p>Now, let's build the code:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>This time, we'll not be using <code class="literal">spark-submit</code>. Instead, we'll run the code like any standard Python code. Therefore, we'll define the location of spark driver and the Spark deep learning package in the code itself and <span>create</span><a id="id325909934" class="indexterm"></a> a Spark session using PySpark's <code class="literal">SparkSession</code> builder. One thing to keep in mind here is the memory allocated to the heap: Spark executor and Spark driver. The values should be based on your machine's specifications:</li></ol></div><pre class="programlisting">import findspark
findspark.init('/home/ubuntu/spark-2.4.0-bin-hadoop2.7')

import os
SUBMIT_ARGS = "--packages databricks:spark-deep-learning:1.3.0-spark2.4-s_2.11 pyspark-shell"
os.environ["PYSPARK_SUBMIT_ARGS"] = SUBMIT_ARGS

from pyspark.sql import SparkSession
spark = SparkSession.builder \
    .appName("ImageClassification") \
    .config("spark.executor.memory", "70g") \
    .config("spark.driver.memory", "50g") \
    .config("spark.memory.offHeap.enabled",True) \
    .config("spark.memory.offHeap.size","16g") \
    .getOrCreate()</pre><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>The images are loaded in the Spark DataFrame using PySpark's <code class="literal">ImageSchema</code> class. The bus and cars images are loaded in different Spark DataFrames:</li></ol></div><pre class="programlisting">import pyspark.sql.functions as f
import sparkdl as dl
from pyspark.ml.image import ImageSchema

dfbuses = ImageSchema.readImages('buses/').withColumn('label', f.lit(0))
dfcars = ImageSchema.readImages('cars/').withColumn('label', f.lit(1))</pre><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>You can see the top five rows of the Spark DataFrame here:</li></ol></div><pre class="programlisting">dfbuses.show(5)
dfcars.show(5)</pre><p>The output of the preceding code is as follows:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/41f08c58-9cc2-4ffe-818b-6f3b28a5bc59.png" /></div><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>We split the dataset into <span>the</span><a id="id325910076" class="indexterm"></a> training-test datasets, with a ratio of 60% training and 40% test. Remember that these values are random and you can vary them accordingly:</li></ol></div><pre class="programlisting">trainDFbuses, testDFbuses = dfbuses.randomSplit([0.60,0.40], seed = 123)
trainDFcars, testDFcars = dfcars.randomSplit([0.60,0.40], seed = 122)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>The training dataset for buses and cars is combined. The same is done for the test dataset:</li></ol></div><pre class="programlisting">trainDF = trainDFbuses.unionAll(trainDFcars)
testDF = testDFbuses.unionAll(testDFcars)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>We use the Sparkdl API to get the pre-trained Inception v3 model and on top of the CNN layers of Inception, we add a logistic regressor. Now, we'll train <span>the</span><a id="id325910115" class="indexterm"></a> model on our dataset:</li></ol></div><pre class="programlisting">from pyspark.ml.classification import LogisticRegression
from pyspark.ml import Pipeline
vectorizer = dl.DeepImageFeaturizer(inputCol="image",
         outputCol="features", 
        modelName="InceptionV3")

logreg = LogisticRegression(maxIter=30, labelCol="label")
pipeline = Pipeline(stages=[vectorizer, logreg])
pipeline_model = pipeline.fit(trainDF)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="7" type="1"><li>Let's see how the trained model fairs on the test dataset. Let's use a perfect confusion matrix:</li></ol></div><pre class="programlisting">predictDF = pipeline_model.transform(testDF)
predictDF.select('prediction', 'label').show(n = testDF.toPandas().shape[0], truncate=False)
predictDF.crosstab('prediction', 'label').show()</pre><p>The output of the preceding code is as follows:</p><div class="mediaobject"><img src="/graphics/9781789132212/graphics/9b5c3862-364a-41a6-9773-b606eda0c693.png" /></div><div class="orderedlist"><ol class="orderedlist arabic" start="8" type="1"><li>For the test dataset, the model gives 100% accuracy:</li></ol></div><pre class="programlisting">from pyspark.ml.evaluation import MulticlassClassificationEvaluator
scoring = predictDF.select("prediction", "label")
accuracy_score = MulticlassClassificationEvaluator(metricName="accuracy")
rate = accuracy_score.evaluate(scoring)*100
print("accuracy: {}%" .format(round(rate,2)))</pre><p>Our model is giving such a good performance because the Inception v3 model that we have used as the base model for transfer learning has already been trained on a lot of vehicle images. A word of caution, however—100% accuracy doesn't mean it's the best model, just that it does well on the present test images.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note69"></a>Note</h3><p>Developed by DataBricks, Sparkdl is part of the Deep Learning Pipelines. They provide high-level APIs for scalable deep learning in Python with Apache Spark. You can learn more about its features and how to use it here: <a class="ulink" href="https://github.com/databricks/spark-deep-learning" target="_blank">https://github.com/databricks/spark-deep-learning</a>.</p></div></div></div>