<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch15lvl1sec115"></a>Limitations of deep learning</h2></div></div><hr /></div><p>In this project, almost all of the <span>projects</span><a id="id326012469" class="indexterm"></a> involved some sort of deep learning. Deep learning has been pivotal in powering most of the advances in the last few years. However, there are obvious limitations to deep learning that we should understand before applying them to real-world situations. Here are some of them:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Data-hungry</strong></span>: Usually, we don't have big datasets for every problem we want to solve using machine learning. On the contrary, deep learning algorithms only work when we have huge datasets for the problem.</li><li style="list-style-type: disc"><span class="strong"><strong>Compute intensive</strong></span>: Deep learning training usually requires GPU support and a huge amount of RAM. However, this makes it impossible to train deep neural networks on edge devices like mobiles and tablets.</li><li style="list-style-type: disc"><span class="strong"><strong>No prediction uncertainty</strong></span>: Deep learning algorithms are, by default, poor at representing uncertainty. Deep neural networks can confidently misclassify a cat image as that of a dog.</li></ul></div><p>There is no notion of confidence intervals or uncertainty in predictions. For applications like self-driving cars, it is very important to take uncertainty into account before making any decision. In this book, we touched on concepts like Bayesian neural networks, which are an attempt to incorporate uncertainty in deep neural networks.</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Uninterpretable blackÂ boxes</strong></span>: Deep learning models are hard to interpret and trust. For example, the loan department at a bank decides whether to give a loan to an individual based on their past purchases or credit history using a deep neural network.</li></ul></div><p>If the model denies the loan, the bank has to give an explanation to the individual regarding why their loan was denied. However, with deep neural networks, it is <span>almost</span><a id="id326012512" class="indexterm"></a> impossible to provide an explicit reason about why the loan was denied. Uninterpretability is a major reason why these models are not ubiquitous across different industries.</p></div>