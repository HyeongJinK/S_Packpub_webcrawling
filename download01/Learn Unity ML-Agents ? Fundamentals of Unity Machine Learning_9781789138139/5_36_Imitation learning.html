<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec40"></a>Imitation learning</h2></div></div><hr /></div><p>Imitation learning is a cool training <span>technique</span><a id="id324673281" class="indexterm"></a> that we can use to train agents by example. This has tremendous benefits in complex training scenarios with repetitive actions. Games like Pong or Tennis are very good candidates for this type of training since the game action is repetitive. Since the agent is learning by example, the need for random search actions or exploration is eliminated and training performance improves dramatically. Unity has a Tennis example that makes a good candidate to demonstrate this type of training. Let's jump to the next exercise where we set up imitation learning:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Open the <span class="strong"><strong>Tennis</strong></span> scene located in the <code class="literal">Assets/ML-Agents/Examples/Tennis</code> folder.</li><li>Locate the <span class="strong"><strong>Agent</strong></span> brain object in the <span class="strong"><strong>Hierarchy</strong></span>. Rename the object <code class="literal">Student</code>. Set the <span class="strong"><strong>Brain Type</strong></span> to <span class="strong"><strong>External</strong></span>.</li><li>Select the <span class="strong"><strong>Player</strong></span> brain object and rename it <code class="literal">Teacher</code>. Set the <span class="strong"><strong>Brain Type</strong></span> to <span class="strong"><strong>Player</strong></span> and make sure that the brain is set to <span class="strong"><strong>Broadcast</strong></span>, as shown in the following screenshot:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/b54fb42a-c7c1-47b0-a1f6-ad5a608415f8.png" /></div><p>Setting the Teach brain to Broadcast</p><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>Setting the <span class="strong"><strong>Teacher</strong></span> brain to <span class="strong"><strong>Broadcast</strong></span> allows the brain to communicate with the trainer. The brain will broadcast its observations and action space to the trainer, which allows the student brain to learn from the teacher's experiences.</li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>Locate the <code class="literal">AgentA</code> and <code class="literal">AgentB</code> objects <span>under</span><a id="id324988427" class="indexterm"></a> the <span class="strong"><strong>TennisArea</strong></span>. Select either agent and set its <span class="strong"><strong>Brain</strong></span> property to be the <span class="strong"><strong>Teacher</strong></span>, as shown in the following screenshot:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/4d03b2e6-ff70-4f97-8e27-cde0913180eb.png" /></div><p>Setting AgentA to use the Teacher (player) brain</p><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>The <span class="strong"><strong>Teacher</strong></span> is the brain, which you, the player, will use to teach the <span class="strong"><strong>Student</strong></span>.</li><li>Locate and select the <strong class="userinput"><code>Teacher</code></strong> brain again in the <strong class="userinput"><code>Hierarchy</code></strong> window. Then, in the <span class="strong"><strong>Inspector</strong></span> window, click the Add Component button at the bottom of the window. Search for the <strong class="userinput"><code>BC Teacher Helper component (Script)</code></strong> and add it to the object. This component will allow us to turn on/off imitation training using the <span class="strong"><strong>Record Key</strong></span> and <span class="strong"><strong>Reset</strong></span> experience with the <span class="strong"><strong>Reset Key</strong></span>, as shown in the following screenshot:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/b715d4d9-118b-4958-ab35-c4a759167976.png" /></div><p>Setting the BC Teacher Helper keys</p><div class="orderedlist"><ol class="orderedlist arabic" start="8" type="1"><li>From the menu, select <strong class="userinput"><code>File</code></strong> | <strong class="userinput"><code>Build Settings...</code></strong>. This will open the build settings dialog. Make sure to set the Tennis scene as the only open scene and click the <span class="strong"><strong>Build</strong></span> button.</li></ol></div><p>With the scene built into our Unity environment, we now need to configure the <code class="literal">trainer_config.yaml</code> file with the proper training configuration.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl2sec36"></a>Setting up a cloning behavior trainer</h3></div></div></div><p>The trainer we use when performing <span>Imitation Learning</span> is called <span class="strong"><strong>Behavioral Cloning</strong></span>. This trainer matches the <span class="strong"><strong>PPO</strong></span> trainer we have used many times before, but it is extended to take <span>observation</span><a id="id324673414" class="indexterm"></a> and action space input from a training or player brain. Fortunately, the configuration is quite similar and only <span>requires</span><a id="id324673424" class="indexterm"></a> some special customization. Follow this exercise to finish configuring the trainer and play the game:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Open the <code class="literal">trainer_config.yaml</code> file in Visual Studio Code or your favorite editor and add the following new section at the end of the file:</li></ol></div><pre class="programlisting">      Student:
trainer: imitation
max_steps: 10000
summary_freq: 1000
brain_to_imitate: Teacher
batch_size: 16
batches_per_epoch: 5
num_layers: 4
hidden_units: 64
use_recurrent: false
sequence_length: 16
buffer_size: 128</pre><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>The new section creates the configuration for our training brain, called <span class="strong"><strong>Student</strong></span>. Recall that this is the brain object we renamed to <span class="strong"><strong>Student</strong></span> earlier. We set the trainer to <span class="strong"><strong>imitation</strong></span> from <span class="strong"><strong>PPO</strong></span>, which is what we would normally set. The implementation of the imitation algorithm we are using is called Behavioral Cloning. <span class="strong"><strong>Behavioral Cloning</strong></span> is the simplest form of Imitation Learning, but as you will see it, works quit handily. Save the file when you are done editing it.</li><li>Open a Python or Anaconda prompt and activate <code class="literal">ml-agents</code> and navigate to the <code class="literal">'ml-agents'</code> folder.</li><li>Start the training session by entering the following trainer command:</li></ol></div><pre class="programlisting">      python python/learn.py python/python.exe --run-id=<span class="strong"><strong>tennis1</strong></span> --train 
<span class="strong"><strong>      --slow</strong></span></pre><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>Note the use of <code class="literal">--slow</code>. This allows the <span>training</span><a id="id324988490" class="indexterm"></a> to run in a manner that will allow us to interact with the actual environment.</li><li>As the environment starts, you will notice that the environment expands to a larger window and that you can control one of the agents. Use the <span class="strong"><strong>WASD</strong></span> keys to control the agent and see how well you can return the ball. As you play the game, you should notice that many of the same moves you do, the learning agent does as well. This is a really fun way to train an agent and it makes for a pretty good time-wasting game on its own.</li><li>You can use the <span class="strong"><strong>Reset Reward</strong></span> (<span class="strong"><strong>R key</strong></span>) or <span class="strong"><strong>Reset Experience</strong></span> (<span class="strong"><strong>C key</strong></span>) to enable/disable training and reset experience respectively. You will also see the following key shortcuts in the environment window:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/da0056d0-186c-4471-a746-6ef8b543b268.png" /></div><p>Using the Teacher brain (player) to teach the agent</p><div class="orderedlist"><ol class="orderedlist arabic" start="8" type="1"><li>You can try and reset the experience by pressing <span class="strong"><strong>C</strong></span> or disabling recording experiences by typing <span class="strong"><strong>R</strong></span>. Give them a try and see what effect these have on the agent.</li></ol></div><p>As you have just seen, Imitation Learning is certainly the most fun and engaging way to train an agent. This method of training also opens up potentially endless possibilities in training game agents or agents that need to perform some memorized or redundant set of tasks, be it in games or building something more complex. As we have seen, though, even making a game where a player teaches an agent is a possibility.</p><p>In the next section, we up our training game yet again to yet more complex tasks. This time, we will look at a form of stage or curriculum training that is perfect for training agents on especially difficult multi-stage tasks.</p></div></div>