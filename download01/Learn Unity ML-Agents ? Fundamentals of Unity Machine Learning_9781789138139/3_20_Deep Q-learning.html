<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec26"></a>Deep Q-learning</h2></div></div><hr /></div><p>Now that we understand some of the foundations of neural networks, it will be <span>really</span><a id="id324673344" class="indexterm"></a> helpful to look at a very basic example in Python that demonstrates their use. Go through the following steps to build a neural network that trains an agent with deep Q-learning. Windows users, make sure that you open an Anaconda prompt and switch to the <code class="literal">ml-agents</code> environment with <code class="literal">activate ml-agents</code>, as we did earlier.</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Open a command prompt or shell window to an empty folder and enter the following:</li></ol></div><pre class="programlisting"><span class="strong"><strong>git clone https://github.com/matthiasplappert/keras-rl.git
      cd keras-rl
      python setup.py install</strong></span></pre><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>This will install Keras RL, the reinforcement learning package for Keras. Keras is a popular library for building neural networks and other ML tasks. It can be backed by TensorFlow or Theano. Since we already have TensorFlow installed, we are good.</li><li>Enter the following:</li></ol></div><pre class="programlisting"><span class="strong"><strong>      pip install h5py
      pip install gym</strong></span></pre><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>The <code class="literal">h5py</code> code phrase is a Pythonic interface to the HDF5 format, and allows you to work with large numerical datasets. The next line installs <code class="literal">gym</code>, which is Python ML test environment.</li><li>Download and install Visual Studio Code. This will be our preferred Python editor, but feel free to use another IDE or editor of your preference if you are an experienced Python developer.</li></ol></div><p>This will install all the required dependencies we will need for our quick example. Next, we will look at writing the Python code to build the example.</p><p>There are hundreds of examples that demonstrate Q-learning with Keras that are available on the internet, but many of the examples are quite complex, or provide complex stats code. The example we will look at here has been chosen because it is succinct and works quickly. Feel free to explore many of the other examples on your own.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec23"></a>Building the deep network</h3></div></div></div><p>Normally, after introducing neural networks, we would <span>start</span><a id="id324988520" class="indexterm"></a> with a simple example of perhaps a single neuron or layer. However, that type of sample would be less than impressive, and is small fry compared to building a working deep Q-learning example. This means that in order to build a working example, we need to jump into the deep end, pun intended. Go through the following exercise to build the example:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Open Visual Studio Code, click <strong class="userinput"><code><strong class="userinput"><code>File</code></strong></code></strong> | <strong class="userinput"><code>New File</code></strong>, and create a new file named <code class="literal">DeepQLearning.py</code>.</li><li>This first part of the code imports the various libraries we need, enter the following code</li></ol></div><pre class="programlisting">      import numpy as np
      import gym

      from keras.models import Sequential
      from keras.layers import Dense, Activation, Flatten
      from keras.optimizers import Adam

      from rl.agents.dqn import DQNAgent
      from rl.policy import EpsGreedyQPolicy
      from rl.memory import SequentialMemory</pre><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>Then we set up some base variables with the following:</li></ol></div><pre class="programlisting">      ENV_NAME = 'CartPole-v0'

      env = gym.make(ENV_NAME)
      np.random.seed(123)
      env.seed(123)
      nb_actions = env.action_space.n</pre><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>We are going to use the cart–pole problem from the <code class="literal">gym</code> library, and this is why we set <code class="literal">ENV_NAME</code> to <code class="literal">CartPole-v0</code>. Then we create the <code class="literal">env</code> environment with <code class="literal">gym.make</code>. Once this is done, we create a random seed with a set seed value. This allows us to create a reproducible random sequence to allow us to reproduce results. </li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>Next, we build the neural network with the following:</li></ol></div><pre class="programlisting">      model = Sequential()
      model.add(Flatten(input_shape=(1,) + env.observation_space.shape))
      model.add(Dense(16))
      model.add(Activation('relu'))
      model.add(Dense(nb_actions))
      model.add(Activation('linear'))
      print(model.summary())</pre><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>We start by creating a sequential network. A sequential network is an ordered stack of layers not unlike the image of the neural network we saw earlier. To build a sequential network, we add layers of neurons that will be connected to each other. The first layer we add is the input layer that is flattened with <code class="literal">Flatten</code>, meaning that it creates an input layer of neurons corresponding to the number of observations. Next, we create a normal <code class="literal">Dense</code> layer with 16 neurons using a <code class="literal">relu</code> activation function. Finally, we finish with another <code class="literal">Dense</code> output layer with a <code class="literal">linear</code> activation function. 
The model we are building is defined by the tensor shape of our input. In this case, that shape is a simple 1 x 4 array of inputs. The inputs into the model will be the observed state of the agent, with the final output representing the optimum action for the observed state.</li><li>Save the file. The <code class="literal">relu</code>, or <code class="literal">ReLu</code>, activation <span>functions</span><a id="id324988634" class="indexterm"></a> and other details can be found online at the Keras documentation site.</li><li>Debug the sample by selecting <strong class="userinput"><code>Debug</code></strong> | <strong class="userinput"><code>Start Debugging </code></strong>from the menu. This will run the code we have so far, and should output a summary of the model (neural network), as shown in the following code:</li></ol></div><pre class="programlisting">      _________________________________________________________________
      Layer (type) Output Shape Param #
      =================================================================
      flatten_1 (Flatten) (None, 4) 0
      _________________________________________________________________
      dense_1 (Dense) (None, 16) 80
      _________________________________________________________________
      activation_1 (Activation) (None, 16) 0
      _________________________________________________________________
      dense_2 (Dense) (None, 2) 34
      _________________________________________________________________
      activation_2 (Activation) (None, 2) 0
      =================================================================
      Total params: 114
      Trainable params: 114
      Non-trainable params: 0
      _________________________________________________________________</pre><p>Take a look at the output and you will see that we have built a 4-input, 16-hidden-layer, and 2-output neural network. This is a very simple network that we are going to use to fit our Q-learning equation. This means we don't have to write our equation, since we are using the NN to essentially work as our equation solver.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec24"></a>Training the model</h3></div></div></div><p>In order for our neural network to fit our Q-learning equation, we need to train it iteratively, typically over thousands of iterations. We do this so that our model (network) can <span>gradually</span><a id="id324673444" class="indexterm"></a> fit the equation to our learning problem without getting stuck at a local minimum or maximum. The parameters we can adjust for training are numerous, and can be <span>complex, but don't worry. Go through</span> the following exercise to finish the sample and train the model:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Enter the following code just beneath the last section:</li></ol></div><pre class="programlisting">      policy = EpsGreedyQPolicy()
      memory = SequentialMemory(limit=50000, window_length=1)
      dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory,
      nb_steps_warmup=10,
      target_model_update=1e-2, policy=policy)
      dqn.compile(Adam(lr=1e-3), metrics=['mae'])
      dqn.fit(env, nb_steps=5000, visualize=True, verbose=2)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>We start by creating a policy of the <code class="literal">EpsGreedyQPolicy</code> type, which is just a variation of the epsilon greedy policy we have already been using. Next, we set up the memory using <code class="literal">SequentialMemory</code> with a limit of <code class="literal">50000</code>. This is where we will store the <span>agents'</span> observations of state for training. Next, we build a <code class="literal">DQNAgent</code> with the <code class="literal">nb_actions</code> <span>model's memory and policy</span>. This agent is essentially a brain (in Unity terms) that handles the input and training. 
Next, we compile the <code class="literal">dqn</code> with an Adam optimizer. Adam introduces a newer form of training rather than using the classic stochastic gradient descent. After that, we finish with a call to fit, which essentially runs the training on the <code class="literal">env </code>environment visually with <code class="literal">5000</code> steps.</li><li>Finish the script by entering the following:</li></ol></div><pre class="programlisting">      dqn.test(env, nb_episodes=5, visualize=True)</pre><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>This last line will test the agent/brain in the environment.</li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>Save the file.</li><li>Debug the script by clicking<strong class="userinput"><code>Debug</code></strong> | <strong class="userinput"><code>Start Debugging</code></strong>. After selecting the option in the menu, you may need to select your Python environment as well. As the script runs, you will see the<code class="literal">gym</code>environment displayed with the cart–pole problem running, as shown in the following screenshot:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/3b795c14-1e11-474c-9173-57a40aa832ef.png" /></div><p>The gym environment running the cart-pole problem with Keras DQN</p><div class="orderedlist"><ol class="orderedlist arabic" start="7" type="1"><li>As the script runs, you will see the training output.</li></ol></div><p>After the script runs, evaluate the results and determine if you need to increase the number of training runs or the network itself. Play around with the sample and see how you can improve on it.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec25"></a>Exploring the tensor</h3></div></div></div><p>One of the things about Python that turns developers away is the <span>loose</span><a id="id324673613" class="indexterm"></a> typing. It can also be difficult to debug applications without the right tools, or with the right tools that are loosely typed. This <span>gets</span><a id="id324673622" class="indexterm"></a> more complicated when we start to look at complex mathematical types, such as tensors, in code. Fortunately, Visual Studio Code provides a simple Python debugger that can expose type inspection at runtime. Let's see how this works by going through the following exercise:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Open Visual Studio Code back up to the last exercise.</li><li>Set a breakpoint by clicking just in the margin of the editor, as shown in the following image:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/4099dcda-9514-4b76-8d05-50692906d348.png" /></div><p>Setting a breakpoint in Visual Studio Code</p><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>From the menu, select <strong class="userinput"><code>Debug</code></strong> | <strong class="userinput"><code>Start Debugging</code></strong>. Let the code start and run. After the model is set up, the code will break at the set breakpoint.</li><li><p>Use your mouse to hover over the model text, as shown in the following screenshot:</p></li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/220b740c-e8ab-4f68-aa6a-efd4ab97cfe8.png" /></div><p>Inspecting the neural network model and tensor types</p><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>After a second or so, the type <strong class="userinput"><code>Inspector</code></strong> window will pop up, allowing you to inspect the various properties.</li><li>Click the arrow beside <code class="literal">input: &lt;Tensor&gt;</code> to expand the input property.</li><li>Expand the <code class="literal">_shape</code> property as well.</li><li>You should see an input shape of three dimensions of <code class="literal">0</code>, <code class="literal">1</code>, and <code class="literal">4</code> dimensions respectively. This also happens to represent the shape of the input tensor. In this case, the input tensor is a flat, 1 x 4 array of inputs, which you can also think of as a single-row matrix or vector. We can represent a single value as a (<code class="literal">0,1,1</code>) shape, or any dimension of values with a tensor.</li><li>You can continue to explore the NN model and other variables on your own in this way.</li></ol></div><p>Since the concept of a tensor as input can be quite confusing to newcomers, let's go over the concepts of tensors and tensor shapes. In the following diagram, we <span>show</span><a id="id324673859" class="indexterm"></a> a one-dimensional tensor that <span>represents</span><a id="id324673867" class="indexterm"></a> a single value all the way up to a six-dimensional tensor representing multiple values:</p><div class="mediaobject"><img src="/graphics/9781789138139/graphics/282ff77a-e103-4c45-9755-b8701fea5f19.png" /></div><p>
The many shapes of tensor</p><p>In our last example, the cart-pole problem, the tensor could be defined in multiple ways: as a 1D array; a 2D array/matrix of 1 x 4 or 4x1 values; as a 3D cube of (<code class="literal">0,1,4</code>) dimensions; and so on. The take-away from this is that we can represent any shape of data in the form of a tensor. You just have to make sure your data is in the correct shape; in fact, this will likely be your biggest issue when you go on to set up new networks on your own using Keras. </p><p>TensorFlow, our backend math engine, is of course named after the tensor. With most engines, you don't necessarily have to know how the internals work to use them, and TensorFlow is no exception. Therefore, we leave it up to the reader to further learn the internal workings of TensorFlow and Keras or other NN libraries on their own. Packt has numerous well-written books and videos on the subject.</p><p>There is a lot going on in this example, and hopefully you can appreciate the amount of work Keras is saving us. We chose this example because it featured the building of a model (network) without a lot of other plumbing. We won't explore any more of this example, but feel free to explore this code or other DQN agents more on your own. Fortunately for us, Unity has already taken care of mapping the observation of state and actions to the proper shapes. Going forward, we will use more of the advanced Unity Python code for building models, starting with proximal policy optimization in the next section.</p></div></div>