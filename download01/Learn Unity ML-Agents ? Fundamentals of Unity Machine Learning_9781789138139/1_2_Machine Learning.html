<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec10"></a>Machine Learning</h2></div></div><hr /></div><p>Games and simulations are no stranger to AI technologies and <span>there</span><a id="id325398024" class="indexterm"></a> are numerous assets available to the Unity developer in order to provide simulated machine intelligence. These technologies include content like Behavior Trees, Finite State Machine, navigation meshes, <code class="literal">A*</code>, and other heuristic ways game developers use to simulate intelligence. So, why Machine Learning and why now? After all, many of the base ML techniques, like neural nets, we will use later in this book have been used in games before. </p><p><span>The reason, is due in large part to the OpenAI initiative, an initiative that encourages research across academia and the industry to share ideas and research on AI and ML. This has resulted in an explosion of growth in new ideas, methods, and areas for research. </span>This means for games and simulations that we no longer have to fake or simulate intelligence. Now, we can build agents that learn from their environment and even learn to beat their human builders.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note5"></a>Note</h3><p>Machine Learning is an implementation of Artificial Intelligence. It is a way for a computer to assimilate data or state and provide a learned solution or response. We often think of AI now as a broader term to reflect a "smart" system. A full game AI system, for instance, may incorporate ML tools combined with more classic AIs like Behavior Trees in order to simulate a richer, more unpredictable AI. We will use AI to describe a system and ML to describe the implementation.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec4"></a>Training models</h3></div></div></div><p>Machine Learning is so aptly named because it uses various forms of <span>training</span><a id="id325398054" class="indexterm"></a> to analyze data or state and provide that trained response. These methods are worth mentioning and we will focus on one particular method of learning that is currently showing good success. Before we get to that though, for later chapters, let's breakdown the three types of training we frequently see in ML:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Unsupervised Training</strong></span>: This <span>method</span><a id="id325398071" class="indexterm"></a> of training examines a dataset on its own and performs a classification. The classification may be based on certain metrics and <span>can</span><a id="id325398080" class="indexterm"></a> be discovered by the training itself. Most people used to think that all AI or ML worked this way, but of course, it does not:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>ESRI</strong></span>, which is a major mapping <span>provider</span><a id="id325397686" class="indexterm"></a> of GIS software and data provides a demographic dataset called <span class="strong"><strong>Tapestry</strong></span>. This dataset is derived from a <span>combination</span><a id="id325397697" class="indexterm"></a> of US census data and other resources. It is processed through an ML algorithm that classifies the data into 68 consumer segments using Unsupervised Training. The Tapestry data is not free but can be invaluable for anyone building ML for a consumer or retail application.</li></ul></div></li><li style="list-style-type: disc"><span class="strong"><strong>Supervised Training</strong></span>: This is the typical training <span>method</span><a id="id325397708" class="indexterm"></a> most data science ML methods use to perform prediction or classification. It is a type of training that requires <span>input</span><a id="id325397718" class="indexterm"></a> and output data be labelled. As such, it requires a set of training data in order to build a model. Oftentimes, depending on the particular ML technique, it can require vast amounts of data:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Google Inception</strong></span> is an image <span>classification</span><a id="id325397733" class="indexterm"></a> ML model that is freely available. It has been trained by millions of images into various trained classifications. The Inception model is small enough to fit on a mobile device in order to provide real-time image classification.
</li></ul></div></li><li style="list-style-type: disc"><span class="strong"><strong>Reinforcement Learning</strong></span>: This is based on control theory and provides a <span>method</span><a id="id325397746" class="indexterm"></a> of learning without any initial state or model of the environment. This is a <span>powerful</span><a id="id325397754" class="indexterm"></a> concept because it eliminates the need to model the environment or undertake the tedious data labeling often required by Supervised Training. Instead, agents are modeled in the environment and receive rewards based on their actions. Of course, that also means that this advanced method of training is not without its pitfalls and frustrations. We will start learning the details of RL in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>The Bandit and Reinforcement Learning</em></span>:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>DeepMind</strong></span> built the bot that was able to play classic Atari 2600 games better than a human.</li></ul></div></li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Imitation Learning</strong></span>: This is a technique where <span>agents</span><a id="id325397788" class="indexterm"></a> are trained by watching a demonstration of the desired actions and then imitating them. This is a <span>powerful</span><a id="id325397797" class="indexterm"></a> technique and has plenty of applications. We will explore this type of <span>training in</span><a class="link" href="#" linkend="ch04">Chapter 4</a>, <span class="emphasis"><em>Going Deeper with Deep Learning</em></span>.</li><li style="list-style-type: disc"><span class="strong"><strong>Curriculum Learning</strong></span>: This is an advanced form of learning that works by breaking down a problem into levels of complexity, which allows the agent or ML to <span>overcome</span><a id="id325397825" class="indexterm"></a> each level of complexity before moving on to more advanced activities. For example, an agent waiter may <span>first</span><a id="id325397833" class="indexterm"></a> need to learn to balance a tray, then the tray with a plate of food, then walking with the tray and food, and finally delivering the food to a table. We will explore this form of training in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Playing the Game</em></span>.</li><li style="list-style-type: disc"><span class="strong"><strong>Deep Learning</strong></span>: This uses various forms of internal <span>training</span><a id="id325397853" class="indexterm"></a> mechanisms to train a multi-layer neural network. We will spend more <span>time</span><a id="id325397862" class="indexterm"></a> on neural <span>networks</span><a id="id325397868" class="indexterm"></a> and Deep Learning in <a class="link" href="#" linkend="ch03">Chapter 3</a>, <span class="emphasis"><em>Deep Reinforcement Learning with Python</em></span>.</li></ul></div><p>You may have already noticed the interchange of terms ML and agent use to denote the thing that is learning. It is helpful to think of things in these terms for now. Later in this chapter, we will start to distinguish the differences between an agent and their brain or ML. For now, though, let's get back to some basics and explore a simple ML example in the next section.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec5"></a>A Machine Learning example</h3></div></div></div><p>In order to demonstrate some of these concepts in a <span>practical</span><a id="id325397929" class="indexterm"></a> manner, let's look at an example scenario where we use ML to solve a game problem. In our game, we have a cannon that shoots a projectile at a specific velocity in a physics-based world. The object of the game is to choose the <strong class="userinput"><code>velocity</code></strong> to hit the target at a specific distance. We have already fired the cannon ten times and recorded the results in a table and chart, as shown in the following screenshot:</p><div class="mediaobject"><img src="/graphics/9781789138139/graphics/9ab0bf2f-342d-4d16-8efc-5d5a5fd45b2b.png" /></div><p>
Record and chart of cannon shots</p><p>Since the data is labelled already, this problem is well-suited for Supervised Training. We will use a very simple method called linear regression in order to give us a model that can predict a velocity in order to hit a target at a certain distance. Microsoft Excel provides a quick way for us to model linear regression on the chart by adding a trendline, as follows:</p><div class="mediaobject"><img src="/graphics/9781789138139/graphics/df5faaa6-b9da-4dc4-899b-a49775ebb49a.png" /></div><p>
Linear Regression applied with a trendline
</p><p>By using this simple feature in Excel, you can quickly analyze your data and see an equation that best fits that data. Now, this is a rudimentary example of data science, but hopefully you can appreciate how this can easily be used to predict complex environments just based on the data. While the linear regression model can provide us with an answer, it obviously is not very good and the R<sup>2 </sup>reflects that. The problem we have with our model is that we are using a linear model to try and solve a nonlinear problem. This is reflected with the arrows to the points, where the distance shows the amount of errors from the trendline. Our goal with any ML method will be to minimize the errors in order to find the solution of best fit. In most cases, that is all ML is, finding an equation that best predicts/classifies a value or action.</p><p>Getting back to our earlier question, we can now solve the velocity using some simple algebraic substitution, as shown in the following equation:</p><div class="mediaobject"><img src="/graphics/9781789138139/graphics/c92af205-6f54-48ef-8703-4d62ffb6c6d4.png" /></div><p>Where <span class="emphasis"><em>d</em></span> = distance and <span class="emphasis"><em>v</em></span> = velocity:</p><div class="mediaobject"><img src="/graphics/9781789138139/graphics/5b752f69-fadc-47a1-a2b4-47d432d1a5bd.png" /></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/a2a1fc3e-7f0d-4023-9060-824610511ddb.png" /></div><p>Our final answer would be an answer of <code class="literal">56.05</code>, but as we already mentioned, we may still miss, because our model is not entirely accurate. However, if you look at the graph, our errors appear to <span>minimize</span><a id="id325398120" class="indexterm"></a> around the distance of <code class="literal">300</code>. So, in our specific example, our model fits well. Looking closer at the graph, though, you can see that at a distance of around <code class="literal">100</code>, our error gets quite large and it is unlikely that we will hit our target. </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip6"></a>Note</h3><p><span class="emphasis"><em>R<sup>2</sup></em></span> or <span class="emphasis"><em>R</em></span> squared is an error value between <code class="literal">0</code> and <code class="literal">1</code>, with 1 being the highest or best fit. <span class="emphasis"><em>R<sup>2</sup></em></span> attempts to summarize the quality of fit. In some cases, it works well and in others there are other measures of fit that work better. We will use different measures of quality of fitness, but the concepts are similar.</p></div><p>The example we just looked at is quite simple and doesn't take into account many other factors, such as elevation differences or movement speed, and so on. If we wanted to add those inputs, we would just add more columns to our table. Each new column would expand our data space and consequently increase the complexity of the model. As you can quickly see, our model could quickly expand and become impractical. This is essentially the shortcomings the gaming industry already experienced using ML techniques at the turn of the century when implementing game AI. It is also a <span>shortcoming</span><a id="id325398163" class="indexterm"></a> that any other industry faces when implementing supervision-based models. That is the need to constantly re-sample and relabel data and consequently retrain models, which is why Reinforcement Learning and other methods of learning have become so significant. They provide a method of learning whereby autonomous agents or ML with no previous knowledge of an environment can successfully explore.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec6"></a>ML uses in gaming</h3></div></div></div><p>Unity has embraced the idea of incorporating ML into all <span>aspects</span><a id="id325398178" class="indexterm"></a> of its product and not just for use as a game AI. While most developers may try to use ML for gaming, it certainly helps game development in the following areas:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Map/Level Generation</strong></span>: There are already <span>plenty</span><a id="id325398195" class="indexterm"></a> of examples where developers have used ML to auto-generate everything from dungeons to realistic terrain. Getting this right can provide a game with endless replayability, but it can be some of the most challenging ML to develop.</li><li style="list-style-type: disc"><span class="strong"><strong>Texture/Shader Generation</strong></span>: Another area that is getting the attention of ML is texture and shader generation. These technologies are getting a boost brought on by the attention of advanced generative adversarial networks, or GAN. There are <span>plenty</span><a id="id325398209" class="indexterm"></a> of great and fun examples of this tech in action; just do a search for DEEP FAKES in your favorite search engine.</li><li style="list-style-type: disc"><span class="strong"><strong>Model Generation</strong></span>: There are a few <span>projects</span><a id="id325398225" class="indexterm"></a> coming to fruition in this area that could greatly simplify 3D object construction through enhanced scanning and/or auto-generation. Imagine being able to textually describe a simple model and having ML build it for you, in real-time, in a game or other <span class="emphasis"><em>AR</em></span>/VR/MR app, for example.</li><li style="list-style-type: disc"><span class="strong"><strong>Audio Generation</strong></span>: Being able to generate <span>audio</span><a id="id325398242" class="indexterm"></a> sound effects or music on the fly is already being worked on for other areas, not just games. Yet, just imagine being able to have a custom designed soundtrack for your game developed by ML.
</li></ul></div><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>Artificial Players</strong></span>: This encompasses <span>many</span><a id="id325398259" class="indexterm"></a> uses from the gamer themselves using ML to play the game on their behalf to the developer using artificial players as enhanced test agents or as a way to engage players during low activity. If your game is simple enough, this could also be a way of auto testing levels, for instance. We will explore an example of using ML to play a game in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Playing the Game</em></span>.</li><li style="list-style-type: disc"><span class="strong"><strong>NPCs or Game AI</strong></span>: Currently, there are <span>better</span><a id="id325398281" class="indexterm"></a> patterns out there to model basic behavioral intelligence in the form of Behavior Trees. While it's unlikely that BTs or other similar patterns will go away any time soon, imagine being able to model an NPC that may actually do an unpredictable, but rather cool behavior. This opens all sorts of possibilities that excite not only developers but players as well. We will look at ways of modeling behavioral patterns using ML in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Terrarium Revisited – Building A Multi-Agent Ecosystem</em></span>.</li></ul></div><p><span>Our interest in this book will be in the area of artificial players and the game AI, as it tends to be the most broad topic in scope. The reader is encouraged to search out the other areas mentioned in the preceding list on their own and as/when they relate to their own project.</span></p><p>It is highly recommended that you take a course, read a book, or <span>watch</span><a id="id325398341" class="indexterm"></a> a video on <span class="strong"><strong>Data Science</strong></span>. The area of data science deals primarily with Supervised and Unsupervised Training on ML against <span>known</span><a id="id325398354" class="indexterm"></a> datasets. However, you will or should learn data scrubbing, data labeling, the mathematics of ML, and calculating errors to name just a few important concepts. Having a background in Data Science will help you model problems as well as help you uncover possible issues when things don't work as expected.</p><p>That overview of ML certainly won't rival any Data Science course, but it should get us started for the rest of the good stuff starting in the next section, where we start looking at ML in action with Unity ML-Agents.</p></div></div>