<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec41"></a>Curriculum Learning</h2></div></div><hr /></div><p>As you get more comfortable building agent, you will start to <span>tackle</span><a id="id324673124" class="indexterm"></a> larger problems, which are so large that it often may be better to break the task down to levels of difficulty, not unlike a game. After the problem is decomposed, it can be tackled with Curriculum Learning. Curriculum Learning is where an agent learns a task in stages or levels that increase in difficulty. It really is not unlike the way we learn a task as humans, for example, walking; we first learn to roll, then crawl, stand, stagger, and then walk. We have intuitively learned how to walk this way, but our agent friends need a bit of help, at least for now.</p><p>Let's go back to Unity and look at an example that is mostly configured for Curriculum Learning, it just needs a bit of our help to complete the setup. Follow this exercise to set up a Curriculum Learning scenario:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Open the <code class="literal">WallJump</code> scene in the <code class="literal">Assets/ML-Agents/Examples/WallJump/Scenes</code> folder. If you have followed all the previous exercises, you will have now worked with all the Unity example scenes and you are certainly on your way to becoming an <span class="strong"><strong>RL</strong></span> master.</li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="2" type="1"><li>Select the <span class="strong"><strong>Academy</strong></span> object in the <span class="strong"><strong>Hierarchy</strong></span> and notice the <span class="strong"><strong>Reset Parameters</strong></span> under the <span class="strong"><strong>Wall Jump Academy</strong></span> component, as shown in the <span>following</span><a id="id324673451" class="indexterm"></a> screenshot:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/c9ac6121-13b7-41c0-a51a-13f6f65d46e2.png" /></div><p>Checking the Reset Parameters on the Academy object</p><div class="orderedlist"><ol class="orderedlist arabic" start="3" type="1"><li>We haven't worked with these parameters too much, but they are used to define various environment variables that may change from reset to reset. In <span class="strong"><strong>Curriculum Learning</strong></span>, we use these parameters as a way to define difficulty. In the current example, we have a parameter that defines the minimum wall height (<code class="literal">big_wall_min_height</code>) and maximum wall height (<code class="literal">big_well_max_height</code>). Our trainer will use these parameters to adjust the height of the wall during training.</li><li>Change the brain type to <strong class="userinput"><code>External</code></strong> on both the <strong class="userinput"><code>SmallWallBrain</code></strong> and <span class="strong"><strong><strong class="userinput"><code>BigWallBrain</code></strong></strong></span>. You should be able to do this in your sleep by now.</li><li>Build the environment for external training. Again, you should know this in your sleep.</li></ol></div><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>Open Visual Studio Code or your favorite text editor and create a new file called <code class="literal">curricula.json</code>. Save the file to the <code class="literal">python</code> folder.</li><li>Edit the <code class="literal">curricula.json</code> file with the following JSON:</li></ol></div><pre class="programlisting">      {
"measure" : "reward",
"thresholds" : [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],
"min_lesson_length" : 2,
"signal_smoothing" : true, 
"parameters" :  {
"big_wall_min_height" : [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 
          4.0, 4.5],
"big_wall_max_height" : [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 
          8.0, 8.5]
        }
      }</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip29"></a>Note</h3><p><span>JSON stands for JavaScript Object Notation. While its origins are JavaScript, the notation itself is now the standard for most configuration settings. If you are not familiar with the format, learn it.</span></p></div><div class="orderedlist"><ol class="orderedlist arabic" start="8" type="1"><li>In this configuration (JSON) file, we are defining several parameters, which are defined as follows:<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><code class="literal">measure</code>: Determines the process by which to measure success. The allow values are:
<div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>reward</strong></span>: Based on returned cumulative reward</li><li style="list-style-type: disc"><span class="strong"><strong>progress</strong></span>: How far an agent has undertaken a task</li></ul></div></li><li style="list-style-type: disc"><code class="literal">thresholds</code> (<code class="literal">array float</code>): Determines the points in value by which the lesson will be increased. Here, it is set to <code class="literal">.5</code> for all lessons.</li><li style="list-style-type: disc"><code class="literal">min_lesson_length</code> (<code class="literal">int</code>): Sets how many times the progress measure is reported before incrementing the lesson.
</li><li style="list-style-type: disc"><code class="literal">signal_smoothing</code> (<code class="literal">true</code>/<code class="literal">false</code>): If <code class="literal">true</code>, it uses a signal smoothing algorithm to blend new at <code class="literal">.75x</code> and old at <code class="literal">.25x</code> measures.</li><li style="list-style-type: disc"><code class="literal">parameters</code>: This is where we match up the <span class="strong"><strong>Reset Parameters</strong></span> in the <span class="strong"><strong>Academy</strong></span> with the ranges we want the agent to train against. You will notice how the value increases by .5 for the min and max heights of the wall. In our example, this means that the wall will get increasingly higher.</li></ul></div></li><li>Open a <span class="strong"><strong>Python</strong></span> or <span class="strong"><strong>Anaconda</strong></span> prompt and, well, you know the rest by now. Run the trainer with the following command on a single line:</li></ol></div><pre class="programlisting">      python python/learn.py python/python.exe --run-id=<span class="strong"><strong>walljump1</strong></span> --train 
      --slow                            
      --curriculum=python/curricula.json</pre><div class="orderedlist"><ol class="orderedlist arabic" start="10" type="1"><li>The new parameter we are using here is <code class="literal">--curriculum=</code>, which points to our previously configured training file. As the training session runs, you will see that the <span>agent</span><a id="id325402877" class="indexterm"></a> takes on taller and taller walls, as shown in the following screenshot:</li></ol></div><div class="mediaobject"><img src="/graphics/9781789138139/graphics/8d440e18-6efa-4cf8-bd50-b56d210e16a3.png" /></div><p>Curriculum training session running in an environment</p><p>As the agent runs, watch the prompt window as well. You will see the <span>agent</span><a id="id325402896" class="indexterm"></a> training on progressively higher and higher walls, just as the preceding excerpt shows. This form of training can be applied to all forms of situations, as we will see in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Terrarium Revisited – A Multi-Agent Ecosystem</em></span>, where we will use Curriculum Training to cycle through various training environments, for instance.</p></div>