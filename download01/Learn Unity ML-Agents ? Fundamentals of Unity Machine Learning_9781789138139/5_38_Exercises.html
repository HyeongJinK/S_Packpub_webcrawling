<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch05lvl1sec42"></a>Exercises</h2></div></div><hr /></div><p>This chapter tried to cover a lot of material, but did not provide many practical new examples. Be sure to try some of the following exercises to build on your already growing experience as an RL guru:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Return to the Banana Collectors and add several more agents using <span class="emphasis"><em>Ctrl + D</em></span> or (<span class="emphasis"><em>Command</em></span> + <span class="emphasis"><em>D</em></span> on macOS). How can you keep adding agents without the training scenario lagging or slowing down too much?</li><li>Convert the <strong class="userinput"><code>Soccor</code></strong> example to use Imitation Learning for one of the players. If you select the Goalie type, then set one Goalie player as a Teacher and one as a Student.</li><li>Convert the <strong class="userinput"><code>GridWorld</code></strong> example to use Imitation Learning. Create a new Teacher agent and convert the existing agent into a Student. We covered this example in some detail, so it will be a great comparison to the see the difference in training performance.</li><li>Expand on the <strong class="userinput"><code>WallJump</code></strong> example by adding additional training reset parameters. You could increase the difficultly by placing an agent farther and farther away from the wall, thus also making the agent first have to find the wall.</li><li>Convert the <strong class="userinput"><code>GridWorld</code></strong> example to use Curriculum Learning. You will need to create new reset parameters for the min/max values you want to set. You could increase the grid size and the number of obstacles, but decrease rewards to make more difficult training situations. See if you can best the current models.</li></ol></div><p>Even doing one or two exercises is better than none at all.</p></div>