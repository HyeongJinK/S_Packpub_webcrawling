<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec10"></a>AI techniques</h2></div></div><hr /></div><p>In this section, we'll walk <a id="id6" class="indexterm"></a>through some of the AI techniques being used in different types of games. We'll learn how to implement each of these features in Unity in the upcoming chapters. Since this book is not focused on AI techniques itself, but the implementation of those techniques inside Unity, we won't go into too much detail about these techniques here. So, let's just take it as a crash course, before actually going into implementation. If you want to learn more about AI for games, there are some really great books out there, such as <span class="emphasis"><em>Programming Game AI by Example</em></span> by <span class="emphasis"><em>Mat Buckland</em></span> and <span class="emphasis"><em>Artificial Intelligence for Games</em></span> by <span class="emphasis"><em>Ian Millington</em></span> and <span class="emphasis"><em>John Funge</em></span>. The <span class="emphasis"><em>AI Game Programming Wisdom</em></span> series also contain a lot of useful resources and articles on the latest AI techniques.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec08"></a>Finite State Machines (FSM)</h3></div></div></div><p><span class="strong"><strong>Finite State Machines</strong></span> (<span class="strong"><strong>FSM</strong></span>) can <a id="id7" class="indexterm"></a>be considered as one of the simplest AI model form, and are commonly used in the majority of games. A state machine basically consists of a finite number of states that are connected in a graph by the transitions between them. A game entity starts with an initial state, and then looks out for the events and rules that will trigger a transition to another state. A game entity can only be in exactly one state at any given time.</p><p>For example, let's take a look at an AI guard character in a typical shooting game. Its states could be as simple as patrolling, chasing, and shooting.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_01.jpg" /><div class="caption"><p>Simple FSM of an AI guard character</p></div></div><p>There are basically four <a id="id8" class="indexterm"></a>components in a simple FSM:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>States</strong></span>: This component <a id="id9" class="indexterm"></a>defines a set of states that a game <a id="id10" class="indexterm"></a>entity or an NPC can choose from (patrol, chase, and shoot)</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Transitions</strong></span>: This <a id="id11" class="indexterm"></a>component defines <a id="id12" class="indexterm"></a>relations between different states</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Rules</strong></span>: This component is <a id="id13" class="indexterm"></a>used to trigger a state <a id="id14" class="indexterm"></a>transition (player on sight, close enough to attack, and lost/killed player)</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Events</strong></span>: This is the <a id="id15" class="indexterm"></a>component, which will trigger to check <a id="id16" class="indexterm"></a>the rules (guard's visible area, distance with the player, and so on)</p></li></ul></div><p>So, a monster in Quake 2 might have the following states: standing, walking, running, dodging, attacking, idle, and searching.</p><p>FSMs are widely used in game AI especially, because they are really easy to implement and more than enough for both simple and somewhat complex games. Using simple <code class="literal">if/else</code> statements or switch statements, we can easily implement an FSM. It can get messy, as we start to have more states and more transitions. We'll look at how to manage a simple FSM in the next chapter.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec09"></a>Random and probability in AI</h3></div></div></div><p>Imagine an enemy bot in an <a id="id17" class="indexterm"></a>FPS game that can always kill the player with a headshot, an opponent in a racing game that always chooses the best route, and overtakes without collision with any obstacle. Such a level of intelligence will make the game so difficult that it becomes almost impossible to win. On the other hand, imagine an AI enemy that always chooses the same route to follow, or tries to escape from the player. AI controlled entities behaving the same way every time the player encounters them, makes the game predictable and easy to win.</p><p>Both of the previous situations obviously affect the fun aspect of the game, and make the player feel like the game is not challenging or fair enough anymore. One way to fix this sort of perfect AI and stupid AI is to introduce some errors in their intelligence. In games, randomness and probabilities are applied in the decision making process of AI calculations. The following are the main situations when we would want to let our AI entities change a random decision:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Non-intentional</strong></span>: This situation is sometimes a game agent, or perhaps an NPC might need to make a decision randomly, just because it doesn't have enough information to make a perfect decision, and/or it doesn't really matter what decision it makes. Simply making a decision randomly and hoping for the best result is the way to go in such a situation.</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Intentional</strong></span>: This situation is for perfect AI and stupid AI. As we discussed in the previous examples, we will need to add some randomness purposely, just to make them more realistic, and also to match the difficulty level that the player is comfortable with. Such randomness and probability could be used for things such as hit probabilities, plus or minus random damage on top of base damage. Using randomness and probability we can add a sense of realistic uncertainty to our game and make our AI system somewhat unpredictable.</p></li></ul></div><p>We can also use probability to define different classes of AI characters. Let's look at the hero characters from <a id="id18" class="indexterm"></a>
<span class="strong"><strong>Defense of the Ancient</strong></span> (<span class="strong"><strong>DotA</strong></span>), which is a popular action <a id="id19" class="indexterm"></a>
<span class="strong"><strong>real-time strategy</strong></span> (<span class="strong"><strong>RTS</strong></span>) game mode of Warcraft III. There are three categories of heroes based on the three main attributes: strength, intelligence, and agility. Strength is the measure of the physical power of the hero, while intellect relates to how well the hero can control spells and magic. Agility defines a hero's ability to avoid attacks and attack quickly. An AI hero from the strength category will have the <a id="id20" class="indexterm"></a>ability to do more damage during close combat, while an intelligence hero will have more chance of success to score higher damage using spells and magic. Carefully balancing the randomness and probability between different classes and heroes, makes the game a lot more challenging, and makes DotA a lot fun to play.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec10"></a>The sensor system</h3></div></div></div><p>Our AI characters need to know about their surroundings, and the world they are interacting with, in order to make a <a id="id21" class="indexterm"></a>particular decision. Such information could be as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Position of the player</strong></span>: This information is used to decide whether to attack or chase, or keep patrolling</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Buildings and objects nearby</strong></span>: This information is used to hide or take cover</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Player's health and its own health</strong></span>: This remaining information is used to decide whether to retreat or advance</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Location of resources on the map in an RTS game</strong></span>: This information is used to occupy and collect resources, required for constructing and producing other units</p></li></ul></div><p>As you can see, it could vary a lot depending on the type of game we are trying to build. So, how do we collect that information?</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec01"></a>Polling</h4></div></div></div><p>One method to collect such information is <a id="id22" class="indexterm"></a>polling. We can simply do <code class="literal">if/else</code> or <code class="literal">switch</code> checks in the <code class="literal">FixedUpdate</code> method of our AI character. AI character just polls the information they are interested in from the game world, does the checks, and takes action accordingly. Polling methods works great, if there aren't too many things to check. However, some characters might not need to poll the world states every frame. Different characters might require different polling rates. So, usually in larger games with more complex AI systems, we need to deploy an event-driven method using a global messaging system.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl3sec02"></a>The messaging system</h4></div></div></div><p>AI does decision making in response <a id="id23" class="indexterm"></a>to the events in the world. The events are communicated between the AI entity and the player, the world, or the other AI entities through a messaging system. For example, when the player attacks an enemy unit from a group of patrol guards, the other AI units need to know about this incident as well, so that they can start searching for and attacking the player. If we were using the polling method, our AI entities will need to check the state of all the other AI entities, in order to know about this incident. But with an event-driven messaging system, we can implement this in a more manageable and scalable way. The AI characters interested in a particular event can be registered as listeners, and if that event happens, our messaging system will broadcast to all listeners. The AI entities can then proceed to take appropriate actions, or perform further checks.</p><p>The event-driven system does not necessarily provide faster mechanism than polling. But it provides a convenient, central checking system that senses the world and informs the interested AI agents, rather than each individual agent having to check the same event in every frame. In reality, both polling and messaging system are used together most of the time. For example, AI might poll for more detailed information when it receives an event from the messaging system.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec11"></a>Flocking, swarming, and herding</h3></div></div></div><p>Many living beings such as birds, fish, insects, and land animals perform certain operations such as moving, hunting, and foraging in groups. They stay and hunt in groups, because it makes them stronger and safer from predators than pursuing goals individually. So, let's say you want a group of birds flocking, swarming around in the sky; it'll cost too much time and effort for animators to design the movement and animations of each bird. But if we apply some simple rules for each bird to follow, we can achieve emergent intelligence of the whole group with complex, global behavior.</p><p>One pioneer of this concept is <span class="emphasis"><em>Craig Reynolds</em></span>, who presented such a flocking algorithm in his <span class="emphasis"><em>SIGGRAPH</em></span> paper, 1987, <span class="emphasis"><em>Flocks, Herds and Schools – A Distributed Behavioral Model</em></span>. He coined the term "boid" that sounds like "bird", but referring to a "bird-like" object. He proposed three simple rules to apply to each unit, which are as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p><span class="strong"><strong>Separation</strong></span>: This <a id="id24" class="indexterm"></a>rule is used to maintain a minimum distance with neighboring boids to avoid hitting them</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Alignment</strong></span>: This <a id="id25" class="indexterm"></a>rule is used to align itself with the average direction of its neighbors, and then move in the same velocity with them as a flock</p></li><li style="list-style-type: disc"><p><span class="strong"><strong>Cohesion</strong></span>: This step is <a id="id26" class="indexterm"></a>used to maintain a minimum distance with the group's center of mass</p></li></ul></div><p>These three simple rules are all that we need to implement a realistic and a fairly complex flocking behavior for birds. They can also be applied to group behaviors of any other entity type with little or no modifications. We'll examine how to implement such a flocking system in Unity in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Flocking</em></span>.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip02"></a>Tip</h3><p><span class="strong"><strong>Downloading the color images of this book</strong></span></p><p>We also provide you a PDF file that has color images of the screenshots/diagrams used in this book. The color images will help you better understand the changes in the output.You can download this file from: <a class="ulink" href="http://www.packtpub.com/sites/default/files/downloads/3400OT_ColoredImages.pdf" target="_blank">http://www.packtpub.com/sites/default/files/downloads/3400OT_ColoredImages.pdf</a></p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec12"></a>Path following and steering</h3></div></div></div><p>Sometimes we want our AI characters to roam around in the game world, following a roughly guided or thoroughly defined path. For example in a racing game, the AI opponents need to navigate on the road. And the decision-making algorithms such as our flocking boid algorithm discussed already, can only do well in making decisions. But in the end, it all comes down to dealing with actual movements and steering behaviors. Steering behaviors for AI characters have been in research topics for a couple of decades now. One notable paper in this field is <span class="emphasis"><em>Steering Behaviors for Autonomous Characters</em></span>, again by <span class="emphasis"><em>Craig Reynolds</em></span>, presented in 1999 at the <a id="id27" class="indexterm"></a>
<span class="strong"><strong>Game Developers</strong></span><a id="id28" class="indexterm"></a>
<span class="strong"><strong>Conference</strong></span> (<span class="strong"><strong>GDC</strong></span>). He categorized steering behaviors <a id="id29" class="indexterm"></a>into the following three layers:</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_02.jpg" /><div class="caption"><p>Hierarchy of motion behaviors</p></div></div><p>Let me quote the original example from his paper to understand these three layers:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>"Consider, for example, some cowboys tending a herd of cattle out on the range. A cow wanders away from the herd. The trail boss tells a cowboy to fetch the stray. The cowboy says "giddy-up" to his horse, and guides it to the cow, possibly avoiding obstacles along the way. In this example, the trail boss represents action selection, noticing that the state of the world has changed (a cow left the herd), and setting a goal (retrieve the stray). The steering level is represented by the cowboy who decomposes the goal into a series of simple sub goals (approach the cow, avoid obstacles, and retrieve the cow). A sub goal corresponds to a steering behavior for the cowboy-and-horse team. Using various control signals (vocal commands, spurs, and reins), the cowboy steers his horse towards the target. In general terms, these signals express concepts like go faster, go slower, turn right, turn left, and so on. The horse implements the locomotion level. Taking the cowboy's control signals as input, the horse moves in the indicated direction. This motion is the result of a complex interaction of the horse's visual perception, its sense of balance, and its muscles applying torques to the joints of its skeleton."</em></span></p></blockquote></div><p>Then he presented how to design and implement some common and simple steering behaviors for individual AI <a id="id30" class="indexterm"></a>characters and pairs. Such behaviors include seek and flee, pursue and evade, wander, arrival, obstacle avoidance, wall following, and path following. We'll implement some of those behaviors in Unity in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Path Following and Steering Behaviors</em></span>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec13"></a>A* pathfinding</h3></div></div></div><p>There are many games where you can find monsters or enemies that follow the player, or go to a particular point while <a id="id31" class="indexterm"></a>avoiding obstacles. For example, let's take a look at a typical RTS game. You can select a group of units and click a location where you want them to move or click on the enemy units to attack them. Your units then need to find a way to reach the goal without colliding with the obstacles. The enemy units also need to be able to do the same. Obstacles could be different for different units. For example, an air force unit might be able to pass over a mountain, while the ground or artillery units need to find a way around it.</p><p>A* (pronounced "A star") is a pathfinding algorithm widely used in games, because of its performance and accuracy. Let's take a look at an example to see how it works. Let's say we want our unit to move from point A to point B, but there's a wall in the way, and it can't go straight towards the target. So, it needs to find a way to point B while avoiding the wall.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_03.jpg" /><div class="caption"><p>Top-down view of our map</p></div></div><p>We are looking at a simple 2D example. But the same idea can be applied to 3D environments. In order to find the path from point A to point B, we need to know more about the map such as the position of <a id="id32" class="indexterm"></a>obstacles. For that we can split our whole map into small tiles, representing the whole map in a grid format, as shown in the following figure:</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_04.jpg" /><div class="caption"><p>Map represented in a 2D grid</p></div></div><p>The tiles can also be of other shapes such as hexagons and triangles. But we'll just use square tiles here, as that's quite simple and enough for our scenario. Representing the whole map in a grid, makes the search area more simplified, and this is an important step in pathfinding. We can now reference our map in a small 2D array.</p><p>Our map is now represented by a 5 x 5 grid of square tiles with a total of 25 tiles. We can start searching for the best path to reach the target. How do we do this? By calculating the movement score of each tile adjacent to the starting tile, which is a tile on the map not occupied by an obstacle, and then choosing the tile with the lowest cost.</p><p>There are four possible adjacent tiles <a id="id33" class="indexterm"></a>to the player, if we don't consider the diagonal movements. Now, we need to know two numbers to calculate the movement score for each of those tiles. Let's call them G and H, where G is the cost of movement from starting tile to current tile, and H is the cost to reach the target tile from current tile.</p><p>By adding G and H, we can get the final score of that tile; let's call it F. So we'll be using this formula: F = G + H.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_05.jpg" /><div class="caption"><p>Valid adjacent tiles</p></div></div><p>In this example, we'll be using a simple method called <a id="id34" class="indexterm"></a>
<span class="strong"><strong>Manhattan length</strong></span> (also known as Taxicab geometry), in which we just count the total number of tiles between the starting tile and the target tile to know the distance between them.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_06.jpg" /><div class="caption"><p>Calculating G</p></div></div><p>The preceding figure shows the calculations of G with two different paths. We just add one (which is the cost to move one tile) to the previous tile's G score to get the current G score of the current tile. We can <a id="id35" class="indexterm"></a>give different costs to different tiles. For example, we might want to give a higher movement cost for diagonal movements (if we are considering them), or to specific tiles occupied by, let's say a pond or a muddy road. Now we know how to get G. Let's look at the calculation of H. The following figure shows different H values from different starting tiles to the target tile. You can try counting the squares between them to understand how we get those values.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_07.jpg" /><div class="caption"><p>Calculating H</p></div></div><p>So, now we know how to get G and H. Let's go back to our original example to figure out the shortest path from A to B. We first choose the starting tile, and then determine the valid adjacent tiles, as shown in the following figure. Then we calculate the G and H scores of each tile, shown in the lower-left and right corners of the tile respectively. And then the final score F, which is G + H is shown at the top-left corner. Obviously, the tile to the <a id="id36" class="indexterm"></a>immediate right of the start tile has got the lowest F score.</p><p>So, we choose this tile as our next movement, and store the previous tile as its parent. This parent stuff will be useful later, when we trace back our final path.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_08.jpg" /><div class="caption"><p>Starting position</p></div></div><p>From the current tile, we do the similar process again, determining valid adjacent tiles. This time there are only two valid adjacent tiles at the top and bottom. The left tile is a starting tile, which we've already examined, and the obstacle occupies the right tile. We calculate the G, the H, and then the F score of those new adjacent tiles. This time we have four tiles on our map with all having the same score, six. So, which one do we choose? We can choose any of them. It <a id="id37" class="indexterm"></a>doesn't really matter in this example, because we'll eventually find the shortest path with whichever tile we choose, if they have the same score. Usually, we just choose the tile added most recently to our adjacent list. This is because later we'll be using some sort of data structure, such as a list to store those tiles that are being considered for the next move. So, accessing the tile most recently added to that list could be faster than searching through the list to reach a particular tile that was added previously.</p><p>In this demo, we'll just randomly choose the tile for our next test, just to prove that it can actually find the shortest path.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_09.jpg" /><div class="caption"><p>Second step</p></div></div><p>So, we choose this tile, which is <a id="id38" class="indexterm"></a>highlighted with a red border. Again we examine the adjacent tiles. In this step, there's only one new adjacent tile with a calculated F score of 8. So, the lowest score right now is still 6. We can choose any tile with the score 6.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_10.jpg" /><div class="caption"><p>Third step</p></div></div><p>So, we choose a tile randomly from all the tiles with the score 6. If we repeat this process until we reach our target tile, we'll <a id="id39" class="indexterm"></a>end up with a board complete with all the scores for each valid tile.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_11.jpg" /><div class="caption"><p>Reach target</p></div></div><p>Now all we have to do is to trace back starting from the target tile using its parent tile. This will give a path that looks something like the following figure:</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_12.jpg" /><div class="caption"><p>Path traced back</p></div></div><p>So this is the concept of A* pathfinding in a nutshell, without displaying any code. A* is an important concept in the AI pathfinding area, but since Unity 3.5, there are a couple of new features such as automatic navigation mesh generation and the Nav Mesh Agent, which we'll see roughly in the next section and then in more detail in <a class="link" href="#" linkend="ch08">Chapter 8</a>, <span class="emphasis"><em>Navigation Mesh</em></span>. These features make implementing <a id="id40" class="indexterm"></a>pathfinding in your games very much easier. In fact, you may not even need to know about A* to implement pathfinding for your AI characters. Nonetheless, knowing how the system is actually working behind the scenes will help you to become a solid AI programmer. Unfortunately, those advanced navigation features in Unity are only available in the Pro version at this moment.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec14"></a>A navigation mesh</h3></div></div></div><p>Now we have some idea of A* pathfinding techniques. One thing that you might notice is that using a simple grid in A* requires quite a <a id="id41" class="indexterm"></a>number of computations to get a path which is the shortest to the target, and at the same time avoids the obstacles. So, to make it cheaper and easier for AI characters to find a path, people came up with the idea of using waypoints as a guide to move AI characters from the start point to the target point. Let's say we want to move our AI character from point A to point B, and we've set up three waypoints as shown in the following figure:</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_13.jpg" /><div class="caption"><p>Waypoints</p></div></div><p>All we have to do now is to pick up the nearest waypoint, and then follow its connected node leading to the target waypoint. Most of the games use waypoints for pathfinding, because they are simple and quite effective in using less computation resources. However, they do have some issues. What if we <a id="id42" class="indexterm"></a>want to update the obstacles in our map? We'll also have to place waypoints for the updated map again, as shown in the following figure:</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_14.jpg" /><div class="caption"><p>New waypoints</p></div></div><p>Following each node to the target can mean the AI character moves in zigzag directions. Look at the preceding figures; it's quite likely that the AI character will collide with the wall where the path is close to the wall. If that happens, our AI will keep trying to go through the wall to reach the next target, but it won't be able to and it will get stuck there. Even though we can smooth out the zigzag path by transforming it to a spline and do some adjustments to avoid such obstacles, the problem is the waypoints don't give any information about the environment, other than the spline connected between two nodes. What if our smoothed and <a id="id43" class="indexterm"></a>adjusted path passes the edge of a cliff or a bridge? The new path might not be a safe path anymore. So, for our AI entities to be able to effectively traverse the whole level, we're going to need a tremendous number of waypoints, which will be really hard to implement and manage.</p><p>Let's look at a better solution, navigation mesh. A navigation mesh is another graph structure that can be used to represent our world, similar to the way we did with our square tile-based grid or waypoints graph.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_15.jpg" /><div class="caption"><p>Navigation mesh</p></div></div><p>A navigation mesh uses convex polygons to represent the areas in the map that an AI entity can travel. The most important benefit of using a navigation mesh is that it gives a lot more information about the environment than a waypoint system. Now we can adjust our path safely, because we know the safe region in which our AI entities can travel. Another advantage of using a navigation mesh is that we can use the same mesh for different types of AI entities. Different AI entities can have different properties such as size, speed, and movement abilities. A set of waypoints is tailored for human, AI may not work nicely for flying creatures or AI controlled <a id="id44" class="indexterm"></a>vehicles. Those might need different sets of waypoints. Using a navigation mesh can save a lot of time in such cases.</p><p>But generating a navigation mesh programmatically based on a scene, is a somewhat complicated process. Fortunately, Unity 3.5 introduced a built-in navigation mesh generator (Pro only feature). Since this is not a book on core AI techniques, we won't go too much into how to really generate and use such navigation meshes. Instead, we'll learn how to use Unity's navigation mesh for generating features to easily implement our AI pathfinding.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec15"></a>The behavior trees</h3></div></div></div><p>Behavior trees are the other <a id="id45" class="indexterm"></a>techniques used to represent and control the logic behind AI characters. They have become popular for the applications in AAA games such as Halo and Spore. Previously, we have briefly covered FSM. FSMs provide a very simple way to define the logic of an AI character, based on the different states and transitions between them. However, FSMs are considered difficult to scale and re-use existing logic. We need to add many states and hard-wire many transitions, in order to support all the scenarios, which we want our AI character to consider. So, we need a more scalable approach when dealing with large problems. behavior trees are a better way to implement AI game characters that could potentially become more and more complex.</p><p>The basic elements of behavior trees are tasks, where states are the main elements for FSMs. There are a few different tasks such as Sequence, Selector, and Parallel Decorator. This is quite confusing. The best way to understand this is to look at an example. Let's try to translate our example from the FSM section using a behavior tree. We can break all the transitions and states into tasks.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_16.jpg" /><div class="caption"><p>Tasks</p></div></div><p>Let's look at a Selector task for this Behavior tree. Selector tasks are represented with a circle and a question mark inside. First it'll choose to attack the player. If the Attack task returns success, the Selector task is <a id="id46" class="indexterm"></a>done and will go back to the parent node, if there is one. If the Attack task fails, it'll try the Chase task. If the Chase task fails, it'll try the Patrol task.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_17.jpg" /><div class="caption"><p>Selector task</p></div></div><p>What about the tests? They are also one of the tasks in the behavior trees. The following diagram shows the use of Sequence tasks, denoted by a rectangle with an arrow inside it. The root selector may choose the first Sequence action. This Sequence action's first task is to check whether the player character is close enough to attack. If this task succeeds, it'll proceed with the next task, which is to attack the player. If the Attack task also returns success, the whole sequence will return success, and the selector is done with this behavior, and will not continue with other Sequence tasks. If the Close enough to attack? task fails, then the Sequence action will not proceed to the Attack task, and will return a failed status to the parent selector task. Then the selector will choose the next task in the sequence, Lost or Killed Player?.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_18.jpg" /><div class="caption"><p>Sequence tasks</p></div></div><p>The other two common components are Parallel and Decorator. A Parallel task will execute all of its child tasks at the same time, while the Sequence and Selector tasks only execute their child tasks one by one. Decorator is another type of task that has only one child. It can change the behavior of its own child's tasks, which includes whether to run its child's task or not, how <a id="id47" class="indexterm"></a>many times it should run, and so on.</p><p>We'll study how to implement a basic behavior tree system in Unity <a class="link" href="#" linkend="ch09">Chapter 9</a>, <span class="emphasis"><em>Behavior Trees</em></span>. There's a free add-on for Unity called Behave in the Unity Asset Store. Behave is a useful, free GUI editor to set up behavior trees of AI characters, and we'll look at it in more detail later as well.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec16"></a>Locomotion</h3></div></div></div><p>Animals (including humans) have <a id="id48" class="indexterm"></a>a very complex musculoskeletal system (the locomotor system) that gives them the ability to move around the body using the muscular and skeletal systems. We know where to put our steps when climbing a ladder, stairs, or on uneven terrain, and we know how to balance our body to stabilize all the fancy poses we want to make. We can do all this using our bones, muscles, joints, and other tissues, collectively described as our locomotor system.</p><p>Now put that into our game development perspective. Let's say we've a human character who needs to walk on both even and uneven surfaces, or on small slopes, and we have only one animation for a "walk" cycle. With the lack of a locomotor system in our virtual character, this is how it would look:</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_19.jpg" /><div class="caption"><p>Climbing stair without locomotion</p></div></div><p>First we play the walk animation and advance the player forward. Now the character knows it's penetrating the surface. So, the collision detection system will pull the character up above the surface to prevent this penetration. This is how we usually set up the movement on an uneven surface. Even though it doesn't give a realistic look and feel, it does the job and is cheap to implement.</p><p>Let's take a look at how we really <a id="id49" class="indexterm"></a>walk up stairs. We put our step firmly on the staircase, and using this force we pull up the rest of our body for the next step. This is how we do it in real life with our advanced locomotor system. However, it's not so simple to implement this level of realism inside games. We'll need a lot of animations for different scenarios, which include climbing ladders, walking/running up stairs, and so on. So, only the large studios with a lot of animators could pull this off in the past, until we came up with an automated system.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_20.jpg" /><div class="caption"><p>With a locomotion system</p></div></div><p>Fortunately, Unity 3D has an extension that can do just that, which is a locomotion system.</p><div class="mediaobject"><img src="/graphics/9781849693400/graphics/3400_01_21.jpg" /><div class="caption"><p>Locomotion system Unity extension</p></div></div><p>This system can automatically blend our animated walk/run cycles, and adjust the movements of the bones in the legs to ensure that the feet step correctly on the ground. It can also adjust the original animations made for a specific speed and direction on any surface, arbitrary steps, and slopes. We'll <a id="id50" class="indexterm"></a>see how to use this locomotion system to apply realistic movement to our AI characters in a later chapter.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec17"></a>Dijkstra's algorithm</h3></div></div></div><p>The Dijkstra's algorithm, <a id="id51" class="indexterm"></a>named after professor <span class="emphasis"><em>Edsger Dijkstra</em></span>, who devised the algorithm, is one of the most famous algorithms for finding the shortest paths in a graph with non-negative edge path costs. The algorithm was originally designed to solve the shortest path problem in the context of mathematical graph theory. And it's designed to find all the shortest paths from a starting node to all the other nodes in the graph. Since most of the games only need the shortest path between one starting point and one target point, all the other paths generated or found by this algorithm are not really useful. We can stop the algorithm, once we find the shortest path from a single starting point to a target point. But still it'll try to find all the shortest paths from all the points it has visited. So, this algorithm is not efficient enough to be used in most games. And we won't be doing a Unity demo of Dijkstra's algorithm in this book as well.</p><p>However, Dijkstra's algorithm is an important algorithm for the games that require strategic AI that needs as much information as possible about the map to make tactical decisions. It has many <a id="id52" class="indexterm"></a>applications other than games, such as finding the shortest path in network routing protocols.</p></div></div>