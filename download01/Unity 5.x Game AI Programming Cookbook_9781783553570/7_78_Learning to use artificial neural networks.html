<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch07lvl1sec79"></a>Learning to use artificial neural networks</h2></div></div><hr /></div><p>Imagine a <a id="id354" class="indexterm"></a>way to make an enemy or game system emulate the way the brain works. That's how neural networks operate. They are based on a neuron, we call it <code class="literal">Perceptron</code>, and the sum of several neurons; its inputs and outputs are what makes a neural network.</p><p>In this recipe, we will learn how to build a neural system, starting from <code class="literal">Perceptron</code>, all the way to joining them in order to create a network.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec272"></a>Getting ready…</h3></div></div></div><p>We will need a data type for handling raw input; this is called <code class="literal">InputPerceptron</code>:</p><div class="informalexample"><pre class="programlisting">public class InputPerceptron
{
    public float input;
    public float weight;
}</pre></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec273"></a>How to do it…</h3></div></div></div><p>We will implement <a id="id355" class="indexterm"></a>two big classes. The first one is the implementation for the <code class="literal">Perceptron</code> data type, and the second one is the data type handling the neural network:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li><p>Implement a <code class="literal">Perceptron</code> class derived from the <code class="literal">InputPerceptron</code> class that was previously defined:</p><div class="informalexample"><pre class="programlisting">public class Perceptron : InputPerceptron
{
    public InputPerceptron[] inputList;
    public delegate float Threshold(float x);
    public Threshold threshold;
    public float state;
    public float error;    
}</pre></div></li><li><p>Implement the constructor for setting the number of inputs:</p><div class="informalexample"><pre class="programlisting">public Perceptron(int inputSize)
{
    inputList = new InputPerceptron[inputSize];
}</pre></div></li><li><p>Define the function for processing the inputs:</p><div class="informalexample"><pre class="programlisting">public void FeedForward()
{
    float sum = 0f;
    foreach (InputPerceptron i in inputList)
    {
        sum += i.input * i.weight;
    }
    state = threshold(sum);
}</pre></div></li><li><p>Implement the functions for adjusting weights:</p><div class="informalexample"><pre class="programlisting">public void AdjustWeights(float currentError)
{
    int i;
    for (i = 0; i &lt; inputList.Length; i++)
    {
        float deltaWeight;
        deltaWeight = currentError * inputList[i].weight * state;
        inputList[i].weight = deltaWeight;
        error = currentError;
    }
}</pre></div></li><li><p>Define a <a id="id356" class="indexterm"></a>function for funneling the weights with regard to the type of input:</p><div class="informalexample"><pre class="programlisting">public float GetIncomingWeight()
{
    foreach (InputPerceptron i in inputList)
    {
        if (i.GetType() == typeof(Perceptron))
            return i.weight;
    }
    return 0f;
}</pre></div></li><li><p>Create the class for handling the set of <code class="literal">Perceptron</code> as a network:</p><div class="informalexample"><pre class="programlisting">using UnityEngine;
using System.Collections;

public class MLPNetwork : MonoBehaviour
{
    public Perceptron[] inputPer;
    public Perceptron[] hiddenPer;
    public Perceptron[] outputPer;
}</pre></div></li><li><p>Implement the function for transmitting inputs from one end to the other of the neural network:</p><div class="informalexample"><pre class="programlisting">public void GenerateOutput(Perceptron[] inputs)
{
    int i;
    for (i = 0; i &lt; inputs.Length; i++)
        inputPer[i].state = inputs[i].input;
    
    for (i = 0; i &lt; hiddenPer.Length; i++)
        hiddenPer[i].FeedForward();
    
    for (i = 0; i &lt; outputPer.Length; i++)
        outputPer[i].FeedForward();
}</pre></div></li><li><p>Define the function for propelling the computation that actually emulates learning:</p><div class="informalexample"><pre class="programlisting">public void BackProp(Perceptron[] outputs)
{
    // next steps
}</pre></div></li><li><p>Traverse the <a id="id357" class="indexterm"></a>output layer for computing values:</p><div class="informalexample"><pre class="programlisting">int i;
for (i = 0; i &lt; outputPer.Length; i++)
{
    Perceptron p = outputPer[i];
    float state = p.state;
    float error = state * (1f - state);
    error *= outputs[i].state - state;
    p.AdjustWeights(error);
}</pre></div></li><li><p>Traverse the internal <code class="literal">Perceptron</code> layers, but the input layer:</p><div class="informalexample"><pre class="programlisting">for (i = 0; i &lt; hiddenPer.Length; i++)
{
    Perceptron p = outputPer[i];
    float state = p.state;
    float sum = 0f;
    for (i = 0; i &lt; outputs.Length; i++)
    {
        float incomingW = outputs[i].GetIncomingWeight();
        sum += incomingW * outputs[i].error;
        float error = state * (1f - state) * sum;
        p.AdjustWeights(error);
    }
}</pre></div></li><li><p>Implement a high-level function for ease of use:</p><div class="informalexample"><pre class="programlisting">public void Learn(
        Perceptron[] inputs,
        Perceptron[] outputs)
{
    GenerateOutput(inputs);
    BackProp(outputs);
}</pre></div></li></ol></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl2sec274"></a>How it works…</h3></div></div></div><p>We implemented two types of Perceptrons in order to define the ones that handle external input and the ones internally connected to each other. That's why the <span class="emphasis"><em>basic</em></span> Perceptron class derives from the latter category. The <code class="literal">FeedForward</code> function handles the inputs and irrigates them along the network. Finally, the function for back propagation is the one responsible for <a id="id358" class="indexterm"></a>adjusting the weights. This <span class="emphasis"><em>weight adjustment</em></span> is the emulation of learning.</p></div></div>