<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec24"></a>Basic sensory systems</h2></div></div><hr /></div><p>The AI sensory <a id="id80" class="indexterm"></a>systems emulate senses such as perspectives, sounds, and even scents to track and identify objects. In game AI sensory systems, the agents will have to examine the environment and check for such senses periodically, based on their particular interest.</p><p>The concept of a basic sensory system is that there will be two components: <code class="literal">Aspect</code> and <code class="literal">Sense</code>. Our AI characters will have senses, such as perception, smell, and touch. These senses will look out for specific aspects such as enemy and bandit. For example, you could have a patrol guard AI with a perception sense that's looking for other game objects with an enemy aspect, or it could be a zombie entity with a smell sense looking for other entities with an aspect defined as brain.</p><p>For our demo, this is basically what we are going to implement: a base interface called <code class="literal">Sense</code> that will be implemented by other custom senses. In this chapter, we'll implement perspective and touch senses. Perspective is what animals use to see the world around them. If our AI character sees an enemy, we want to be notified so that we can take some action. Likewise, with touch, when an enemy gets too close, we want to be able to sense that; almost as if our AI character can hear that the enemy is nearby. Then we'll write a minimal <code class="literal">Aspect</code> class that our senses will be looking for.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec18"></a>Cone of sight</h3></div></div></div><p>In the example <a id="id81" class="indexterm"></a>provided in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Finite State Machines and You</em></span>, we set up our agent to detect the player tank using line of sight, which is literally a line in the form of a raycast. A raycast is a feature in Unity that allows you to determine which objects are intersected by a line cast from a point toward a given direction. While this is a fairly efficient to handle visual detection in a simple way, it doesn't accurately model the way vision works for most entities. An alternative to using line of sight is using a cone-shaped field of vision. As the following figure illustrates, the field of vision is literally modeled using a cone shape. This can be in 2D or 3D, as appropriate for your type of game.</p><div class="mediaobject"><img src="/graphics/9781785288272/graphics/B04204_03_01.jpg" /></div><p>The preceding figure illustrates the concept of a cone of sight. In this case, beginning with the source, that is, the agent's eyes, the cone grows, but becomes less accurate with the distance, as represented by the fading color of the cone.</p><p>The actual <a id="id82" class="indexterm"></a>implementation of the cone can vary from a basic overlap test to a more complex realistic model, mimicking eyesight. In the simple implementation, it is only necessary to test whether an object overlaps with the cone of sight, ignoring distance or periphery. The complex implementation mimics eyesight more closely; as the cone widens away from the source, the field of vision grows, but the chance of getting to see things toward the edges of the cone diminishes compared to those near the center of the source.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec19"></a>Hearing, feeling, and smelling using spheres</h3></div></div></div><p>One very <a id="id83" class="indexterm"></a>simple, yet effective way of modeling sounds, touch, and smell is via the use of spheres. For sounds, for example, we imagine the center as being the source, and the loudness dissipating the farther from the center the listener is. Inversely, the listener can be modeled instead of, or in addition to, the source of the sound. The listener's hearing is represented with a sphere, and the sounds closest to the listener are more likely to be "heard". We can modify the size and position of the sphere relative to our agent to accommodate feeling and smelling.</p><p>The following figure visualizes our sphere and how our agent fits into the setup:</p><div class="mediaobject"><img src="/graphics/9781785288272/graphics/B04204_03_02.jpg" /></div><p>As with sight, the <a id="id84" class="indexterm"></a>probability of an agent registering the sensory event can be modified, based on the distance from the sensor or as a simple overlap event, where the sensory event is always detected as long as the source overlaps the sphere.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec20"></a>Expanding AI through omniscience</h3></div></div></div><p>Truth be told, omniscience is really a way to make your AI cheat. While your agent doesn't <a id="id85" class="indexterm"></a>necessarily know everything, it simply means that they can know anything. In some ways, this can seem like the antithesis to realism, but often the simple solution is the best solution. Allowing our agent access to seemingly hidden information about their surroundings or other entities in the game world can be a powerful tool to give it an extra layer of complexity.</p><p>In games, we tend to model abstract concepts using concrete values. For example, we may represent a player's health with a numeric value ranging from 0 to 100. Giving our agent access to this type of information allows it to make realistic decisions, even though having access to that information is not realistic. You can also think of omniscience as your agent being able to "use the force" or sense events in your game world without having to "physically" experience them.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec21"></a>Getting creative with sensing</h3></div></div></div><p>While these <a id="id86" class="indexterm"></a>are among the most basic ways an agent can see, hear, and perceive their environment, they are by no means the only ways to implement these senses. If your game calls for other types of sensing, feel free to combine these patterns together. Want to use a cylinder or a sphere to represent a field of vision? Go for it. Want to use boxes to represent the sense of smell? Sniff away!</p></div></div>