<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="09lvl1sec57"></a>Speech and phonemes</h2></div></div><hr /></div><p>As you have seen in the last section, we created a <span>character</span> lip sync demo driven by real-time microphone input. While the demo is fun to play, it starts to show what is possible, but it could hardly be mistaken for real speech. After all, we don't just flap our jaws when we speak. Speech and vocalization are a very complex process requiring a synchronization of your larynx, tongue, lips, and even teeth. So as much as we understand how to visualize sound, we will need to go a little further into understanding the key elements in our speech patterns in order to build a more authentic lip syncing simulation.</p><p>Animators have been performing realistic lip syncing for many years now, and there are plenty of well established practices for creating speech animation, which means we will be able to use some of those learning and best practices. However, real-time character lip syncing is unique in a few areas and certain practices are less well established. Fortunately, we can still use the basis for character lip sync animation and apply it for our purposes.</p><p>Years ago, animators realized that basic sounds of speech called <span>phonemes</span> (pronounced fo-neme) also equate to specific facial expressions. Here is a simple animators chart that shows the common phonemes and how they look when the speaker is speaking those sounds:</p><div class="mediaobject"><img src="/graphics/9781787286450/graphics/08799c80-0c17-4bd8-b006-9059065d9ecd.png" /></div><p>Animators, phoneme mouth chart
</p><p>Do a quick exercise and work through the chart making each of the sounds. Does your mouth look or feel the same as when you make each of those phonemes? Chances are they follow pretty close. Of course, there are several other phonemes (up to 44 and more) for all sorts of different sounds an English speaker could make. We won't be worrying about all those other phonemes, at least not for this demonstration, and the nine shown in the preceding chart will work just fine.</p><p>So at this point, you may be asking yourself how do we go from our signal processing and binning visualization code to controlling phonemes on the character? Well, that is the part that is going to require a little finesse on our part and what we will be doing won't be far from how an animator may do it. There are other real-time lip syncing tools out there, but they use speech recognition APIs to do the work of extracting phonemes. Our audio animation approach won't be perfect, but it will provide you with a character lip syncing tool that you can apply to other languages and speech patterns.</p><p>The first thing we need to do is to map the preceding <span>basic</span> speech phonemes to our audio visualization bins. Follow the instructions here to establish your vocal baseline:</p><div class="orderedlist"><ol class="orderedlist arabic" type="1"><li>Go to Unity and open and run the <code class="literal">Chapter_9_VoiceTest</code> scene.</li><li>Work through the table and vocalize each of the phonemes by speaking into the microphone loudly:<div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col /><col /><col /></colgroup><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>Phoneme</p></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>Sound</p></td><td style="border-bottom: 0.5pt solid ; "><p>Bins</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/084f31cd-2842-4230-ad19-a260eaad7d17.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>AAAAAH, A</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/082ba37d-5ec6-4359-867d-c8065a5b958a.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>EEE</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/084f31cd-2842-4230-ad19-a260eaad7d17.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>I</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/ae7811e4-c9b1-41c8-aa9d-7a7815678990.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>OH!</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/1dbe6f6b-248b-4bdd-a9a4-31ae7273f433.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>U AND W</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/579bbdbb-53c1-428b-9f46-ea35bd89fe5e.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>FUH, VUH</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/72bff0ba-e3ee-40cd-99cf-433a44ca9bc2.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>MMM, PEE, BEE</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/402901e9-cd6b-4cca-a44f-7d954c956d29.png" /></div></td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; "><p>LUH, LAH</p></td><td style="border-bottom: 0.5pt solid ; "><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr><tr><td style="border-right: 0.5pt solid ; "><div class="mediaobject"><img src="/graphics/9781787286450/graphics/63ca2642-1892-4658-a53e-5750864b0819.png" /></div></td><td style="border-right: 0.5pt solid ; "><p>ESS, SSSS, DEE, GEE, EEEEH</p></td><td style=""><p>[0][1][2][3][4][5][6][7][8][9][10][11][12][13][14][15]</p></td></tr></tbody></table></div></li><li>As you work through the table and make the sounds, extend the sounds and consult the <strong class="userinput"><code>Console</code></strong> window. If you are speaking loud enough into your microphone, you should be able to see at least one, two, three, or more bars. Here is a screenshot of how this will look in the <strong class="userinput"><code>Console</code></strong>:</li></ol></div><div class="mediaobject"><img src="/graphics/9781787286450/graphics/6066967e-baed-4b55-81d6-47b050d02781.png" /></div><p>Log output showing the currently activated bins when sounding out a phoneme
</p><div class="orderedlist"><ol class="orderedlist arabic" start="4" type="1"><li>Work through the table again but this <span>time</span> black out or mark the numbers that show up in the <strong class="userinput"><code>Console</code></strong> window. These will essentially be the corresponding bins that match the sound you make when speaking that phoneme. As long as you consistently get from 1-4 bin numbers for each phoneme you are doing well. If you get more than four bin numbers for each phoneme, you will need to turn up the <strong class="userinput"><code>Min Signal</code></strong> parameter on the <strong class="userinput"><code>Phoneme Controller</code></strong> component. This component is located on the <code class="literal">PhonemeController</code> game object. The object, component and parameters are shown in the screenshot of the <strong class="userinput"><code>Inspector</code></strong> window here:</li></ol></div><div class="mediaobject"><img src="/graphics/9781787286450/graphics/e3ecbc0d-fe4d-47ed-a097-3dbbfc4e3b75.png" /></div><p>Adjusting the Min Signal threshold parameter on the Phoneme Controller</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note149"></a>Note</h3><p>You may have already realized that the Visualizer in this scene is set up with 16 bins or visualization channels. This was required because using 10 bins would not provide enough distinction in audio binning. There would be just too much overlap in the phoneme sounds.</p></div><div class="orderedlist"><ol class="orderedlist arabic" start="5" type="1"><li>When you have filled in values for the table, stop the scene. If you notice that more than a couple of the phoneme entries in the table have the same bin range, then try adjusting the <strong class="userinput"><code>Min Signal</code></strong> parameter on the <strong class="userinput"><code>Phoneme</code></strong><strong class="userinput"><code>Controller</code></strong> to a larger value, as shown in the preceding screenshot. Be sure that you are also over vocalizing the phoneme so that you can extract distinct patterns. This may require a little trial and error on your part.</li></ol></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip150"></a>Note</h3><p>If you are having trouble identifying consistent bin ranges, then practice your vocalization and do your best to hold the note while simulating the phoneme. It may also be helpful too ask a friend to try and read the phonemes into the microphone while you watch the bin range response.</p></div><div class="orderedlist"><ol class="orderedlist arabic" start="6" type="1"><li>Locate the <span class="strong"><strong>iClone</strong></span> character prefab from the <code class="literal">{name}/prefab</code> folder in the <strong class="userinput"><code>Project</code></strong> window. This will be the same prefab you used to set up the last scene. Drag the prefab into the <strong class="userinput"><code>Hierarchy</code></strong> window and make sure to reset the <strong class="userinput"><code>Transform Position</code></strong> to <code class="literal">0</code><span class="strong"><strong>,</strong></span><code class="literal">0</code><span class="strong"><strong>,</strong></span><code class="literal">0</code>.</li><li>Expand the character's hierarchy <span>again</span> and locate the <strong class="userinput"><code>RL-G6_JawRoot</code></strong> transform just as you did in the last exercise. Use the <strong class="userinput"><code>Add Component</code></strong> button to find and add a <strong class="userinput"><code>Bone Animator</code></strong> component. Set the parameters of this component to the values shown in the screenshot here:</li></ol></div><div class="mediaobject"><img src="/graphics/9781787286450/graphics/5c6eeed2-414e-470c-a386-fa6f8ca62a50.png" /></div><p>Setting the parameters for the Bone Animator component
</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note151"></a>Note</h3><p>The <code class="literal">BoneAnimator</code> script is another generic variation of the <code class="literal">VisualTransformer</code> we used in the last exercise. The difference is that the <code class="literal">VisualTransformer</code> will fetch updates from the <code class="literal">VisualizeSoundManger</code>, whereas, the <strong class="userinput"><code>Bone Animator</code></strong> only updates itself based on the <strong class="userinput"><code>Signal</code></strong> set by another component.</p></div><div class="orderedlist"><ol class="orderedlist arabic" start="8" type="1"><li>When you are done editing, save the scene.</li></ol></div><p>Now that we have identified the sounds that match your basic phonemes and some other additional setup, we can start to use that information to update the real-time lip sync character animation. In the next section, we are going to use the bin ranges in controlling what phonemes we animate for our character.</p></div>