<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec25"></a>Draw Calls</h2></div></div><hr /></div><p>Before we discuss Static and Dynamic Batching independently, let's first understand the problems that they are<a id="id182" class="indexterm"></a> both trying to solve within the graphics pipeline. We will try to keep fairly light on the technicalities. We will explore this topic in greater detail in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Dynamic Graphics</em></span>.</p><p>The primary goal of these batching methods is to reduce the number of Draw Calls required to render all objects in the current view. At its most basic form, a <span class="strong"><strong>Draw Call</strong></span> is a request sent from the CPU to the GPU, asking it to draw an object. But, before a Draw Call can be requested, several important criteria need to be met. Firstly, mesh and texture data must be pushed from the CPU memory (RAM) into GPU memory (VRAM), which typically takes place during initialization of the Scene. Next, the CPU must prepare the GPU by configuring the options and rendering features that are needed to process the object that is the target of the Draw Call.</p><p>These communication tasks between the CPU and GPU take place through the underlying graphics API, which could be either DirectX or OpenGL depending on the platform we're targeting and certain graphics settings. These APIs feature many complex and interrelated settings, state variables, and datasets that can be configured, and the available features change enormously based on the hardware device we're operating on. The massive array of settings that can be configured before rendering a single object is often condensed into a single term known as the Render State. Until these Render State options are changed, the GPU will maintain the same Render State for all incoming objects and render them in a similar fashion.</p><p>Changing the<a id="id183" class="indexterm"></a> Render State can be a time-consuming process. We won't go too deeply into the particulars of this, but essentially the Render State is a collection of global variables that affect the entire graphics pipeline. Changing a global variable within a parallel system is much easier said than done. A lot of work must happen on the GPU to synchronize the outcome of these state changes, which often involves waiting for the current batch to finish. In a massively parallel system such as a GPU, a lot of valuable time can be lost waiting for one batch to finish before beginning the next. Things that can trigger this synchronization may include pushing a new texture into the GPU, changing a Shader, changing lighting information, shadows, transparency, and changing almost any setting we can think of.</p><p>Once the Render State has been configured, the CPU must decide what mesh to draw, what Material it should use, and where to draw the object based on its position, rotation, and scale (all represented within a single transform matrix). In order to keep the communication between CPU and GPU very dynamic, new requests are pushed into a Command Buffer. This is a buffered list, which the CPU sends instructions to, and which the GPU pulls from whenever it finishes the previous command. The Command Buffer behaves like a <a id="id184" class="indexterm"></a>First In First Out (FIFO) queue, and each time the GPU finishes one command, it pops the oldest command from the front of the queue, processes it, and repeats until the Command Buffer is empty.</p><p>Note that a new Draw Call does not necessarily mean that a new Render State must be configured. If two objects share the exact same Render State information, then the GPU can immediately begin rendering the new object since the same Render State is maintained after the last object was finished.</p><p>Because the rendering process requires two hardware components to work in tandem, it is very sensitive to bottlenecks, which could originate in one or both components. GPUs can render individual objects incredibly quickly, so if the CPU is spending too much time generating Draw <a id="id185" class="indexterm"></a>Call commands (or simply generating too many of them), then the GPU will wait for instructions more often than it is working. In this case, our application's graphics would be CPU-bound. We're spending more time waiting on the CPU to decide what to draw, than the GPU spends drawing it. Conversely, being GPU-bound means the Command Buffer fills up with requests as the GPU cannot process requests from the CPU quickly enough.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note14"></a>Note</h3><p>You will learn more about what it means to have rendering bottlenecks in either the CPU or GPU, and how to solve both cases, in <a class="link" href="#" linkend="ch06">Chapter 6</a>, <span class="emphasis"><em>Dynamic Graphics</em></span>.</p></div><p>Another component which can impede the speed of graphics activity in this chain of events is within the hardware driver. This component mediates commands coming through the graphics API, which can come from multiple sources such as our application, other applications, and even the Operating System itself (such as rendering the desktop). Because of this, using updated drivers can sometimes result in a fairly significant increase in performance!</p><p>Next-generation graphics APIs, such as Microsoft's DirectX 12, Apple's Metal, and the Kronos Group's Vulcan, all aim to reduce the overhead on the driver by simplifying and parallelizing certain tasks; particularly, how instructions are passed into the Command Buffer. Once these APIs become commonplace, we may be able to get away with using significantly more Draw Calls comfortably within our application. But until these APIs mature, we must treat our Draw Call consumption with a good deal of concern, in order to avoid becoming CPU-bound.</p></div>