<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch06lvl1sec30"></a>An overview of sensing</h2></div></div><hr /></div><p>A part of having<a id="id160" class="indexterm"></a> good game AI is having the AI characters react to other parts of the game in a realistic way. For example, let's say you have an AI character in a scene searching for something, such as the player to attack them or items to collect (as in the demo in this chapter). We could have a simple proximity check, for example, if the enemy is 10 units from the player, it starts attacking. However, what if the enemy wasn't looking in the direction of the player and wouldn't be able to see or hear the player in real life? Having the enemy attack then is very unrealistic. We need to be able to set up more realistic and configurable sensors for our AI.</p><p>To set up<a id="id161" class="indexterm"></a> senses for our characters, we will use RAIN's senses system. You might assume that we will use standard methods to query a scene in Unity, such as performing picking through Unity's ray casting methods. This works for simple cases, but <a id="id162" class="indexterm"></a>RAIN has several advanced features to configure sensors for more realism. The senses RAIN supports are seeing and hearing. They are defined as volumes attached to an object, and the AI might be able to sense objects only inside the volume. Not everything in the volume can be sensed because there might be additional restrictions such as not being able to see<a id="id163" class="indexterm"></a> through walls. A visualization illustrates this volume in the editor view to make configuring them easier. The following figure is based on the visualization of a sense in a RAIN AI:</p><div class="mediaobject"><img src="/graphics/9781783553556/graphics/3556OT_06_01.jpg" /></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note08"></a>Note</h3><p>The early versions of RAIN included additional senses, such as smell, with the idea that more senses meant more realism. However, adding more senses was confusing for users and was used only in rare cases, so they were cut from the current versions. If you need a sense such as smell for something like the ant demo we saw in <a class="link" href="#" linkend="ch05">Chapter 5</a>, <span class="emphasis"><em>Crowd Control</em></span>, try modifying how you use vision or hearing, such as using a visual for smell and have it on a layer not visible to players in game.</p></div><p>While setting up <a id="id164" class="indexterm"></a>characters to sense game objects in their environment, you might think that the AI system would automatically analyze everything in the scene (game objects and geometry) to determine what is sensed. This will work for small levels but as we've seen before, we run into the problem of scaling if we have a very large scene with many objects. Larger scenes will mostly have background items that our AI doesn't care about, and we will need a more complex system to analyze all the objects to be efficient. Typically, AI systems work using a simplified version of the level, for example, how pathfinding uses navigation meshes to find a path instead of using the geometry from the level directly because it is much more efficient. Similarly, our senses don't work on everything; for an object to be sensed, it needs to be tagged.</p><p>In RAIN, the AI characters we create have an <code class="literal">AIRig</code> object, but for items we want to detect in the scene, we add a RAIN <span class="strong"><strong>Entity</strong></span> component to them. The <span class="strong"><strong>RAIN</strong></span> menu in Unity has a <span class="strong"><strong>Create Entity</strong></span> option that is used to add an <span class="strong"><strong>Entity</strong></span> component. The tags that you can set on the entities are called<a id="id165" class="indexterm"></a> <span class="strong"><strong>aspects</strong></span>, and the two types of aspects correspond to our two sensor types: visual aspects and audio aspects. So, a typical workflow to make your <a id="id166" class="indexterm"></a>AI characters sense the environment is to put <span class="strong"><strong>Entity</strong></span> components on game objects to detect, add aspects to those entities with the different tags a sensor can detect, and create sensors on your AI characters. We will look at a demo of this, but first let's discuss sensors in detail.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec17"></a>Advanced visual sensor settings</h3></div></div></div><p>We've heard <a id="id167" class="indexterm"></a>stories of people setting up their sensors—especially visual ones—and starting the game, but nothing happens or it seems to work incorrectly. Configuring the senses' advanced settings can help avoid issues such as these and make development easier.</p><p>To see <a id="id168" class="indexterm"></a>visual sensor settings, add a RAIN AI to a game object and click on the eye icon, select <span class="strong"><strong>Visual Sensor</strong></span> from the <span class="strong"><strong>Add Sensor</strong></span> dropdown, and then click on the gear icon in the upper-right corner and select <span class="strong"><strong>Show Advanced Settings</strong></span>. The following screenshot shows the <span class="strong"><strong>Visual Sensor</strong></span> section in RAIN:</p><div class="mediaobject"><img src="/graphics/9781783553556/graphics/3556OT_06_02.jpg" /></div><p>Here are some of the<a id="id169" class="indexterm"></a> properties of the sensor:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="strong"><strong>Show Visual</strong></span> / <span class="strong"><strong>Sensor Color</strong></span>: These are used to show how the sensor will look in the Unity editor, not in the game.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Is Active</strong></span>: This flag determines whether the sensor is currently trying to sense aspects in the scene or whether it is disabled.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Sensor Name</strong></span>: This shows the name of the sensor. This is useful when using the sensor in behavior trees, which we will see in this chapter's demo.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Mount Point</strong></span>: This is the game object the sensor is attached to.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Horizontal Angle</strong></span> / <span class="strong"><strong>Vertical Angle</strong></span> / <span class="strong"><strong>Range</strong></span>: These three define the volume of the sense; nothing outside of it will be picked up. The visualization of the sense matches these dimensions. You will want to customize these settings for different characters in your game. Unexpected behavior can occur from setting these up incorrectly.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Require Line of Sight</strong></span>: This flag requires a line from the character to the aspect without intersecting other objects for the aspect to be seen. Without this flag, a character could appear to have X-Ray vision.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Can Detect Self</strong></span> / <span class="strong"><strong>Line of Sight Ignores Self</strong></span>: These flag if the sensor should ignore the AI character. This is important as it prevents a common problem. For example, we<a id="id170" class="indexterm"></a> can have several soldier characters with a soldier aspect and then add a soldier from a different team that attacks the other soldiers. However, the attacking soldier when sensing might pick up its own aspect and try to start attacking itself, and this is definitely not what we want.</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Line of Sight Mask</strong></span>: To further help control what can be seen, layer masks can be used. These work the same as Unity's ray casting masks.</p></li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl2sec18"></a>Advanced audio sensor settings</h3></div></div></div><p>The <a id="id171" class="indexterm"></a>properties for the audio sensor is similar to that of the visual sensor, except it doesn't have any line of sight properties and the volume of the sense is a radius and doesn't have vertical or horizontal angle limits. The important <a id="id172" class="indexterm"></a>properties are:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><p>
<span class="strong"><strong>Range</strong></span>: This specifies how far the sensor can detect</p></li><li style="list-style-type: disc"><p>
<span class="strong"><strong>Volume Threshold</strong></span>: When listening for aspects, this is the lowest volume that the sensor can hear</p></li></ul></div><p>Now that we understand all of our sensor options, let's start the demo.</p></div></div>