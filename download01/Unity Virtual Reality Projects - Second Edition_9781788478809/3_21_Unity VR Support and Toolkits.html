<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch03lvl1sec27"></a>Unity VR Support and Toolkits</h2></div></div><hr /></div><p>Generally, as a developer, you spend <span>your</span><a id="id325547516" class="indexterm"></a> time working on <span>your</span><a id="id325577500" class="indexterm"></a> project scene. As we did for the diorama in the previous chapter, you'll add objects, attach materials, write scripts, and so on. When you build and run your project, the scene is rendered on a VR device and responds in real time to head and hand motions. The following diagram summarizes this Unity system VR architecture:</p><div class="mediaobject"><img src="/graphics/9781788478809/graphics/b1717110-123e-4f3f-9dc8-a2f406a05fe0.png" /></div><p>Within your scene, you may include a camera rig and other higher-level toolkit prefabs and components. All device manufacturers provide toolkits that are tuned to their specific devices. At a minimum, this includes the Unity Camera component for rendering the VR scene. It probably also includes a whole suite of prefabs and components, some required and some optional, which really help you create interactive, responsive, and comfortable VR experiences. We will go into detail throughout this chapter on how to set up your scene with these specific devices.</p><p>Unity has a growing library of built-in classes and components to support VR—what they call <span class="emphasis"><em>XR</em></span>—and also to include augmented reality. Some are platform specific. But some are device independent. These include stereo rendering, input tracking, and audio spatializers, to name a few. For details, see the Unity Manual pages for <code class="literal">UnityEngine.XR</code> and <code class="literal">UnityEngine.SpatialTracking</code> (<a class="ulink" href="https://docs.unity3d.com/ScriptReference/30_search.html?q=xr" target="_blank">https://docs.unity3d.com/ScriptReference/30_search.html?q=xr</a>).</p><p>At the lower level, any Unity project that runs on VR must set up the <span class="strong"><strong>XR Player Settings</strong></span> with <span class="strong"><strong>Virtual Reality Supported</strong></span>, and identify the specific low-level SDK the application should be used to drive the VR device. We will go into detail throughout this chapter on how to set up your project for specific devices.</p><p>So, as you can see, Unity is sandwiched between the app-level toolkit components and the device-level SDK. It provides a device-independent glue between device-specific API, tools, and optimizations.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note23"></a>Note</h3><p>Strategically, the team at Unity Technologies is dedicated to delivering a unified development platform for 2D, 3D, VR, and AR games and apps. Important new components are under development at Unity (and may already be available by the time you read this book) including the VR Foundation Toolkit and new input system. These are not covered in this book.</p></div><p>Before jumping in, let's understand the possible ways to integrate our Unity project with virtual reality devices. Software for the integration of applications with VR hardware spans a spectrum, from built-in support and device-specific interfaces to device-independent and platform- independent ones. So, let's consider your options.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec30"></a>Unity's built-in VR support</h3></div></div></div><p>In general, your Unity project must <span>include</span><a id="id325577564" class="indexterm"></a> a camera object that can render stereoscopic views, one for each eye on the VR headset. Since Unity 5.1, support for VR headsets has been built into Unity for various devices across several platforms.</p><p>You can simply use a standard camera component, like the one attached to the default <code class="literal">Main Camera</code> when you create a new scene. As we'll see, you can have <strong class="userinput"><code>Virtual Reality Supported</code></strong> enabled in <strong class="userinput"><code>XR Player Settings</code></strong> for Unity to render stereoscopic camera views and run your project on a VR headset (HMD). In <strong class="userinput"><code>Player Settings</code></strong>, you then choose which specific virtual reality SDK(s) to use when the project is built. The SDK talks to the device runtime drivers and underlying hardware. Unity's support for VR devices is collected in the XR class, and is documented as follows:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>XR Settings</strong></span>: Global XR-related settings including a list of supported devices in the build, and eye textures for the loaded device. See <a class="ulink" href="https://docs.unity3d.com/ScriptReference/XR.XRSettings.html" target="_blank">https://docs.unity3d.com/ScriptReference/XR.XRSettings.html</a>.</li><li style="list-style-type: disc"><span class="strong"><strong>XR Device</strong></span>: Query the capabilities of the current device such as the refresh rate and tracking space type. See <a class="ulink" href="https://docs.unity3d.com/ScriptReference/XR.XRDevice.html" target="_blank">https://docs.unity3d.com/ScriptReference/XR.XRDevice.html</a>.</li><li style="list-style-type: disc"><span class="strong"><strong>XR Input Tracking</strong></span>: Access the VR positional tracking data including the position and rotation of individual <span class="emphasis"><em>nodes</em></span>. See <a class="ulink" href="https://docs.unity3d.com/ScriptReference/XR.InputTracking.html" target="_blank">https://docs.unity3d.com/ScriptReference/XR.InputTracking.html</a>.</li></ul></div><p>Input controller buttons, triggers, touchpads, and thumbsticks can also map generically to Unity's Input system. For example, the OpenVR hand controller mappings can be found here: <a class="ulink" href="https://docs.unity3d.com/Manual/OpenVRControllers.html" target="_blank">https://docs.unity3d.com/Manual/OpenVRControllers.html</a>.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec31"></a>Device-specific toolkits</h3></div></div></div><p>While built-in VR support may be sufficient to <span>get</span><a id="id325577672" class="indexterm"></a> started, you are advised to also install the device-specific Unity package provided by the manufacturer. The device-specific interface will provide prefab objects, lots of useful custom scripts, shaders, and other important optimizations that directly take advantage of the features of the underlying runtime and hardware. The toolkits ordinarily include example scenes, prefabs, components, and documentation to guide you. Toolkits include:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong><span>SteamVR Plugin</span></strong></span>: Steam's SteamVR toolkit (<a class="ulink" href="https://assetstore.unity.com/packages/tools/steamvr-plugin-32647" target="_blank">https://assetstore.unity.com/packages/tools/steamvr-plugin-32647</a>) was originally <span>released</span><a id="id325577697" class="indexterm"></a> for HTC VIVE only. It <span>now</span><a id="id325577705" class="indexterm"></a> has support for several VR devices and runtimes that have positional-tracked left and right-hand controllers. This includes Oculus Rift and <span>Windows Immersive MR</span>. You build your project using the OpenVR SDK and the final executable program will decide at runtime which type of hardware you have attached to your PC and run that app on that device. This way, you don't need different versions of your app for VIVE, Rift, and IMR devices.</li><li style="list-style-type: disc"><span class="strong"><strong>Oculus Integration Toolkit</strong></span>: The Oculus Integration <span>plugin</span><a id="id325577724" class="indexterm"></a> for Unity (<a class="ulink" href="https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022" target="_blank">https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022</a>) supports Oculus VR devices <span>including</span><a id="id325577772" class="indexterm"></a> Rift, GearVR, and GO. In addition to the Touch hand controllers, it supports Oculus Avatar, Spatial Audio, and <span>network Rooms</span> SDK.</li><li style="list-style-type: disc"><span class="strong"><strong>Windows Mixed Reality Toolkit</strong></span>: The Windows MRTK plugin (<a class="ulink" href="https://github.com/Microsoft/MixedRealityToolkit-Unity" target="_blank">https://github.com/Microsoft/MixedRealityToolkit-Unity</a>) supports VR and AR devices <span>in</span><a id="id325577797" class="indexterm"></a> the Windows 10 UWP Mixed Reality family, including <span>immersive</span><a id="id325577805" class="indexterm"></a> HMD (like those from Acer, HP, and others) as well as the wearable HoloLens augmented reality headset.</li><li style="list-style-type: disc"><span class="strong"><strong>Google VR SDK for Unity</strong></span>: The GVR SDK <span>for</span><a id="id325577819" class="indexterm"></a> Unity plugin (<a class="ulink" href="https://github.com/googlevr/gvr-unity-sdk/releases" target="_blank">https://github.com/googlevr/gvr-unity-sdk/releases</a>) provides support for user input, controllers, and rendering <span>for</span><a id="id325577867" class="indexterm"></a> both Google Daydream and simpler Google Cardboard environments.</li></ul></div><p>When you set up your VR projects in Unity, you will probably install one or more of these toolkits. We walk you through this later in this chapter.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec32"></a>Application toolkits</h3></div></div></div><p>If you require <span>more</span><a id="id325577884" class="indexterm"></a> device independence <span>plus</span><a id="id325577891" class="indexterm"></a> higher-level interactive features, consider the <span>open</span><a id="id325577899" class="indexterm"></a> source <span class="strong"><strong>Virtual Reality ToolKit</strong></span> (<span class="strong"><strong>VRTK</strong></span>) at <a class="ulink" href="https://assetstore.unity.com/packages/tools/vrtk-virtual-reality-toolkit-vr-toolkit-64131" target="_blank">https://assetstore.unity.com/packages/tools/vrtk-virtual-reality-toolkit-vr-toolkit-64131</a> and <span class="strong"><strong>NewtonVR</strong></span> (<a class="ulink" href="https://github.com/TomorrowTodayLabs/NewtonVR" target="_blank">https://github.com/TomorrowTodayLabs/NewtonVR</a>). These Unity plugins provide a framework <span>for</span><a id="id325577929" class="indexterm"></a> developing VR applications with support for multiple platforms, locomotion, interactions, and UI controls. NewtonVR focuses mostly on <span class="emphasis"><em>physics interactions</em></span>. VRTK is built on top of the Unity built-in VR support plus the device-specific prefabs, so it's not <span class="emphasis"><em>instead of</em></span> but is a wrapper on top of those SDKs.</p><p>It is worth mentioning at this point that Unity is working on its <span>own</span><a id="id325577947" class="indexterm"></a> toolkit, the <span class="strong"><strong>XR Foundation Toolkit</strong></span> (<span class="strong"><strong>XRFT</strong></span>) at <a class="ulink" href="https://blogs.unity3d.com/2017/02/28/updates-from-unitys-gdc-2017-keynote/)" target="_blank">https://blogs.unity3d.com/2017/02/28/updates-from-unitys-gdc-2017-keynote/</a> which will include:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Cross-platform controller input</li><li style="list-style-type: disc">Customizable physics systems</li><li style="list-style-type: disc">AR/VR-specific shaders and camera fades</li><li style="list-style-type: disc">Object snapping and building systems</li><li style="list-style-type: disc">Developer debugging and profiling tools</li><li style="list-style-type: disc">All major AR and VR hardware systems</li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec33"></a>Web and JavaScript-based VR</h3></div></div></div><p>Important JavaScript APIs are <span>being</span><a id="id325577992" class="indexterm"></a> built directly into major web browsers, including special builds of Firefox, Chrome, Microsoft Edge, and other browsers like <span>those</span><a id="id325578003" class="indexterm"></a> from Oculus and Samsung for GearVR.</p><p>WebVR, for example, is like <span class="strong"><strong>WebGL</strong></span> (the 2D and 3D graphics markup API for the web), adding VR rendering and hardware support. While Unity presently <span>has</span><a id="id325578019" class="indexterm"></a> support for WebGL, it does not support building VR apps for WebVR (yet). But we hope to see this happen one day soon.</p><p>The promise of Internet-based WebVR is exciting. The internet is the greatest content distribution system in the history of the world. The ability to build and distribute VR content just as easily as web pages will be revolutionary.</p><p>As we know, browsers run on just about any platform. So, if you target your game to WebVR or similar framework, you don't even need to know the user's operating system, let alone which VR hardware they're using! That's the idea anyway. Some of the tools and frameworks to watch include:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>WebVR</strong></span> (<a class="ulink" href="http://webvr.info/" target="_blank">http://webvr.info/</a>)</li><li style="list-style-type: disc"><span class="strong"><strong>A-Frame</strong></span> (<a class="ulink" href="https://aframe.io/" target="_blank">https://aframe.io/</a>)</li><li style="list-style-type: disc"><span class="strong"><strong>Primrose</strong></span> (<a class="ulink" href="https://www.primrosevr.com/" target="_blank">https://www.primrosevr.com/</a>)</li><li style="list-style-type: disc"><span class="strong"><strong>ReactVR</strong></span>(<a class="ulink" href="https://facebook.github.io/react-vr/" target="_blank">https://facebook.github.io/react-vr/</a>)</li></ul></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl2sec34"></a>3D worlds</h3></div></div></div><p>There are a number of third-party 3D world <span>platforms</span><a id="id325578080" class="indexterm"></a> that provide multi-user social experiences in shared virtual spaces. You can chat with other players, move between rooms through <span class="emphasis"><em>portals</em></span>, and even build complex interactions and games without having to be an expert. For <span>examples</span><a id="id325578091" class="indexterm"></a> of 3D virtual worlds, check out the following:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc"><span class="strong"><strong>VRChat</strong></span>: <a class="ulink" href="http://vrchat.net/" target="_blank">http://vrchat.net/</a></li><li style="list-style-type: disc"><span class="strong"><strong>AltspaceVR</strong></span>: <a class="ulink" href="http://altvr.com/" target="_blank">http://altvr.com/</a></li><li style="list-style-type: disc"><span class="strong"><strong>High Fidelity</strong></span>: <a class="ulink" href="https://highfidelity.com/" target="_blank">https://highfidelity.com/</a></li></ul></div><p>While these platforms may have their own tools for building rooms and interactions, in particular, VRChat lets you develop 3D spaces and avatars in Unity. Then you export them using their SDK and load them into VRChat for you and others to share the virtual spaces you created over the internet in a real-time social VR experience. We will explore this in <a class="link" href="#" linkend="ch12">Chapter 13</a>, <span class="emphasis"><em>Social VR Metaverse</em></span>.</p></div></div>