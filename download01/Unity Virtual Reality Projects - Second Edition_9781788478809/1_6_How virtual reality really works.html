<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec14"></a>How virtual reality really works</h2></div></div><hr /></div><p>So, what is it about VR that's got <span>everyone</span><a id="id325563576" class="indexterm"></a> so excited? With your headset on, you experience synthetic scenes. It appears 3D, it feels 3D, and maybe you even have a sense of actually being there inside the virtual world. The strikingly obvious thing is: VR looks and feels <span class="emphasis"><em>really cool!</em></span> But why?</p><p><span class="emphasis"><em>Immersion</em></span> and <span class="emphasis"><em>presence</em></span> are the two words used to describe the quality of a VR experience. The Holy Grail is to increase both to the point where it seems so real, you forget you're in a virtual world. <span class="emphasis"><em>Immersion</em></span> is the result of emulating the sensory input that your body receives (visual, auditory, motor, and so on). This can be explained technically. <span class="emphasis"><em>Presence</em></span> is the visceral feeling that you get being transported there—a deep emotional or intuitive feeling. You could say that immersion is the science of VR and presence is the art. And that, my friend, is cool.</p><p>A number of different technologies and techniques come together to make the VR experience work, which can be separated into two basic areas:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">3D viewing</li><li style="list-style-type: disc">Head-pose tracking</li></ul></div><p>In other words, displays and sensors, like those built into today's mobile devices, are a big reason why VR is possible and affordable today.</p><p>Suppose the VR system knows exactly where your head is positioned at any given moment in time. Suppose that it can immediately render and display the 3D scene for this precise viewpoint stereoscopically. Then, wherever and whenever you move, you'll see the virtual scene exactly as you should. You will have a nearly perfect visual VR experience. That's basically it. <span class="emphasis"><em>Ta-dah!</em></span></p><p>Well, not so fast. Literally.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec6"></a>Stereoscopic 3D viewing</h3></div></div></div><p>Split-screen stereography was discovered <span>not</span><a id="id325567592" class="indexterm"></a> long after the <span>invention</span><a id="id325567601" class="indexterm"></a> of photography, like the popular stereograph viewer from 1876 shown in the following picture (B.W. Kilborn &amp; Co, Littleton, New Hampshire; see <a class="ulink" href="http://en.wikipedia.org/wiki/Benjamin_W._Kilburn" target="_blank">http://en.wikipedia.org/wiki/Benjamin_W._Kilburn</a>). A stereo photograph has separate views for the left and right eyes, which are slightly offset to create parallax. This fools the brain into thinking that it's a truly three-dimensional view. The device contains separate lenses for each eye, which let you easily focus on the photo close up:</p><div class="mediaobject"><img src="/graphics/9781788478809/graphics/931dd1af-8a2a-49c5-8fe9-0ad2bb6e21c1.jpg" /></div><p>Similarly, rendering these side-by-side stereo views is the first job of the VR-enabled camera in Unity.</p><p>Let's say that you're wearing a VR headset and you're holding your head very still so that the image looks frozen. It still appears better than a simple stereograph. Why?</p><p>The old-fashioned stereograph has relatively small twin images rectangularly bound. When your eye is focused on the center of the view, the 3D effect is convincing, but you will see the boundaries of the view. Move your eyes around (even with your head still), and any remaining sense of immersion is totally lost. You're just an observer on the outside peering into a diorama.</p><p>Now, consider what a VR screen looks like without the headset (see the following screenshot):</p><div class="mediaobject"><img src="/graphics/9781788478809/graphics/e9405e3b-3665-4425-93bd-5869309de874.png" /></div><p>The first thing that you will notice is that each eye has a barrel-shaped view. Why is that? The headset lens is a very wide-angle lens. So, when <span>you</span><a id="id325572801" class="indexterm"></a> look through it, you have a nice wide field of view. In fact, it is so wide (and tall), it distorts the image (<span class="strong"><strong>pincushion effect</strong></span>). The graphics software SDK <span>does an inverse</span> of <span>that</span><a id="id325576979" class="indexterm"></a> distortion (<span class="strong"><strong>barrel distortion</strong></span>) so that it looks correct to us through the lenses. This is referred <span>to</span><a id="id325576989" class="indexterm"></a> as an <span class="strong"><strong>ocular distortion correction</strong></span>. The result is an apparent <span class="strong"><strong>field of view</strong></span> (<span class="strong"><strong>FOV</strong></span>) that is <span>wide</span><a id="id325577040" class="indexterm"></a> enough to include a lot more of your peripheral vision. For example, the Oculus Rift has a FOV of about 100 degrees. (We talk more about FOV in <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Using All 360 Degrees</em></span>.)</p><p>Also, of course, the <span>view</span><a id="id325577441" class="indexterm"></a> angle from each eye is slightly offset, comparable to the distance between your eyes or the <span class="strong"><strong>Inter Pupillary Distance</strong></span> (<span class="strong"><strong>IPD</strong></span>). IPD is used to calculate the parallax and can vary from one person to the next. (The Oculus <span>Configuration Utility</span> comes with a utility to measure and configure your IPD. Alternatively, you can ask your eye doctor for an accurate measurement.)</p><p>It might be less obvious, but if you look closer at the VR screen, you will see color separations, like you'd get from a color printer whose print head is not aligned properly. This is intentional. Light passing through a lens is refracted at different angles based on the wavelength of the light. Again, the rendering software <span>does an inverse</span> of the color separation so that it looks correct to us. This is referred <span>to</span><a id="id325577468" class="indexterm"></a> as a <span class="strong"><strong>chromatic aberration correction</strong></span>. It helps make the image look really crisp.</p><p>The resolution of the screen is also important to get a convincing view. If it's too low-res, you'll see the pixels, or what some refer to as a <span class="strong"><strong>screen-door effect</strong></span>. The pixel <span>width</span><a id="id325577486" class="indexterm"></a> and height of the display is an oft-quoted specification when comparing the HMDs, but the <span class="strong"><strong>pixels per inch</strong></span> (<span class="strong"><strong>PPI</strong></span>) value <span>may</span><a id="id325578035" class="indexterm"></a> be more important. Other innovations in display technology such as <span class="strong"><strong>pixel smearing</strong></span> and <span class="strong"><strong>foveated rendering</strong></span> (showing higher-resolution details exactly where the eyeball is looking) will also <span>help</span><a id="id325578050" class="indexterm"></a> reduce <span>the</span><a id="id325578056" class="indexterm"></a> screen-door effect.</p><p>When experiencing a 3D scene in VR, you must also <span>consider</span><a id="id325578065" class="indexterm"></a> the <span class="strong"><strong>frames per second</strong></span> (<span class="strong"><strong>FPS</strong></span>). If the FPS is too slow, the animation will look choppy. Things that affect FPS include the GPU performance and the complexity of the Unity scene (the number of polygons and lighting calculations), among other factors. <span class="emphasis"><em>This is compounded in VR because you need to draw the scene twice, once for each eye</em></span>. Technology innovations, such as GPUs optimized for VR, frame interpolation, and other techniques will improve the frame rates. For us, developers, performance-tuning techniques in Unity, such as those used by mobile game developers, can be applied in VR. (We will talk more about performance optimization in <a class="link" href="#" linkend="ch13">Chapter 13</a>, <span class="emphasis"><em>Optimizing for Performance and Comfort</em></span>.) These techniques and optics help make the 3D scene appear realistic.</p><p>Sound is also very important—more important than many people realize. VR should be experienced while wearing stereo headphones. In fact, when the audio is done well but the graphics are pretty crappy, you can still have a great experience. We see this a lot in TV and cinema. The same holds true in VR. Binaural audio gives each ear its own stereo <span class="emphasis"><em>view</em></span> of a sound source in such a way that your brain imagines its location in 3D space. No special listening devices are needed. Regular headphones will work (speakers will not). For example, put on your headphones and visit the <span class="emphasis"><em>Virtual Barber Shop</em></span> at <a class="ulink" href="http://www.youtube.com/watch?v=IUDTlvagjJA" target="_blank">https://www.youtube.com/watch?v=IUDTlvagjJA</a>. True 3D audio provides an even more realistic spatial audio rendering, where sounds bounce off nearby walls and can be occluded by obstacles in the scene to enhance the first-person experience and realism.</p><p>Lastly, the VR headset should fit your head and <span>face</span><a id="id325581624" class="indexterm"></a> comfortably so that it's easy to forget that you're wearing it, and it should block out light from the real environment around you.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec7"></a>Head tracking</h3></div></div></div><p>So, we have a nice 3D picture that is viewable <span>in</span><a id="id325581670" class="indexterm"></a> a comfortable VR headset with a wide field of view. If this was it and you moved your head, it'd feel like you had a diorama box stuck to your face. Move your head and the box moves along with it, and this is much like holding the antique <span>stereograph</span><a id="id325581678" class="indexterm"></a> device <span>or</span><a id="id325581685" class="indexterm"></a> the childhood<span class="strong"><strong>View-Master</strong></span>. Fortunately, VR is so much better.</p><p>The VR headset has a motion sensor (IMU) inside that detects spatial acceleration and rotation rates on all three axes, providing what's called the <span class="strong"><strong>six degrees of freedom</strong></span>. This is the same technology that is commonly found in mobile phones and some console <span>game</span><a id="id325577565" class="indexterm"></a> controllers. <span>Mounted on your headset, when you move your head</span>, the current viewpoint is calculated and used when the next frame's image is drawn. This is <span>referred</span><a id="id325577577" class="indexterm"></a> to as <span class="strong"><strong>motion detection</strong></span>.</p><p>The previous generation of mobile motion sensors was good enough for us to play mobile games on a phone, but for VR, it's not accurate enough. These inaccuracies (rounding errors) accumulate over time, as the sensor is sampled thousands of times per second and one may eventually lose track of where they were in the real world. This <span class="emphasis"><em>drift</em></span> was a major shortfall of the older, phone-based Google Cardboard VR. It could sense your head's motion, but it lost track of your head's orientation. The current generation of phones, such as Google Pixel and Samsung Galaxy, which conform to the Daydream specifications, have upgraded sensors.</p><p>High-end HMDs account for drift with a separate <span class="emphasis"><em>positional tracking</em></span> mechanism. The Oculus Rift does this with <span class="emphasis"><em><span>inside-out positional tracking</span></em></span>, where an array of (invisible) infrared LEDs on the HMD are read by an external optical sensor (infrared camera) to determine your position. You need to remain within the <span class="emphasis"><em>view</em></span> of the camera for the head tracking to work.</p><p>Alternatively, the Steam VR VIVE Lighthouse technology does outside-in positional tracking, where two or more dumb laser emitters are placed in the room (much like the lasers in a barcode reader at the grocery checkout), and an optical sensor on the headset reads the rays to determine your position.</p><p>Windows MR headsets use no external sensors or cameras. Rather, there are integrated cameras and sensors to perform spatial mapping of the local environment around you, in order to locate and track your position in the real-world 3D space.</p><p>Either way, the primary purpose is to accurately find the position of your head and other similarly equipped devices, such as handheld controllers.</p><p>Together, the position, tilt, and the forward direction of your head—or the <span class="emphasis"><em>head pose—</em></span>are used by the graphics software to redraw the 3D scene from this vantage point. Graphics engines such as Unity are really good at this.</p><p>Now, let's say that the screen is getting updated at 90 FPS, and you're moving your head. The software determines the head pose, renders the 3D view, and draws it on the HMD screen. However, you're still moving your head. So, by the time it's displayed, the image is a little out of date with respect to your current position. This is called <span class="strong"><strong>latency</strong></span>, and it can make you feel nauseous.</p><p>Motion sickness caused by latency in VR occurs when you're moving your head and your brain expects the world around you to change exactly in sync. Any perceptible delay can make you uncomfortable, to say the least.</p><p>Latency can be measured as the time from reading a motion sensor to rendering the corresponding image, or the <span class="emphasis"><em>sensor-to-pixel</em></span> delay. According to Oculus's John Carmack:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em><span>A total latency of 50 milliseconds will feel responsive, but still noticeable laggy. 20 milliseconds or less will provide the minimum level of latency deemed acceptable.</span></em></span></p></blockquote></div><p>There are a number of very clever strategies that can be used to implement latency compensation. The details are outside the scope of this book and inevitably will change as device manufacturers improve on the technology. One of these strategies is what Oculus <span>calls</span><a id="id325577644" class="indexterm"></a> the <span class="strong"><strong>timewarp</strong></span>, which tries to guess where your head will be by the time the rendering is done and uses that future head pose instead of the actual detected one. All of this is handled in the SDK, so as a Unity developer, you do not have to deal with it directly.</p><p>Meanwhile, as VR developers, we need to be aware of latency as well as the other causes of motion sickness. Latency can be reduced via the faster rendering of each frame (keeping the recommended FPS). This can be achieved by discouraging your head from moving too quickly and using other techniques to make yourself feel grounded and comfortable.</p><p>Another thing that the Rift does to improve head tracking and realism is that it uses a skeletal representation of the neck so that all the rotations that it receives are mapped more accurately to the head rotation. For example, looking down at your lap creates a small forward translation since it knows it's impossible to rotate one's head downwards on the spot.</p><p>Other than head tracking, stereography, and 3D audio, virtual <span>reality</span><a id="id325577661" class="indexterm"></a> experiences can be enhanced with body tracking, hand tracking (and gesture recognition), locomotion tracking (for example, VR treadmills), and controllers with haptic feedback. The goal of all of this is to increase your sense of <span>immersion</span><a id="id325577668" class="indexterm"></a> and presence in the virtual world.</p></div></div>