<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch13lvl1sec115"></a>Optimizing the rendering</h2></div></div><hr /></div><p>There are a number of important <span>performance</span><a id="id325552060" class="indexterm"></a> considerations that are specific to how Unity does its rendering. Some of these may be common for any graphics engine. Some recommendations may change as newer versions of Unity emerge, the technology advances, and algorithms get replaced.</p><p>There are many articles offering recommendations for which setting to use to optimize your VR apps, and it's not unusual for one's advice to contradict another's. Here are some good ones:</p><div class="itemizedlist"><ul type="bullet"><li style="list-style-type: disc">Use the <strong class="userinput"><code>Forward Rendering</code></strong> path. This is the default in <strong class="userinput"><code>Graphics Settings</code></strong>.</li><li style="list-style-type: disc">Use <code class="literal">4X</code><strong class="userinput"><code>MSAA</code></strong> (multi-sampling anti-aliasing). This is a low-cost anti-aliasing technique that helps remove jagged edges and shimmering effects in <strong class="userinput"><code>Quality Settings</code></strong>.</li><li style="list-style-type: disc">Use <strong class="userinput"><code>Single Pass Stereo Rendering</code></strong>. It performs efficient rendering of parallax perspective for each eye in a single pass in <strong class="userinput"><code>Player Settings</code></strong>. </li><li style="list-style-type: disc">Enable <strong class="userinput"><code>Static Batching</code></strong> and <strong class="userinput"><code>Dynamic Batching</code></strong> in <strong class="userinput"><code>Player Settings</code></strong>. These are discussed later.</li></ul></div><p>Note that some rendering settings are device- or platform-specific, and found in the <strong class="userinput"><code>Player Settings</code></strong> (<strong class="userinput"><code>Edit | Project Settings | Player</code></strong>). Others have been abstracted by Unity into project <strong class="userinput"><code>Quality Settings</code></strong> (<strong class="userinput"><code>Edit | Project Settings | Quality</code></strong>). Still others are in the <strong class="userinput"><code>Graphics Settings</code></strong> (<strong class="userinput"><code>Edit | Project Settings | Graphics</code></strong>).</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note141"></a>Note</h3><p>The phrase <span class="emphasis"><em>Player Settings</em></span> in Unity does not refer to the user (player) nor a first-person character (player rig). Rather it's referring to the platform executable that <span class="emphasis"><em>plays</em></span> your app. More like a media player, such as a video player that plays mp4s, the Unity <span class="emphasis"><em>player</em></span> runs your game after it has been compiled. The Player Settings configure the generated executable.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec197"></a>Life's a batch</h3></div></div></div><p>Perhaps, the biggest bang for the buck is a feature in Unity that groups <span>different</span><a id="id325572805" class="indexterm"></a> meshes into a single batch, which is then shoveled into the graphics hardware all at once. This is much faster than sending the meshes separately. Meshes are actually first compiled into an OpenGL vertex buffer object, or VBO, but that's a low-level detail of the rendering pipeline.</p><p>Each batch takes one draw call. Reducing the number of draw calls in a scene is more significant than the actual number of vertices or triangles. For mobile VR, for example, stay around 50 (up to 100) draw calls.</p><p>There are two types of batching, <span class="strong"><strong>static batching</strong></span> and <span class="strong"><strong>dynamic batching</strong></span><span class="emphasis"><em>,</em></span> enabled in <strong class="userinput"><code>Player Settings</code></strong>.</p><p>For <span>static</span><a id="id325577026" class="indexterm"></a> batching, simply mark the objects as <span>static</span><a id="id325577032" class="indexterm"></a> by checking off the <strong class="userinput"><code><span>Static</span><a id="id325577040" class="indexterm"></a></code></strong> checkbox in the Unity <strong class="userinput"><code>Inspector</code></strong> for each object in the scene. Marking an object static tells Unity that it will never move, animate, or scale. Unity will automatically batch together the meshes that share the same material into a single, large mesh.</p><p>The caveat here is meshes must share the same Material settings: the same texture, shader, shader parameters, and the material pointer object. How can this be? They're different objects! This can be done by combining multiple textures into a single macro-texture file or <strong class="userinput"><code>TextureAtlas</code></strong> and then UV-mapping as many models as will fit. It's a lot like a sprite image used for 2D and web graphics. There are third-party tools that help you build these.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note142"></a>Note</h3><p>A useful analytic tool for checking resources in your scene, including active textures, materials and meshes, is the Unity Resource Checker, found here: <a class="ulink" href="https://github.com/handcircus/Unity-Resource-Checker" target="_blank">https://github.com/handcircus/Unity-Resource-Checker</a>.</p></div><p>Dynamic batching is similar to <span>static</span><a id="id325577450" class="indexterm"></a> batching. For objects that are not marked <strong class="userinput"><code>Static</code></strong>, Unity will still try to batch them, albeit it will be a slower process since it needs to think about it frame by frame (the CPU cost). The shared Material requirement still holds, as well as other restrictions such as vertex count (less than 300 vertices) and uniform <strong class="userinput"><code>Transform Scale</code></strong> rules. (See <span><a class="ulink" href="http://docs.unity3d.com/Manual/DrawCallBatching.html" target="_blank">http://docs.unity3d.com/Manual/DrawCallBatching.html</a>.)</span></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="tip143"></a>Note</h3><p>When managing textures in scripts, use <code class="literal">Renderer.sharedMaterial</code> rather than <code class="literal">Renderer.material</code> to avoid creating duplicate materials. Objects receiving a duplicate material will opt out of the batch.</p></div><p>Currently, only <strong class="userinput"><code>Mesh Renderers</code></strong> and <strong class="userinput"><code>Particle Systems</code></strong> are batched. This means that skinned meshes, cloth, trail renderers, and other types of rendering components are not.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec198"></a>Multipass pixel filling</h3></div></div></div><p>Another concern in the rendering pipeline is sometimes <span>referred</span><a id="id325577707" class="indexterm"></a> to as the pixel fill-rate. If you think about it, the ultimate goal of rendering is to fill each pixel on the display device with the correct color value. If it has to paint any pixels more than once, that's more costly. For example, watch out for transparent particle effects, such as smoke, that touch many pixels with mostly transparent quads.</p><p>For VR, Unity paints into a frame buffer memory that is larger than the physical display dimensions, which is then post-processed for ocular distortion correction (barrel effect) and chromatic aberration correction (color separation), before getting tossed onto the HMD display. In fact, there may be multiple overlay buffers that get composited before the post-processing.</p><p>This multipass pixel filling is how some advanced renderers work, including lighting and material effects such as multiple lights, dynamic shadows, and transparency (<strong class="userinput"><code>Transparent</code></strong> and <strong class="userinput"><code>Fade Render</code></strong> modes) - the Unity Standard Shader as well. Basically, all the good stuff!</p><p>VBO batches with materials that require multipass pixel filling get submitted multiple times, thus increasing the net number of draw calls. Depending on your project, you may choose to either optimize the heck out of it and avoid multipass pixel filling altogether, or carefully curate the scenes with an understanding of what should have a high performance and what should have a high fidelity.</p><p>You can use <strong class="userinput"><code><span>Light</span><a id="id325577732" class="indexterm"></a> Probes</code></strong> to inexpensively simulate dynamic lighting of your dynamic objects. Light probes are baked cubemaps that store information about direct, indirect, and even emissive light at various points in your scene. As a dynamic object moves, it interpolates samples of the nearby light probes to approximate the lighting at that specific position. This is a cheap way of simulating realistic lighting on dynamic objects without using expensive real-time lights. (See <a class="ulink" href="http://docs.unity3d.com/Manual/LightProbes.html" target="_blank"><span>http://docs.unity3d.com/Manual/LightProbes.html</span></a>.)</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note144"></a>Note</h3><p>Unity 2018 introduces a new Scriptable Render Pipeline, providing a way of configuring and controlling rendering from C# scripts. Unity 2018 includes alternative built-in pipelines for lightweight rendering (such as for mobile and VR apps), and high definition rendering (such as for high fidelity physically based renders), and there's an opportunity for the community to build and share more. Use of these pipelines may supersede information and recommendations made here.</p></div></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch13lvl2sec199"></a>VR-optimized shaders</h3></div></div></div><p>Shaders are small programs that are <span>compiled</span><a id="id325577758" class="indexterm"></a> to run in the GPU. They process your 3D vectors and polygons (triangles), prepared by the game engine on the CPU, along with lighting information, texture maps, and other parameters, to generate pixels on the display. </p><p>Unity comes with a rich set of shaders. The Default Surface Shader is a powerful and optimized one that supports textures, normal maps, height maps, occlusion maps, emission map, specular highlights, reflections, and more.</p><p>Unity also includes a set of mobile optimized shaders that are popular for mobile (and desktop) VR development. While they may not provide as high-quality lighting and rendering support, they are designed to perform well on mobile devices and should be considered in any developer's toolbox, even on desktop VR apps.</p><p>VR device manufacturers and developers have released their own custom shaders that optimize graphics processing in ways they see fit. </p><p><span class="strong"><strong>Daydream Renderer</strong></span> (<a class="ulink" href="https://developers.google.com/vr/develop/unity/renderer" target="_blank">https://developers.google.com/vr/develop/unity/renderer</a>) is a Unity package designed for high-quality rendering optimized for the <span>Daydream</span><a id="id325581686" class="indexterm"></a> platform. It supports normal maps, specular highlights with up to eight dynamic lights, "hero shadows" with significant performance improvements over Unity's standard shaders.</p><p>Valve (Steam) released the VR shaders used in their impressive demo project, <span class="emphasis"><em>The Lab</em></span>, as a Unity Package (<a class="ulink" href="https://assetstore.unity.com/packages/tools/the-lab-renderer-63141" target="_blank">https://assetstore.unity.com/packages/tools/the-lab-renderer-63141</a>). It supports up to 18 dynamic shadowing lights in a single pass with MSAA. </p><p>The Oculus OVRPlugin, included with Unity, contains a number of Oculus-specific shaders, used by their prefabs and script components.</p><p>Third-party developers also provide shaders with their tools and utilities. As mentioned in <a class="link" href="#" linkend="ch02">Chapter 2</a>, <span class="emphasis"><em>Content, Objects, and Scale</em></span>, the Google Poly Toolkit for Unity include shaders for models downloaded from Poly, including artwork created with TiltBrush.</p><p>And you can experiment and write your own shader. In <a class="link" href="#" linkend="ch10">Chapter 10</a>, <span class="emphasis"><em>Using All 360 Degrees,</em></span> we looked at the Unity <span class="strong"><strong>ShaderLab</strong></span> language when we wrote our own inward shader. Unity 2018 introduces a new <span class="strong"><strong>Shader Graph</strong></span> tool for visually building <span>shaders</span><a id="id325586473" class="indexterm"></a> instead of using code. It's intended to be "simple enough that new <span>users</span><a id="id325586482" class="indexterm"></a> can become involved in shader creation."</p></div></div>