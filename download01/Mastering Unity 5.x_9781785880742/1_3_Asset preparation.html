<div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="ch01lvl1sec8"></a>Asset preparation</h2></div></div><hr /></div><p>When you've reached a clear decision on the initial concept and design, you're ready to prototype! This means building a Unity project demonstrating the core mechanic and game rules in action as a playable sample. After this, you typically refine the design more, and repeat prototyping until arriving at an artifact you want to pursue. From here, the art team must produce assets (meshes and textures) based on the concept art, the game design, and photographic references. When producing meshes and textures for Unity, some important guidelines should be followed to achieve optimal graphical performance in-game. This is about structuring and building assets in a smart way so that they export cleanly and easily from their originating software and can then be imported with minimal fuss, performing as best as they can at runtime. Let's take a look at some of these guidelines for meshes and textures.</p><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec11"></a>Meshes - work only with good topology</h3></div></div></div><p>A good mesh topology consists in all polygons having only three or four sides in the model (not more). Additionally, Edge Loops should flow in an ordered, regular way along the contours of the model, defining its shape and form.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_004-1.jpg" /></div><p>
</p><p>Clean topology</p><p>Unity automatically converts, on import, any <span class="strong"><strong>NGons </strong></span>(polygons with more than four sides) into triangles, if the mesh has any. However, it's better to build meshes without NGons as opposed to relying on Unity's automated methods. Not only does this cultivate good habits at the modeling phase, but it avoids any automatic and unpredictable retopology of the mesh, which affects how it's shaded and animated.</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec12"></a>Meshes - minimize polygon count</h3></div></div></div><p>Every polygon in a mesh entails a rendering performance hit insofar as a GPU needs time to process and render each polygon. Consequently, it's sensible to minimize the number of a polygons in a mesh, even though modern graphics hardware is adept at working with many polygons. It's a good practice to minimize polygons wherever possible and to the degree that it doesn't detract from your central artistic vision and style.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_005.jpg" /></div><p>
</p><p>High-poly meshes! (try reducing polygons where possible)</p><p>There are many techniques available to reduce polygon counts. Most 3D applications (such as 3ds Max, Maya, and Blender) offer automated tools that decimate polygons in a mesh while retaining its basic shape and outline. However, these methods frequently make a mess of topology, leaving you with faces and edge loops leading in all directions. Even so, this can still be useful for reducing polygons in <span class="strong"><strong>static meshes</strong></span> (meshes that never animate), such as statues, houses, or chairs. However, it's typically bad for animated meshes where topology is especially important.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_006.jpg" /></div><p>
</p><p>Reducing mesh polygons with automated methods can produce messy topology!</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><a id="note5"></a>Note</h3><p>If you want to know the total vertex and face count of a mesh, you can use your 3D software statistics. Blender, Maya, 3ds Max, and most 3D software let you see vertex and face counts of selected meshes directly from the viewport. However, this information should only be considered a rough guide! This is because after importing a mesh into Unity, the vertex count frequently turns out higher than expected! There are many reasons for this, which is explained in more depth online at <a class="ulink" href="http://docs.unity3d.com/Manual/OptimizingGraphicsPerformance.html" target="_blank">http://docs.unity3d.com/Manual/OptimizingGraphicsPerformance.html</a>.</p><p>In short, use the Unity vertex count as the final word on the actual vertex count of your mesh. To view the vertex count for an imported mesh in Unity, click on the right-arrow on the mesh thumbnail in the <span class="strong"><strong>Project</strong></span> panel. This shows the internal mesh asset. Select this asset, and then view the vertex count from the preview pane in the <span class="strong"><strong>Inspector</strong></span> object.</p></div><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_007.jpg" /></div><p>
</p><p>Viewing the vertex and face count for meshes in Unity</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec13"></a>Meshes - simulating bump details without geometry</h3></div></div></div><p>As mentioned, try keeping meshes as low-poly as possible. Low-poly meshes are, however, of lower quality than higher-resolution meshes. They have fewer polygons and thereby hold fewer details. Yet, this need not be problematic. Techniques exist for simulating detail in low-poly meshes, making them appear at a higher resolution than they really are. <span class="strong"><strong>Normal Mapping</strong></span> is one example of this. Normal Maps are special textures that define the orientation and roughness of a mesh surface across its polygons and how those polygons interact with lighting. In short, a Normal Map specifies how lighting interacts over a mesh and ultimately effects how the mesh is shaded. This influences how we perceive the details. You can produce Normal Maps in many ways, for example, typically using 3D modeling software. By producing two mesh versions (namely, a high-poly version containing all the needed details, and a low-poly version to receive the details), you can bake normal information from the high-poly mesh to the low-poly mesh via a texture file. This approach (known as <span class="strong"><strong>Normal Map Baking</strong></span>) can lead to stunningly accurate and believable results, as follows:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_008.jpg" /></div><p>
</p><p>Simulating high-poly detail with Normal Maps</p><p>However, if you don't have any Normal Maps for an imported mesh, Unity can generate them from a standard, diffuse texture, via the <span class="strong"><strong>Import Settings</strong></span>. This may not produce the most believable and physically accurate results, like Normal Map Baking, but it's useful to quickly and easily generate displacement details, enhancing the mood and realism of a scene. To create a Normal Map from a diffuse texture, first select the imported texture from the <span class="strong"><strong>Project</strong></span> panel and duplicate it-make sure that the original version is not invalidated or affected. Then, from the object <span class="strong"><strong>Inspector</strong></span>, change the <span class="strong"><strong>Texture Type</strong></span> (for the duplicate texture) from <span class="strong"><strong>Texture</strong></span> to <span class="strong"><strong>Normal map</strong></span>. This changes how Unity understands and works with the texture:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_009.jpg" /></div><p>
</p><p>Configuring texture as a Normal map</p><p>Specifying Normal Map for a texture configures Unity to use and work with that texture in a specialized, optimized way for generating bump details on your model. However, when creating a Normal Map from a diffuse texture, you'll also need to enable the <span class="strong"><strong>Create from Grayscale</strong></span> checkbox. When enabled, Unity generates a Normal Map from a grayscale version of the diffuse texture, using the <span class="strong"><strong>Bumpiness</strong></span> and <span class="strong"><strong>Filtering</strong></span> settings, as follows:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_010.jpg" /></div><p>
</p><p>Enable Create from Grayscale for Normal maps</p><p>With <span class="strong"><strong>Create from </strong></span>Grayscale enabled, you can use the <span class="strong"><strong>Bumpiness</strong></span> slider to intensify and weaken the bump effect and the <span class="strong"><strong>Filtering</strong></span> setting to control the roughness or smoothness of the bump. When you've adjusted the settings as needed, confirm the changes and preview the result by pressing the <span class="strong"><strong>Apply</strong></span> button from the <span class="strong"><strong>Inspector</strong></span> object:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_011.jpg" /></div><p>
</p><p>Customizing an imported Normal Map</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec14"></a>Meshes - minimize UV seams</h3></div></div></div><p>
<span class="strong"><strong>Seams</strong></span> are edge cuts inserted into a mesh during UV mapping to help it unfold, flattening out into a 2D space for the purpose of texture assignment. This process is achieved in 3D modeling software, but the cuts it makes are highly important for properly unfolding a model and getting it to look as intended inside Unity. An edge is classified as a seam in UV space when it has only one neighboring face, as opposed to two. Essentially, the seams determine how a mesh's UVs are cut apart into separate UV shells or UV islands, which are arranged into a final UV layout. This layout maps a texture onto the mesh surface, as follows:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_012.jpg" /></div><p>
</p><p>Creating a UV layout</p><p>Always minimize UV seams where feasible by joining together disparate edges, shells, or islands, forming larger units. This is not something you do in Unity, but in your 3D modeling software. Even so, by doing this, you potentially reduce the vertex count and complexity of your mesh. This leads to improved runtime performance in Unity. This is because Unity must duplicate all vertices along the seams to accommodate the rendering standards for most real-time graphics hardware. Thus, wherever there are seams, there will be a doubling up of vertices, as shown here:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_013.jpg" /></div><p>
</p><p>Binding together edges and islands to reduce UV seams</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec15"></a>Meshes - export as FBX</h3></div></div></div><p>Unity officially supports many mesh import formats, including <code class="literal">.ma</code>, <code class="literal">.mb</code>, <code class="literal">.max</code>, <code class="literal">.blend</code>, and others. Details and comparisons of these are found online at <a class="ulink" href="http://docs.unity3d.com/Manual/3D-formats.html" target="_blank">http://docs.unity3d.com/Manual/3D-formats.html</a>. Unity divides mesh formats into two main groups: <span class="strong"><strong>exported</strong></span> and <span class="strong"><strong>proprietary</strong></span>. The <span class="strong"><strong>exported formats</strong></span> include <code class="literal">.fbx</code> and <code class="literal">.dae</code>. These are meshes exported manually from 3D modeling software into an independent data-interchange format, which is industry recognized. It's feature limited, but widely supported. The <span class="strong"><strong>proprietary formats</strong></span>, in contrast, are application-specific formats that support a wider range of features but at the cost of compatibility. In short, you should almost always use the exported FBX file format. This is the most widely supported, used and tested format within the Unity community and supports imported meshes of all types, both static and animated. It gives the best results. If you choose a proprietary format, you'll frequently end up importing additional 3D objects that you'll never use in your game, and your Unity project is automatically tied to the 3D software itself. That is, you'll need a fully licensed copy of your 3D software on every machine for which you intend to open your Unity project; this is annoying.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_014.jpg" /></div><p>
</p><p>Exporting meshes to an FBX file, works best with Unity</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec16"></a>Meshes - use meters scale (metric)</h3></div></div></div><p>Unity measures 3D space using the metric system, and 1 world unit is understood, by the physics system, to mean 1 meter. Unity is configured to work with models from most 3D applications using their default settings. However, sometimes, your models will appear too big or small when imported. This usually happens when your world units are not configured to metric in your 3D modeling software. The details of how to change units varies for each software, such as Blender, Maya, or 3ds Max. Each program allows unit customization from the <span class="strong"><strong>Preferences</strong></span> menu.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_015.jpg" /></div><p>
</p><p>Configuring 3D software to Metric units</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec17"></a>Textures - never use lossless compression</h3></div></div></div><p>Always save your textures in lossless formats, such as PNG, TGA, or PSD. Avoid lossy formats such as JPG, even though they're typically smaller in file size. JPG might be ideal for website images or for sending holiday snaps to your friends and family; but, for creating video game textures, they are problematic-they lose quality exponentially with each successive save operation. By using lossless formats and by removing JPG from every step of your workflow (including intermediary steps), your textures can remain crisp and sharp:</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_016.jpg" /></div><p>
</p><p>Saving textures to PNG files</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec18"></a>Textures - power of 2 sizes</h3></div></div></div><p>If your textures are for 3D models and meshes (not sprites or GUI elements), then make their dimensions power-2 size for best results. The textures needn't be square (equal in width and height), but each dimension should be from a range of power-2 sizes. Valid sizes include 32, 64, 128, 256, 512, 1024, 2048, 4096, and 8192. Sizing textures to a power-2 dimension helps Unity scale textures up and down, as well as copy pixels between textures as needed, across the widest range of graphical hardware.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_017.jpg" /></div><p>
</p><p>Creating textures at power-2 sizes</p><p>When creating textures, it's always best to design for the largest possible power-2 size you'll need (as opposed to the largest possible size allowed), and then to downscale wherever appropriate to smaller power-2 sizes for older hardware and weaker systems, such as mobile devices. For each imported texture, you can use the Unity platform tabs from the <span class="strong"><strong>Inspector </strong></span> object to specify an appropriate maximum size for each texture on a specific platform: one for desktop systems, one for Android, one for iOS, and so on. This caps the maximum size allowed for the selected target on a per-platform basis. This value should be the smallest size that is compatible with your artistic intentions and intended quality.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_018.jpg" /></div><p>
</p><p>Overriding texture sizes for other platforms</p></div><div class="section" lang="en" xml:lang="en"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl2sec19"></a>Textures - alpha textures</h3></div></div></div><p>
<span class="strong"><strong>Alpha textures</strong></span> are textures with transparency. When applied to 3D models, they make areas of the model transparent, allowing objects behind it to show through. Alpha textures can be either TGA files with dedicated alpha channels or PNG files with transparent pixels. In either case, alpha textures can render with artifacts in Unity if they're not created and imported correctly.</p><p>
</p><div class="mediaobject"><img src="/graphics/9781785880742/graphics/image_01_019.jpg" /></div><p>
</p><p>Creating alpha textures</p><p>If you need to use alpha textures, ensure that you check out the official Unity documentation on how to export them for optimal results from <a class="ulink" href="http://docs.unity3d.com/Manual/HOWTO-alphamaps.html" target="_blank">http://docs.unity3d.com/Manual/HOWTO-alphamaps.html</a>.</p></div></div>